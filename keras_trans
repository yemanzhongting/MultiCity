{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_machine_translation_with_transformer",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/MultiCity/blob/main/keras_trans\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGVU8dNXXIja"
      },
      "source": [
        "# English-to-Spanish translation with a sequence-to-sequence Transformer\n",
        "\n",
        "**Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2021/05/26<br>\n",
        "**Last modified:** 2021/05/26<br>\n",
        "**Description:** Implementing a sequence-to-sequene Transformer and training it on a machine translation task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XUbMP54XIjp"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we'll build a sequence-to-sequence Transformer model, which\n",
        "we'll train on an English-to-Spanish machine translation task.\n",
        "\n",
        "You'll learn how to:\n",
        "\n",
        "- Vectorize text using the Keras `TextVectorization` layer.\n",
        "- Implement a `TransformerEncoder` layer, a `TransformerDecoder` layer,\n",
        "and a `PositionalEmbedding` layer.\n",
        "- Prepare data for training a sequence-to-sequence model.\n",
        "- Use the trained model to generate translations of never-seen-before\n",
        "input sentences (sequence-to-sequence inference).\n",
        "\n",
        "The code featured here is adapted from the book\n",
        "[Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition)\n",
        "(chapter 11: Deep learning for text).\n",
        "The present example is fairly barebones, so for detailed explanations of\n",
        "how each building block works, as well as the theory behind Transformers,\n",
        "I recommend reading the book."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XC2uSopXIjr"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TTXK3grXIjs"
      },
      "source": [
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECK0SY71XIjv"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "We'll be working with an English-to-Spanish translation dataset\n",
        "provided by [Anki](https://www.manythings.org/anki/). Let's download it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lkjhZ4dXIjw"
      },
      "source": [
        "text_file = keras.utils.get_file(\n",
        "    fname=\"spa-eng.zip\",\n",
        "    origin=\"http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\",\n",
        "    extract=True,\n",
        ")\n",
        "text_file = pathlib.Path(text_file).parent / \"spa-eng\" / \"spa.txt\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7-h3V-3XIjy"
      },
      "source": [
        "## Parsing the data\n",
        "\n",
        "Each line contains an English sentence and its corresponding Spanish sentence.\n",
        "The English sentence is the *source sequence* and Spanish one is the *target sequence*.\n",
        "We prepend the token `\"[start]\"` and we append the token `\"[end]\"` to the Spanish sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ghezIbKXIjz"
      },
      "source": [
        "with open(text_file) as f:\n",
        "    lines = f.read().split(\"\\n\")[:-1]\n",
        "text_pairs = []\n",
        "for line in lines:\n",
        "    eng, spa = line.split(\"\\t\")\n",
        "    spa = \"[start] \" + spa + \" [end]\"\n",
        "    text_pairs.append((eng, spa))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-PD1ZpfluNb",
        "outputId": "c1d7a65d-352c-4341-f455-bd5d81157243"
      },
      "source": [
        "len(text_pairs)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "118964"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap7uXms1lxdI",
        "outputId": "dc061b8a-34ca-432f-906b-39c1fec36b98"
      },
      "source": [
        "text_pairs[0]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('He is very kind to me.', '[start] Él es muy lindo conmigo. [end]')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_fbUyM2XIj4"
      },
      "source": [
        "Here's what our sentence pairs look like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-WuGFfrXIj6",
        "outputId": "ef78ae88-599b-4e46-f9df-9f966b2bab3c"
      },
      "source": [
        "for _ in range(5):\n",
        "    print(random.choice(text_pairs))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(\"You don't seem very concerned.\", '[start] No pareces muy preocupado. [end]')\n",
            "(\"It's a dead giveaway.\", '[start] Es una clara señal. [end]')\n",
            "(\"You can't park your car here.\", '[start] No puede aparcar aquí. [end]')\n",
            "('I like your house.', '[start] Me gusta tu casa. [end]')\n",
            "(\"I didn't ask Tom to wait for me.\", '[start] No le pedí a Tom que me esperara. [end]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdT9O0McXIj8"
      },
      "source": [
        "Now, let's split the sentence pairs into a training set, a validation set,\n",
        "and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8G0_QeEHXIj9",
        "outputId": "1c49dd13-bda9-4c24-9399-0c7267faffe7"
      },
      "source": [
        "random.shuffle(text_pairs)\n",
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]\n",
        "\n",
        "print(f\"{len(text_pairs)} total pairs\")\n",
        "print(f\"{len(train_pairs)} training pairs\")\n",
        "print(f\"{len(val_pairs)} validation pairs\")\n",
        "print(f\"{len(test_pairs)} test pairs\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "118964 total pairs\n",
            "83276 training pairs\n",
            "17844 validation pairs\n",
            "17844 test pairs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5Vw2VZ9pypT",
        "outputId": "0a9a1af8-fb5c-4736-8c5c-febefd62b815"
      },
      "source": [
        "test_pairs[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('He was exhausted when he got home.',\n",
              " '[start] Él estaba exhausto cuando llegó a casa. [end]')"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iQUj0ZwXIj-"
      },
      "source": [
        "## Vectorizing the text data\n",
        "\n",
        "We'll use two instances of the `TextVectorization` layer to vectorize the text\n",
        "data (one for English and one for Spanish),\n",
        "that is to say, to turn the original strings into integer sequences\n",
        "where each integer represents the index of a word in a vocabulary.\n",
        "\n",
        "The English layer will use the default string standardization (strip punctuation characters)\n",
        "and splitting scheme (split on whitespace), while\n",
        "the Spanish layer will use a custom standardization, where we add the character\n",
        "`\"¿\"` to the set of punctuation characters to be stripped.\n",
        "\n",
        "Note: in a production-grade machine translation model, I would not recommend\n",
        "stripping the punctuation characters in either language. Instead, I would recommend turning\n",
        "each punctuation character into its own token,\n",
        "which you could achieve by providing a custom `split` function to the `TextVectorization` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qx9BouLYl449"
      },
      "source": [
        "##对文本数据进行矢量化\n",
        "\n",
        "我们将使用 \"TextVectorization \"层的两个实例来对文本数据进行矢量化。\n",
        "数据（一个用于英语，一个用于西班牙语）。\n",
        "也就是说，将原始字符串变成整数序列\n",
        "其中每个整数代表词汇表中的一个词的索引。\n",
        "\n",
        "英语层将使用默认的字符串标准化（去除标点符号\n",
        "和分割方案（在空白处分割），而\n",
        "而西班牙语层将使用一个自定义的标准化，我们在其中添加字符\n",
        "`\"¿\"`到要剥离的标点符号集合中。\n",
        "\n",
        "注意：在一个生产级的机器翻译模型中，我不建议\n",
        "剥离两种语言中的标点符号。相反，我建议将\n",
        "把每个标点符号变成自己的标记。\n",
        "你可以通过为 \"文本矢量化 \"层提供一个自定义的 \"分割 \"函数来实现。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWVMvv0vXIkA"
      },
      "source": [
        "strip_chars = string.punctuation + \"¿\"\n",
        "strip_chars = strip_chars.replace(\"[\", \"\")\n",
        "strip_chars = strip_chars.replace(\"]\", \"\")\n",
        "\n",
        "vocab_size = 15000\n",
        "sequence_length = 20\n",
        "batch_size = 64\n",
        "\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return tf.strings.regex_replace(lowercase, \"[%s]\" % re.escape(strip_chars), \"\")\n",
        "\n",
        "\n",
        "eng_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,\n",
        ")\n",
        "spa_vectorization = TextVectorization(\n",
        "    max_tokens=vocab_size,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length + 1,\n",
        "    standardize=custom_standardization,\n",
        ")\n",
        "train_eng_texts = [pair[0] for pair in train_pairs]\n",
        "train_spa_texts = [pair[1] for pair in train_pairs]\n",
        "eng_vectorization.adapt(train_eng_texts)\n",
        "spa_vectorization.adapt(train_spa_texts)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBCaMq1MmuqI",
        "outputId": "cbf6d357-3224-4298-c009-62c12c06ec08"
      },
      "source": [
        "eng_vectorization"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.preprocessing.text_vectorization.TextVectorization at 0x7ff38b84d890>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "Z9CtmW1NmHMB",
        "outputId": "f7ffbfa8-3540-44ee-bade-c3533057c684"
      },
      "source": [
        "train_spa_texts[0]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[start] Él es muy lindo conmigo. [end]'"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pQUQ7l-zmBSw",
        "outputId": "b3012059-45b2-4d78-a8b8-609d87aa3556"
      },
      "source": [
        "train_eng_texts[0]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'He is very kind to me.'"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hupurzzImLcu"
      },
      "source": [
        "eng_vectorization.adapt(train_eng_texts)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImdXD4umXIkD"
      },
      "source": [
        "Next, we'll format our datasets.\n",
        "\n",
        "At each training step, the model will seek to predict target words N+1 (and beyond)\n",
        "using the source sentence and the target words 0 to N.\n",
        "\n",
        "As such, the training dataset will yield a tuple `(inputs, targets)`, where:\n",
        "\n",
        "- `inputs` is a dictionary with the keys `encoder_inputs` and `decoder_inputs`.\n",
        "`encoder_inputs` is the vectorized source sentence and `encoder_inputs` is the target sentence \"so far\",\n",
        "that is to say, the words 0 to N used to predict word N+1 (and beyond) in the target sentence.\n",
        "- `target` is the target sentence offset by one step:\n",
        "it provides the next words in the target sentence -- what the model will try to predict."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVu-jP9Im8nb",
        "outputId": "4ed54a84-768c-427e-d959-373844a5f495"
      },
      "source": [
        "eng_vectorization(\"You don't seem very concerned.\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=int64, numpy=\n",
              "array([   5,   22,  520,   54, 2121,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iz-5jsKCnDIj",
        "outputId": "71724f9d-9737-40a5-aa70-73a6ec978731"
      },
      "source": [
        "spa_vectorization('No pareces muy preocupado.')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(21,), dtype=int64, numpy=\n",
              "array([   7,  731,   39, 1133,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0])>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljMyXtdimaRg"
      },
      "source": [
        "def format_dataset(eng, spa):\n",
        "    eng = eng_vectorization(eng)\n",
        "    spa = spa_vectorization(spa)\n",
        "    return ({\"encoder_inputs\": eng, \"decoder_inputs\": spa[:, :-1],}, spa[:, 1:])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P84fFoIumc8A"
      },
      "source": [
        "# format_dataset(\"You don't seem very concerned.\", 'No pareces muy preocupado.')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqZiUFxTXIkF"
      },
      "source": [
        "def make_dataset(pairs):\n",
        "    eng_texts, spa_texts = zip(*pairs)\n",
        "    eng_texts = list(eng_texts)\n",
        "    spa_texts = list(spa_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()\n",
        "\n",
        "\n",
        "train_ds = make_dataset(train_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVtOD97jmSRy",
        "outputId": "94e9608f-7307-4871-d772-e905f7456170"
      },
      "source": [
        "train_ds"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CacheDataset shapes: ({encoder_inputs: (None, 20), decoder_inputs: (None, 20)}, (None, 20)), types: ({encoder_inputs: tf.int64, decoder_inputs: tf.int64}, tf.int64)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLCX8kWAXIkG"
      },
      "source": [
        "Let's take a quick look at the sequence shapes\n",
        "(we have batches of 64 pairs, and all sequences are 20 steps long):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3JnZ_HeXIkH",
        "outputId": "4f1fcb6b-d821-4e66-b5a3-b89c030db41f"
      },
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (64, 20)\n",
            "inputs[\"decoder_inputs\"].shape: (64, 20)\n",
            "targets.shape: (64, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vETfD2-WXIkI"
      },
      "source": [
        "## Building the model\n",
        "\n",
        "Our sequence-to-sequence Transformer consists of a `TransformerEncoder`\n",
        "and a `TransformerDecoder` chained together. To make the model aware of word order,\n",
        "we also use a `PositionalEmbedding` layer.\n",
        "\n",
        "The source sequence will be pass to the `TransformerEncoder`,\n",
        "which will produce a new representation of it.\n",
        "This new representation will then be passed\n",
        "to the `TransformerDecoder`, together with the target sequence so far (target words 0 to N).\n",
        "The `TransformerDecoder` will then seek to predict the next words in the target sequence (N+1 and beyond).\n",
        "\n",
        "A key detail that makes this possible is causal masking\n",
        "(see method `get_causal_attention_mask()` on the `TransformerDecoder`).\n",
        "The `TransformerDecoder` sees the entire sequences at once, and thus we must make\n",
        "sure that it only uses information from target tokens 0 to N when predicting token N+1\n",
        "(otherwise, it could use information from the future, which would\n",
        "result in a model that cannot be used at inference time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pdnFAxitp6j"
      },
      "source": [
        "## 构建模型\n",
        "\n",
        "我们的序列到序列的转换器由一个 \"TransformerEncoder \"和一个 \"TransformerDecoder \"组成。\n",
        "和一个 \"TransformerDecoder \"链在一起。为了使模型能够意识到词的顺序。\n",
        "我们还使用了一个 \"位置嵌入 \"层。\n",
        "\n",
        "源序列将被传递给 \"转化器编码器\"。\n",
        "它将产生一个新的表示。\n",
        "然后这个新的表示将被传递给\n",
        "到 \"TransformerDecoder\"，连同到目前为止的目标序列（目标字0到N）。\n",
        "然后`TransformerDecoder'将寻求预测目标序列中的下一个词（N+1及以后）。\n",
        "\n",
        "使之成为可能的一个关键细节是因果掩码\n",
        "(见`TransformerDecoder'上的`get_causal_attention_mask()'方法)。\n",
        "变换器解码器 \"一次就能看到整个序列，因此我们必须确保它只使用目标信息。\n",
        "因此我们必须确保它在预测N+1号标记时只使用目标标记0到N的信息。\n",
        "(的信息（否则，它可能使用未来的信息，这将导致\n",
        "否则，它可能会使用未来的信息，这将导致在推理时不能使用的模型）。)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YT6V2OHXIkJ"
      },
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
        "        super(TransformerEncoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.dense_dim = dense_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
        "        attention_output = self.attention(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
        "        )\n",
        "\n",
        "        # print(attention_output)\n",
        "\n",
        "        proj_input = self.layernorm_1(inputs + attention_output)\n",
        "        proj_output = self.dense_proj(proj_input)\n",
        "        return self.layernorm_2(proj_input + proj_output),attention_output\n",
        "\n",
        "\n",
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
        "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(\n",
        "            input_dim=vocab_size, output_dim=embed_dim\n",
        "        )\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=embed_dim\n",
        "        )\n",
        "        self.sequence_length = sequence_length\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_dim = embed_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "\n",
        "class TransformerDecoder(layers.Layer):\n",
        "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
        "        super(TransformerDecoder, self).__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.attention_1 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.attention_2 = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim\n",
        "        )\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(latent_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "        self.layernorm_3 = layers.LayerNormalization()\n",
        "        self.supports_masking = True\n",
        "\n",
        "    def call(self, inputs, encoder_outputs, mask=None):\n",
        "        causal_mask = self.get_causal_attention_mask(inputs)\n",
        "        if mask is not None:\n",
        "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
        "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
        "\n",
        "        attention_output_1 = self.attention_1(\n",
        "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
        "        )\n",
        "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
        "\n",
        "        attention_output_2 = self.attention_2(\n",
        "            query=out_1,\n",
        "            value=encoder_outputs,\n",
        "            key=encoder_outputs,\n",
        "            attention_mask=padding_mask,\n",
        "        )\n",
        "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
        "\n",
        "        proj_output = self.dense_proj(out_2)\n",
        "        return self.layernorm_3(out_2 + proj_output)\n",
        "\n",
        "    def get_causal_attention_mask(self, inputs):\n",
        "        input_shape = tf.shape(inputs)\n",
        "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
        "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
        "        j = tf.range(sequence_length)\n",
        "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
        "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
        "        mult = tf.concat(\n",
        "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
        "            axis=0,\n",
        "        )\n",
        "        return tf.tile(mask, mult)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1EIjkKvXIkK"
      },
      "source": [
        "Next, we assemble the end-to-end model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQrmskp5XIkL"
      },
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 2048\n",
        "num_heads = 8\n",
        "\n",
        "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO91SV_JutJK",
        "outputId": "ed0e6ef0-e66e-4b24-95a4-3ce69b8fb28d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "TransformerEncoder(embed_dim, latent_dim, num_heads)(x)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<KerasTensor: shape=(None, None, 256) dtype=float32 (created by layer 'transformer_encoder_5')>,\n",
              " <KerasTensor: shape=(None, None, 256) dtype=float32 (created by layer 'transformer_encoder_5')>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TamtUrpRupxP"
      },
      "source": [
        "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)[0]\n",
        "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
        "\n",
        "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
        "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
        "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
        "\n",
        "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
        "transformer = keras.Model(\n",
        "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
        ")"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uugXdDwDXIkM"
      },
      "source": [
        "## Training our model\n",
        "\n",
        "We'll use accuracy as a quick way to monitor training progress on the validation data.\n",
        "Note that machine translation typically uses BLEU scores as well as other metrics, rather than accuracy.\n",
        "\n",
        "Here we only train for 1 epoch, but to get the model to actually converge\n",
        "you should train for at least 30 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "ItCylotwa2zp",
        "outputId": "975f2718-58d2-4408-95a2-64f3f4be9fa6"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "tf.keras.utils.plot_model(\n",
        "transformer, to_file='model.png'\n",
        ")\n",
        "# , show_shapes=False, show_dtype=False,\n",
        "# show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96\n",
        "# plot_model(transformer, to_file='model.png')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_ioQXx-XIkN",
        "outputId": "93a2a0ba-75fb-41a9-b86d-06762641bf7f"
      },
      "source": [
        "epochs = 1  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs)#, validation_data=val_ds"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding_8 (Positio (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_6 (Transfor ((None, None, 256),  3155456     positional_embedding_8[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "model_9 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder_6[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "1302/1302 [==============================] - 151s 113ms/step - loss: 1.6381 - accuracy: 0.4321\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3213c1710>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkpBMxC7o7vo",
        "outputId": "60f6eb20-08fe-464e-effc-abb0926a46c5"
      },
      "source": [
        "epochs = 1  # This should be at least 30 for convergence\n",
        "\n",
        "transformer.summary()\n",
        "transformer.compile(\n",
        "    \"rmsprop\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "transformer.fit(train_ds, epochs=epochs, validation_data=val_ds)#"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"transformer\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "positional_embedding_2 (Positio (None, None, 256)    3845120     encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "transformer_encoder_1 (Transfor (None, None, 256)    3155456     positional_embedding_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Functional)            (None, None, 15000)  12959640    decoder_inputs[0][0]             \n",
            "                                                                 transformer_encoder_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 19,960,216\n",
            "Trainable params: 19,960,216\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "1302/1302 [==============================] - 165s 123ms/step - loss: 1.1847 - accuracy: 0.5830 - val_loss: 1.0757 - val_accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff389e98e50>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxrX-2yhXIkN"
      },
      "source": [
        "## Decoding test sentences\n",
        "\n",
        "Finally, let's demonstrate how to translate brand new English sentences.\n",
        "We simply feed into the model the vectorized English sentence\n",
        "as well as the target token `\"[start]\"`, then we repeatedly generated the next token, until\n",
        "we hit the token `\"[end]\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQ5exr2AnoLr"
      },
      "source": [
        "spa_vocab = spa_vectorization.get_vocabulary()\n",
        "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHzdpwCrnoyA"
      },
      "source": [
        "# spa_index_lookup"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2g_3TSb_XIkO"
      },
      "source": [
        "def decode_sequence(input_sentence):\n",
        "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
        "    decoded_sentence = \"[start]\"\n",
        "    for i in range(max_decoded_sentence_length):\n",
        "        tokenized_target_sentence = spa_vectorization([decoded_sentence])[:, :-1]\n",
        "        predictions = transformer([tokenized_input_sentence, tokenized_target_sentence])\n",
        "\n",
        "        print(predictions)\n",
        "        print(predictions.shape)\n",
        "\n",
        "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
        "\n",
        "        # print(sampled_token_index)\n",
        "\n",
        "        sampled_token = spa_index_lookup[sampled_token_index]\n",
        "        decoded_sentence += \" \" + sampled_token\n",
        "\n",
        "        if sampled_token == \"[end]\":\n",
        "            break\n",
        "    return decoded_sentence"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AKWczO2n_Uq",
        "outputId": "a36c7027-4422-4880-92a8-e487ed0244cd"
      },
      "source": [
        "test_pairs[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('He was exhausted when he got home.',\n",
              " '[start] Él estaba exhausto cuando llegó a casa. [end]')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4Zvdd2dlpwl",
        "outputId": "65cc1ab1-2ce6-41dd-9096-20d34eea68be"
      },
      "source": [
        "test_eng_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(1):\n",
        "    input_sentence = random.choice(test_eng_texts)\n",
        "    translated = decode_sequence(input_sentence)\n",
        "    print(translated)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[1.6545135e-05 5.5736890e-03 6.8310771e-07 ... 7.0592267e-07\n",
            "   6.9500686e-07 1.2233912e-06]\n",
            "  [3.1469677e-05 1.5485076e-02 2.8317132e-07 ... 2.9317363e-07\n",
            "   2.8858872e-07 4.9558633e-07]\n",
            "  [3.6673224e-05 1.8403355e-02 2.7994878e-07 ... 2.8864997e-07\n",
            "   2.8509945e-07 5.0375309e-07]\n",
            "  ...\n",
            "  [2.2755954e-05 1.7234167e-02 5.2689336e-07 ... 5.3761960e-07\n",
            "   5.3448377e-07 9.5144469e-07]\n",
            "  [2.6079726e-05 1.7596619e-02 5.1418050e-07 ... 5.2539190e-07\n",
            "   5.2142860e-07 9.3483925e-07]\n",
            "  [2.5659867e-05 1.6244637e-02 6.2510696e-07 ... 6.3946544e-07\n",
            "   6.3409220e-07 1.1373045e-06]]], shape=(1, 20, 15000), dtype=float32)\n",
            "(1, 20, 15000)\n",
            "tf.Tensor(\n",
            "[[[1.6545135e-05 5.5736890e-03 6.8310771e-07 ... 7.0592267e-07\n",
            "   6.9500686e-07 1.2233912e-06]\n",
            "  [8.0804937e-05 1.1153709e-02 7.9810229e-07 ... 8.6986779e-07\n",
            "   8.3251092e-07 1.2448095e-06]\n",
            "  [1.2990875e-05 8.3614876e-03 5.0420276e-08 ... 5.3548781e-08\n",
            "   5.1994206e-08 8.2909750e-08]\n",
            "  ...\n",
            "  [1.1153680e-05 1.4788154e-02 2.0799996e-07 ... 2.1341678e-07\n",
            "   2.1124565e-07 3.5701441e-07]\n",
            "  [1.2797423e-05 1.5554191e-02 1.9190917e-07 ... 1.9737283e-07\n",
            "   1.9497591e-07 3.3318244e-07]\n",
            "  [1.4165336e-05 1.6215801e-02 2.6382335e-07 ... 2.7079284e-07\n",
            "   2.6794066e-07 4.5650583e-07]]], shape=(1, 20, 15000), dtype=float32)\n",
            "(1, 20, 15000)\n",
            "tf.Tensor(\n",
            "[[[1.6545135e-05 5.5736890e-03 6.8310771e-07 ... 7.0592267e-07\n",
            "   6.9500686e-07 1.2233912e-06]\n",
            "  [8.0804937e-05 1.1153709e-02 7.9810229e-07 ... 8.6986779e-07\n",
            "   8.3251092e-07 1.2448095e-06]\n",
            "  [1.1367194e-04 2.0048823e-02 6.7449565e-07 ... 7.1573328e-07\n",
            "   6.9839365e-07 9.8125065e-07]\n",
            "  ...\n",
            "  [3.0222540e-05 1.2697916e-02 9.1211732e-08 ... 9.6216496e-08\n",
            "   9.3850772e-08 1.3482328e-07]\n",
            "  [3.9708484e-05 1.4209661e-02 9.9006570e-08 ... 1.0487649e-07\n",
            "   1.0177180e-07 1.5033110e-07]\n",
            "  [5.0356564e-05 1.4821576e-02 1.3082247e-07 ... 1.3864823e-07\n",
            "   1.3467820e-07 1.9334144e-07]]], shape=(1, 20, 15000), dtype=float32)\n",
            "(1, 20, 15000)\n",
            "tf.Tensor(\n",
            "[[[1.6545135e-05 5.5736890e-03 6.8310771e-07 ... 7.0592267e-07\n",
            "   6.9500686e-07 1.2233912e-06]\n",
            "  [8.0804937e-05 1.1153709e-02 7.9810229e-07 ... 8.6986779e-07\n",
            "   8.3251092e-07 1.2448095e-06]\n",
            "  [1.1367194e-04 2.0048823e-02 6.7449565e-07 ... 7.1573328e-07\n",
            "   6.9839365e-07 9.8125065e-07]\n",
            "  ...\n",
            "  [7.3307192e-06 4.1563567e-03 2.8591716e-08 ... 3.0429920e-08\n",
            "   2.9419468e-08 4.1039726e-08]\n",
            "  [8.2856341e-06 3.9120154e-03 2.2141819e-08 ... 2.3709575e-08\n",
            "   2.2815108e-08 3.1949480e-08]\n",
            "  [8.2483321e-06 4.1335537e-03 2.8627277e-08 ... 3.0610650e-08\n",
            "   2.9467635e-08 4.1408228e-08]]], shape=(1, 20, 15000), dtype=float32)\n",
            "(1, 20, 15000)\n",
            "tf.Tensor(\n",
            "[[[1.6545135e-05 5.5736890e-03 6.8310771e-07 ... 7.0592267e-07\n",
            "   6.9500686e-07 1.2233912e-06]\n",
            "  [8.0804937e-05 1.1153709e-02 7.9810229e-07 ... 8.6986779e-07\n",
            "   8.3251092e-07 1.2448095e-06]\n",
            "  [1.1367194e-04 2.0048823e-02 6.7449565e-07 ... 7.1573328e-07\n",
            "   6.9839365e-07 9.8125065e-07]\n",
            "  ...\n",
            "  [2.5063907e-06 7.8809162e-04 1.5257116e-08 ... 1.6204419e-08\n",
            "   1.5584767e-08 2.1996748e-08]\n",
            "  [3.0063004e-06 7.5345434e-04 1.2838739e-08 ... 1.3699572e-08\n",
            "   1.3132877e-08 1.8671242e-08]\n",
            "  [2.9367507e-06 8.0552505e-04 1.5335884e-08 ... 1.6363492e-08\n",
            "   1.5670423e-08 2.2237439e-08]]], shape=(1, 20, 15000), dtype=float32)\n",
            "(1, 20, 15000)\n",
            "[start] puedes haber un hombre [end]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMO5Lk7_oKSU"
      },
      "source": [
        "def plot_encoder_decoder_attention(attention, input_sentence,\n",
        "                                   result, layer_name):\n",
        "    fig = plt.figure(figsize = (16, 8))\n",
        "    \n",
        "    input_id_sentence = pt_tokenizer.encode(input_sentence)\n",
        "    \n",
        "    # attention.shape: (num_heads, tar_len, input_len)\n",
        "    attention = tf.squeeze(attention[layer_name], axis = 0)\n",
        "    \n",
        "    for head in range(attention.shape[0]):\n",
        "        ax = fig.add_subplot(2, 4, head + 1)\n",
        "        \n",
        "        ax.matshow(attention[head][:-1, :])\n",
        "        \n",
        "        fontdict = {'fontsize': 10}\n",
        "        \n",
        "        ax.set_xticks(range(len(input_id_sentence) + 2))\n",
        "        ax.set_yticks(range(len(result)))\n",
        "        \n",
        "        ax.set_ylim(len(result) - 1.5, -0.5)\n",
        "        \n",
        "        ax.set_xticklabels(\n",
        "            ['<start>'] + [pt_tokenizer.decode([i]) for i in input_id_sentence] + ['<end>'],\n",
        "            fontdict = fontdict, rotation = 90)\n",
        "        ax.set_yticklabels(\n",
        "            [en_tokenizer.decode([i]) for i in result if i < en_tokenizer.vocab_size],\n",
        "            fontdict = fontdict)\n",
        "        ax.set_xlabel('Head {}'.format(head + 1))\n",
        "    plt.tight_layout() # 自适应调整间距等\n",
        "    plt.show()    "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tDIv9Tts18e"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Evaluate function -- similar to the training loop\n",
        "def evaluate(sentence):\n",
        "\n",
        "  # Attention plot (to be plotted later on) -- initialized with max_lengths of both target and input\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  # Preprocess the sentence given\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  # Fetch the indices concerning the words in the sentence and pad the sequence\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  # Convert the inputs to tensors\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  # Loop until the max_length is reached for the target lang (ENGLISH)\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "\n",
        "    # Store the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "    # Get the prediction with the maximum attention\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    # Append the token to the result\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    # If <end> token is reached, return the result, input, and attention plot\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence, attention_plot\n",
        "\n",
        "    # The predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uam9VvMBXIkP"
      },
      "source": [
        "After 30 epochs, we get results such as:\n",
        "\n",
        "> She handed him the money.\n",
        "> [start] ella le pasó el dinero [end]\n",
        "\n",
        "> Tom has never heard Mary sing.\n",
        "> [start] tom nunca ha oído cantar a mary [end]\n",
        "\n",
        "> Perhaps she will come tomorrow.\n",
        "> [start] tal vez ella vendrá mañana [end]\n",
        "\n",
        "> I love to write.\n",
        "> [start] me encanta escribir [end]\n",
        "\n",
        "> His French is improving little by little.\n",
        "> [start] su francés va a [UNK] sólo un poco [end]\n",
        "\n",
        "> My hotel told me to call you.\n",
        "> [start] mi hotel me dijo que te [UNK] [end]"
      ]
    }
  ]
}