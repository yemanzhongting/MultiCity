{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "22_Image_Captioning.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/MultiCity/blob/main/%E6%A8%A1%E6%80%81%E7%9F%A9%E9%98%B5%E6%90%AD%E5%BB%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8jJ2H-lAmga"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle as pkl\n",
        "import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n",
        "    multiply, concatenate, Flatten, Activation, dot\n",
        "# from keras.optimizers import Adam\n",
        "# from keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pydot as pyd\n",
        "from keras.utils.vis_utils import plot_model, model_to_dot\n",
        "keras.utils.vis_utils.pydot = pyd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1YrYwj8EODi",
        "outputId": "beab3004-7037-4b13-9995-1fb54eca6740"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWpYi4EqEJmR"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import nltk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdA6XdVQEd9l"
      },
      "source": [
        "def load_data(in_file):\n",
        "    cn = []\n",
        "    en = []\n",
        "    num_examples = 0\n",
        "    with open(in_file, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip().split(\"\\t\")\n",
        "            \n",
        "            # en.append([\"BOS\"] + nltk.word_tokenize(line[0].lower()) + [\"EOS\"])\n",
        "            en.append(nltk.word_tokenize(line[0].lower()))\n",
        "            # split chinese sentence into characters\n",
        "            # cn.append([\"BOS\"] + [c for c in line[1].split(' ')] + [\"EOS\"])\n",
        "            cn.append([c for c in line[1].split(' ')] )\n",
        "    return en, cn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRr2LVIsEeAz",
        "outputId": "9b0748e0-b446-4cbb-c656-c4d8be235f03"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "train_file = \"/content/drive/MyDrive/data/sv-sub.txt\"\n",
        "dev_file = \"nmt/en-cn/dev.txt\"\n",
        "train_en, train_cn = load_data(train_file)\n",
        "# dev_en, dev_cn = load_data(dev_file)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIqU68rrSBjx",
        "outputId": "2cad44e5-f4e5-4f1f-ce2d-21f7789b9bec"
      },
      "source": [
        "type(train_en)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItMRc7WORmXy"
      },
      "source": [
        "UNK_IDX = 0\n",
        "PAD_IDX = 1\n",
        "def build_dict(sentences, max_words=50000):\n",
        "    word_count = Counter()\n",
        "    for sentence in sentences:\n",
        "        for s in sentence:\n",
        "            word_count[s] += 1\n",
        "    ls = word_count.most_common(max_words)\n",
        "    total_words = len(ls) #+ 2\n",
        "    # word_dict = {w[0]: index+2 for index, w in enumerate(ls)}\n",
        "    word_dict = {w[0]: index+1 for index, w in enumerate(ls)}\n",
        "    # word_dict[\"UNK\"] = UNK_IDX\n",
        "    # word_dict[\"PAD\"] = PAD_IDX\n",
        "    return word_dict, total_words\n",
        "\n",
        "en_dict, en_total_words = build_dict(train_en)\n",
        "cn_dict, cn_total_words = build_dict(train_cn)\n",
        "inv_en_dict = {v: k for k, v in en_dict.items()}\n",
        "inv_cn_dict = {v: k for k, v in cn_dict.items()}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNrpduHnJt8k",
        "outputId": "ac6de9a7-550e-44a6-bbad-fd631ebf3d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "def words_2_ints(words):\n",
        "    ints = []\n",
        "    for itmp in words:\n",
        "        ints.append(en_dict.get(itmp, 0))\n",
        "    return ints\n",
        "def words_2_one_hot(words, num_classes):\n",
        "    return np_utils.to_categorical(words_2_ints(words), num_classes=num_classes)\n",
        "import tensorflow as tf\n",
        "# from tf.keras.preprocessing.sequence import pad_sequences\n",
        "train_en_pad=[]\n",
        "for i in train_en:\n",
        "  tmp=tf.keras.preprocessing.sequence.pad_sequences(words_2_one_hot(i,len(en_dict)+1).T, padding=\"post\", maxlen=10,value=0).T\n",
        "  train_en_pad.append(tmp)\n",
        "train_en_pad_arr=np.array(train_en_pad)\n",
        "train_en_pad_arr.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20790, 10, 140)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnO4Uu16Tk5r",
        "outputId": "b7ecc540-3816-43e1-e781-9d110fec1ee0"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "def words_2_ints(words):\n",
        "    ints = []\n",
        "    for itmp in words:\n",
        "        ints.append(cn_dict.get(itmp, 0))\n",
        "    return ints\n",
        "def words_2_one_hot(words, num_classes):\n",
        "    return np_utils.to_categorical(words_2_ints(words), num_classes=num_classes)\n",
        "import tensorflow as tf\n",
        "# from tf.keras.preprocessing.sequence import pad_sequences\n",
        "train_cn_pad=[]\n",
        "for i in train_cn:\n",
        "  tmp=tf.keras.preprocessing.sequence.pad_sequences(words_2_one_hot(i,len(cn_dict)+1).T, padding=\"post\", maxlen=10,value=0).T\n",
        "  train_cn_pad.append(tmp)\n",
        "train_cn_pad_arr=np.array(train_cn_pad)\n",
        "train_cn_pad_arr.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20790, 10, 155)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtsAN96XNGD7"
      },
      "source": [
        "\n",
        "# model=Sequential()\n",
        "# model.add(LSTM(256,dropout_W=0.2,dropout_u=0.2,input_shape(seq_length,128)))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(Dense(128,activation=\"sigmoid\"))\n",
        "# model,compile(loss=\"mse\",optimizer=\"adm\")\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pickle as pkl\n",
        "import keras\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import LSTM, Dense, RepeatVector, TimeDistributed, Input, BatchNormalization, \\\n",
        "    multiply, concatenate, Flatten, Activation, dot\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam # - Works\n",
        "\n",
        "# from keras.optimizers import Adam\n",
        "# from keras.utils import plot_model\n",
        "from keras.callbacks import EarlyStopping\n",
        "import pydot as pyd\n",
        "# from keras.utils.vis_utils import plot_model, model_to_dot\n",
        "keras.utils.vis_utils.pydot = pyd"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-L6vxRYG-Gc"
      },
      "source": [
        "n_hidden = 100\n",
        "input_train = Input(shape=(train_en_pad_arr.shape[1], train_en_pad_arr.shape[2]))\n",
        "output_train = Input(shape=(train_cn_pad_arr.shape[1], train_cn_pad_arr.shape[2]))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeH6rPu3VQZP"
      },
      "source": [
        "https://levelup.gitconnected.com/building-seq2seq-lstm-with-luong-attention-in-keras-for-time-series-forecasting-1ee00958decb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmIoPA04VRqf",
        "outputId": "836e56e8-6397-4109-a951-efe389c464ec"
      },
      "source": [
        "encoder_stack_h, encoder_last_h, encoder_last_c = LSTM(\n",
        "    n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2, \n",
        "    return_state=True, return_sequences=True)(input_train)\n",
        "print(encoder_stack_h)\n",
        "print(encoder_last_h)\n",
        "print(encoder_last_c)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 100), dtype=tf.float32, name=None), name='lstm_2/transpose_1:0', description=\"created by layer 'lstm_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='lstm_2/while:4', description=\"created by layer 'lstm_2'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='lstm_2/while:5', description=\"created by layer 'lstm_2'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx-K_xtlVcSE"
      },
      "source": [
        "encoder_last_h = BatchNormalization(momentum=0.6)(encoder_last_h)\n",
        "encoder_last_c = BatchNormalization(momentum=0.6)(encoder_last_c)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoeqIgsvVgNP",
        "outputId": "f59fe191-9719-4761-bca7-5bf139e947af"
      },
      "source": [
        "decoder_input = RepeatVector(output_train.shape[1])(encoder_last_h)\n",
        "print(decoder_input)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 100), dtype=tf.float32, name=None), name='repeat_vector_1/Tile:0', description=\"created by layer 'repeat_vector_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdSIRMG_ViZR",
        "outputId": "7ebc3287-1a68-4317-9138-c9f3a76a8760"
      },
      "source": [
        "decoder_stack_h = LSTM(n_hidden, activation='elu', dropout=0.2, recurrent_dropout=0.2,\n",
        " return_state=False, return_sequences=True)(\n",
        " decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
        "print(decoder_stack_h)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 100), dtype=tf.float32, name=None), name='lstm_3/transpose_1:0', description=\"created by layer 'lstm_3'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RDldd8cVidj",
        "outputId": "1c83a103-4388-494e-834d-bde2f3de12b1"
      },
      "source": [
        "attention = dot([decoder_stack_h, encoder_stack_h], axes=[2, 2])\n",
        "attention = Activation('softmax')(attention)\n",
        "print(attention)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 10), dtype=tf.float32, name=None), name='activation_1/Softmax:0', description=\"created by layer 'activation_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCApwHtJVigr",
        "outputId": "edf4cd3e-d556-42d0-bf54-c2b7127b7bc3"
      },
      "source": [
        "context = dot([attention, encoder_stack_h], axes=[2,1])\n",
        "context = BatchNormalization(momentum=0.6)(context)\n",
        "print(context)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 100), dtype=tf.float32, name=None), name='batch_normalization_5/batchnorm/add_1:0', description=\"created by layer 'batch_normalization_5'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHoUzButVpIE",
        "outputId": "f24c3825-eb9e-444e-f00f-503f6c2097f9"
      },
      "source": [
        "decoder_combined_context = concatenate([context, decoder_stack_h])\n",
        "print(decoder_combined_context)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 200), dtype=tf.float32, name=None), name='concatenate_1/concat:0', description=\"created by layer 'concatenate_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUsoNHDmVpLD",
        "outputId": "8eeffc26-2fe0-48f5-9713-5551d073db71"
      },
      "source": [
        "out = TimeDistributed(Dense(output_train.shape[2]))(decoder_combined_context)\n",
        "print(out)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 10, 155), dtype=tf.float32, name=None), name='time_distributed_1/Reshape_1:0', description=\"created by layer 'time_distributed_1'\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3Y7topTVpQS",
        "outputId": "7a9eb078-7d87-4ee8-be43-0d99c9c58a65"
      },
      "source": [
        "model = Model(inputs=input_train, outputs=out)\n",
        "opt = Adam(lr=0.01, clipnorm=1)\n",
        "model.compile(loss='mean_squared_error', optimizer=opt, metrics=['mae'])\n",
        "model.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 10, 140)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 10, 100), (N 96400       input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 100)          400         lstm_2[0][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_1 (RepeatVector)  (None, 10, 100)      0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 100)          400         lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 10, 100)      80400       repeat_vector_1[0][0]            \n",
            "                                                                 batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dot_2 (Dot)                     (None, 10, 10)       0           lstm_3[0][0]                     \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 10, 10)       0           dot_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dot_3 (Dot)                     (None, 10, 100)      0           activation_1[0][0]               \n",
            "                                                                 lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 10, 100)      400         dot_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10, 200)      0           batch_normalization_5[0][0]      \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 10, 155)      31155       concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 209,155\n",
            "Trainable params: 208,555\n",
            "Non-trainable params: 600\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6A_HLHKVijT",
        "outputId": "819f79f7-dfcc-4dd6-d2a5-29e3a4ad3446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "epc = 5\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', patience=50)\n",
        "history = model.fit(train_en_pad_arr, train_cn_pad_arr, validation_split=0.2, \n",
        "                    epochs=epc, verbose=1, callbacks=[es], \n",
        "                    batch_size=100)\n",
        "train_mae = history.history['mae']\n",
        "valid_mae = history.history['val_mae']\n",
        " \n",
        "model.save('model_forecasting_seq2seq.h5')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "167/167 [==============================] - 30s 131ms/step - loss: 0.0075 - mae: 0.0244 - val_loss: 0.0062 - val_mae: 0.0139\n",
            "Epoch 2/5\n",
            "167/167 [==============================] - 21s 128ms/step - loss: 0.0062 - mae: 0.0147 - val_loss: 0.0062 - val_mae: 0.0142\n",
            "Epoch 3/5\n",
            "167/167 [==============================] - 21s 125ms/step - loss: 0.0062 - mae: 0.0142 - val_loss: 0.0062 - val_mae: 0.0140\n",
            "Epoch 4/5\n",
            "167/167 [==============================] - 21s 128ms/step - loss: 0.0061 - mae: 0.0139 - val_loss: 0.0061 - val_mae: 0.0137\n",
            "Epoch 5/5\n",
            "167/167 [==============================] - 21s 126ms/step - loss: 0.0061 - mae: 0.0138 - val_loss: 0.0061 - val_mae: 0.0137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HUynmS0fynl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY5PrcN_fQ8F",
        "outputId": "f7e832b9-fb98-4684-dfed-b140c682be9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "model.predict()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-c14c5ee82961>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: predict() missing 1 required positional argument: 'x'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHkN3ZmZfECs",
        "outputId": "2dd93f51-7817-48ac-aff7-4aed0e63e076",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_en_pad_arr[0].shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 140)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    }
  ]
}