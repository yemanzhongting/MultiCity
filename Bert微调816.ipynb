{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert微调816.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhmNU4cIqE34ijFICYvPiC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "750c88cae2e94d0884e4f53654e7c3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4cf8e70dca364002b7ad9502604b67b8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_695193db58fd4bdfa0b71ecaec4bf0de",
              "IPY_MODEL_dc137d7a5a9a46b281e30a2ed3fbd1cc",
              "IPY_MODEL_d771535a38ac42a5a6394687ef0e208f"
            ]
          }
        },
        "4cf8e70dca364002b7ad9502604b67b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "695193db58fd4bdfa0b71ecaec4bf0de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cb89d8abba3d4608ad29f0da9b39e1c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3c4c35756544150a918acb83afb87b8"
          }
        },
        "dc137d7a5a9a46b281e30a2ed3fbd1cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_67350c2078e640069339f42b5227aa9f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 519,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 519,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dcf8f99456bd4f4f9036349ecb48ca46"
          }
        },
        "d771535a38ac42a5a6394687ef0e208f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_faef522e0b3d494999c480de5f0d2254",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 519/519 [00:00&lt;00:00, 8.88kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8bcf0be3a23407f9eea6b62620bca32"
          }
        },
        "cb89d8abba3d4608ad29f0da9b39e1c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3c4c35756544150a918acb83afb87b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67350c2078e640069339f42b5227aa9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dcf8f99456bd4f4f9036349ecb48ca46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "faef522e0b3d494999c480de5f0d2254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8bcf0be3a23407f9eea6b62620bca32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ff6399b50f24f4ab5c4ba2cfbafc3d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9958def048a34e139a6b8a167119ce86",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d72bf85e43b2436ab131934cfff6e3a0",
              "IPY_MODEL_dc0292f9d6c34cbba4d8bb2564ec37c4",
              "IPY_MODEL_a616130f5b52496e8886eecadd607a46"
            ]
          }
        },
        "9958def048a34e139a6b8a167119ce86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d72bf85e43b2436ab131934cfff6e3a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91b90c99ee0c4f259cd4aacc12eac0b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_35688aa6efda47bb8bd4e169f80b3972"
          }
        },
        "dc0292f9d6c34cbba4d8bb2564ec37c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4cc75987f0e04cdca85891bc4599361a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 93479,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 93479,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a959a96271549258218ec969213b966"
          }
        },
        "a616130f5b52496e8886eecadd607a46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ea4bfc4c349e44f0b07836eecb1af66a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 93.5k/93.5k [00:00&lt;00:00, 1.35MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_993d0247c45846fc8193ac19f264840f"
          }
        },
        "91b90c99ee0c4f259cd4aacc12eac0b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "35688aa6efda47bb8bd4e169f80b3972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cc75987f0e04cdca85891bc4599361a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a959a96271549258218ec969213b966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea4bfc4c349e44f0b07836eecb1af66a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "993d0247c45846fc8193ac19f264840f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb52dd50162b4b74953296400b95f0e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5385da35666f44eaa073614b7550dc77",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ec0fb81585f74eb1ae11f45081bea745",
              "IPY_MODEL_a13520915d5e47a19a9972c105c6b6f9",
              "IPY_MODEL_db2cd97170f645b3a62857c2952bc4b8"
            ]
          }
        },
        "5385da35666f44eaa073614b7550dc77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec0fb81585f74eb1ae11f45081bea745": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_97b2a893bd7b44c1b5477f7078ca30b4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07293e97380f4f8fafd8c10eeb8eac4c"
          }
        },
        "a13520915d5e47a19a9972c105c6b6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6fedbd288eec45ecbb2bbec415561bb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 418326249,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 418326249,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fefd8020b299405d9a885f3ecdbd6332"
          }
        },
        "db2cd97170f645b3a62857c2952bc4b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_683c156072b2471faf1621d05113ad76",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 418M/418M [00:09&lt;00:00, 46.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_532303f99f3847dca2ee0068ed4adf21"
          }
        },
        "97b2a893bd7b44c1b5477f7078ca30b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07293e97380f4f8fafd8c10eeb8eac4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fedbd288eec45ecbb2bbec415561bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fefd8020b299405d9a885f3ecdbd6332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "683c156072b2471faf1621d05113ad76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "532303f99f3847dca2ee0068ed4adf21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/MultiCity/blob/main/Bert%E5%BE%AE%E8%B0%83816.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sATgqeK9f2BY",
        "outputId": "21b2ac82-99b9-4210-f1a6-775a1069252c"
      },
      "source": [
        "!pip install opencc-python-reimplemented"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencc-python-reimplemented\n",
            "  Downloading opencc-python-reimplemented-0.1.6.tar.gz (484 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 29.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 20 kB 32.6 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 40 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 51 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 61 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 71 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████                          | 92 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 102 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 112 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 122 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 133 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 143 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 153 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 163 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 174 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 184 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 194 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 204 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 215 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 225 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 235 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 245 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 256 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 266 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 276 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 286 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 296 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 307 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 317 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 327 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 337 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 348 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 358 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 368 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 378 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 389 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 399 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 409 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 419 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 430 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 440 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 450 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 460 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 471 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 481 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 484 kB 8.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: opencc-python-reimplemented\n",
            "  Building wheel for opencc-python-reimplemented (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencc-python-reimplemented: filename=opencc_python_reimplemented-0.1.6-py2.py3-none-any.whl size=486150 sha256=05f7a492da3a8b166d6a266184c45ad1efc661309b1cf91fa91a8b740d18984e\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/e2/60/d062d260be08788bb389521544a8fc173de9a9a78d6a593344\n",
            "Successfully built opencc-python-reimplemented\n",
            "Installing collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8CxHzb1gROO",
        "outputId": "189dff71-a404-4ea0-dc12-95def18a1278"
      },
      "source": [
        "from opencc import OpenCC\n",
        "a = '我是中國人'\n",
        "b = OpenCC('s2t').convert(a)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "我是中國人\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5XDAkCArMVU"
      },
      "source": [
        "开始调试"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYXl-KPhhAkz",
        "outputId": "426f171a-f941-41ba-caa7-6db9368ef211"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.12\n",
            "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 71.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBssHUpihDJ0",
        "outputId": "55890a74-4923-4d12-cb7c-f76e69bff381"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "SEED = 123\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "WEIGHT_DECAY = 1e-2\n",
        "EPSILON = 1e-8\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f54d83a5b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dMlHw3dhZ8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "4b698e17-b8a6-4d9c-96ca-740cff2665bf"
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('/content/筛选500-20210818.csv',encoding='utf_8_sig')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xuhao</th>\n",
              "      <th>fenlei</th>\n",
              "      <th>leibie</th>\n",
              "      <th>title</th>\n",
              "      <th>juzi</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>案晁公武《读书志》曰：王冰谓《灵枢》即《汉志·黄帝内经》十八卷之九，或谓好事者於皇甫谧所集《...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>又李濂《医史》载元吕复《群经古方论》曰：《内经》，《灵枢》，汉、隋、唐志皆不录，隋有《针经》...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>或谓王冰以《九灵》更名为《灵枢》，又谓《九灵》尤详於针，故皇甫谧名之为《针经》。</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>苟一经而二名，不应《唐志》别出《针经》十二卷，是《灵枢》不及《素问》之古，宋、元人已言之矣。</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>近时杭世骏《道古堂集》亦有《灵枢经跋》， 曰《七略》、《汉·艺文志·黄帝内经》十八篇，皇甫谧...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   xuhao fenlei  ... label Unnamed: 6\n",
              "0     22    医家类  ...     d        NaN\n",
              "1     23    医家类  ...     d        NaN\n",
              "2     24    医家类  ...     d        NaN\n",
              "3     25    医家类  ...     d        NaN\n",
              "4     26    医家类  ...     d        NaN\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "oIHXmh_QhmS7",
        "outputId": "c4d9f889-6a00-44f8-f41b-902974d7205a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xuhao</th>\n",
              "      <th>fenlei</th>\n",
              "      <th>leibie</th>\n",
              "      <th>title</th>\n",
              "      <th>juzi</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《金匮要略论注》·二十四卷（通行本）</td>\n",
              "      <td>是书亦名《金匮玉函经》，乃晋高平王叔和所编次。</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>146</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《肘後备急方》·八卷（浙江范懋柱家天一阁藏本）</td>\n",
              "      <td>是书初名《肘後卒救方》，梁陶宏景补其阙漏，得一百一首，为《肘後百一方》。</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《肘後备急方》·八卷（浙江范懋柱家天一阁藏本）</td>\n",
              "      <td>金杨用道又取唐慎微证类本草诸方附於肘後随证之下，为《附广肘後方》。</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>219</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《千金要方》·九十三卷（两淮马裕家藏本）</td>\n",
              "      <td>思邈尝谓人命至重，贵於千金，一方济之，德逾於此。</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>220</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《千金要方》·九十三卷（两淮马裕家藏本）</td>\n",
              "      <td>故所著方书以千金名。</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   xuhao fenlei  ...                                  juzi label\n",
              "0    100    医家类  ...               是书亦名《金匮玉函经》，乃晋高平王叔和所编次。     a\n",
              "1    146    医家类  ...  是书初名《肘後卒救方》，梁陶宏景补其阙漏，得一百一首，为《肘後百一方》。     a\n",
              "2    147    医家类  ...     金杨用道又取唐慎微证类本草诸方附於肘後随证之下，为《附广肘後方》。     a\n",
              "3    219    医家类  ...              思邈尝谓人命至重，贵於千金，一方济之，德逾於此。     a\n",
              "4    220    医家类  ...                            故所著方书以千金名。     a\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeinP3lYiVrH"
      },
      "source": [
        "sentence,label=df['juzi'].values.tolist(),df['label'].values.tolist()\n",
        "# readfile('hotel/pos.txt'), readfile('hotel/neg.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187,
          "referenced_widgets": [
            "750c88cae2e94d0884e4f53654e7c3b6",
            "4cf8e70dca364002b7ad9502604b67b8",
            "695193db58fd4bdfa0b71ecaec4bf0de",
            "dc137d7a5a9a46b281e30a2ed3fbd1cc",
            "d771535a38ac42a5a6394687ef0e208f",
            "cb89d8abba3d4608ad29f0da9b39e1c8",
            "b3c4c35756544150a918acb83afb87b8",
            "67350c2078e640069339f42b5227aa9f",
            "dcf8f99456bd4f4f9036349ecb48ca46",
            "faef522e0b3d494999c480de5f0d2254",
            "d8bcf0be3a23407f9eea6b62620bca32",
            "0ff6399b50f24f4ab5c4ba2cfbafc3d7",
            "9958def048a34e139a6b8a167119ce86",
            "d72bf85e43b2436ab131934cfff6e3a0",
            "dc0292f9d6c34cbba4d8bb2564ec37c4",
            "a616130f5b52496e8886eecadd607a46",
            "91b90c99ee0c4f259cd4aacc12eac0b4",
            "35688aa6efda47bb8bd4e169f80b3972",
            "4cc75987f0e04cdca85891bc4599361a",
            "0a959a96271549258218ec969213b966",
            "ea4bfc4c349e44f0b07836eecb1af66a",
            "993d0247c45846fc8193ac19f264840f",
            "fb52dd50162b4b74953296400b95f0e9",
            "5385da35666f44eaa073614b7550dc77",
            "ec0fb81585f74eb1ae11f45081bea745",
            "a13520915d5e47a19a9972c105c6b6f9",
            "db2cd97170f645b3a62857c2952bc4b8",
            "97b2a893bd7b44c1b5477f7078ca30b4",
            "07293e97380f4f8fafd8c10eeb8eac4c",
            "6fedbd288eec45ecbb2bbec415561bb5",
            "fefd8020b299405d9a885f3ecdbd6332",
            "683c156072b2471faf1621d05113ad76",
            "532303f99f3847dca2ee0068ed4adf21"
          ]
        },
        "id": "0yGmbp-piOi_",
        "outputId": "ee7c0096-3d23-4dab-be2b-58aeef4f7f5a"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ethanyt/guwenbert-base\")\n",
        "\n",
        "model = AutoModel.from_pretrained(\"ethanyt/guwenbert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "750c88cae2e94d0884e4f53654e7c3b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/519 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ff6399b50f24f4ab5c4ba2cfbafc3d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/93.5k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb52dd50162b4b74953296400b95f0e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/418M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ethanyt/guwenbert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "so1575Jbhs7q",
        "outputId": "709f0b50-1e64-4209-e6ae-9b39917e68e4"
      },
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-chinese', cache_dir=\"E:/transformer_file/\")\n",
        "print(sentence[2])\n",
        "print(tokenizer.tokenize(sentence[2]))\n",
        "print(tokenizer.encode(sentence[2]))\n",
        "print(tokenizer.convert_ids_to_tokens(tokenizer.encode(sentence[2])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "或谓王冰以《九灵》更名为《灵枢》，又谓《九灵》尤详於针，故皇甫谧名之为《针经》。\n",
            "['或', '谓', '王', '冰', '以', '《', '九', '灵', '》', '更', '名', '为', '《', '灵', '枢', '》', '，', '又', '谓', '《', '九', '灵', '》', '尤', '详', '於', '针', '，', '故', '皇', '甫', '谧', '名', '之', '为', '《', '针', '经', '》', '。']\n",
            "[0, 171, 92, 45, 1421, 8, 184, 152, 521, 185, 363, 74, 9, 184, 521, 1450, 185, 5, 60, 92, 184, 152, 521, 185, 884, 824, 5812, 1828, 5, 40, 274, 1102, 3818, 74, 6, 9, 184, 1828, 124, 185, 4, 2]\n",
            "['[CLS]', '或', '谓', '王', '冰', '以', '《', '九', '灵', '》', '更', '名', '为', '《', '灵', '枢', '》', '，', '又', '谓', '《', '九', '灵', '》', '尤', '详', '於', '针', '，', '故', '皇', '甫', '谧', '名', '之', '为', '《', '针', '经', '》', '。', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fygFi_XhZAe",
        "outputId": "83783ee9-2029-4a71-b7b2-57821b617fe3"
      },
      "source": [
        "#将每一句转成数字（大于126做截断，小于126做PADDING，加上首尾两个标识，长度总共等于128）\n",
        "def convert_text_to_token(tokenizer, sentence, limit_size=126):\n",
        "\n",
        "    tokens = tokenizer.encode(sentence[:limit_size])  #直接截断\n",
        "    if len(tokens) < limit_size + 2:                  #补齐（pad的索引号就是0）\n",
        "        tokens.extend([0] * (limit_size + 2 - len(tokens)))\n",
        "    return tokens\n",
        "\n",
        "input_ids = [convert_text_to_token(tokenizer, sen) for sen in sentence]\n",
        "\n",
        "input_tokens = torch.tensor(input_ids)\n",
        "print(input_tokens.shape)                    #torch.Size([10000, 128])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5226, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFniCw-Ei8wQ"
      },
      "source": [
        "#建立mask\n",
        "def attention_masks(input_ids):\n",
        "    atten_masks = []\n",
        "    for seq in input_ids:\n",
        "        seq_mask = [float(i>0) for i in seq]\n",
        "        atten_masks.append(seq_mask)\n",
        "    return atten_masks\n",
        "\n",
        "atten_masks = attention_masks(input_ids)\n",
        "attention_tokens = torch.tensor(atten_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqLuWjKSkZIQ",
        "outputId": "11da5678-d878-4818-f29b-fadc0ee4c5e3"
      },
      "source": [
        "set(label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a', 'b', 'c', 'd', 'e', 'f'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ptmANWhk2lQ"
      },
      "source": [
        "map_class = {\n",
        "    'a':0, 'b':1, 'c':2, 'd':3, 'e':4, 'f':5}\n",
        "df['类别'] = df['label'].map(map_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srQnMNDolXRb"
      },
      "source": [
        "import numpy as np\n",
        "labels=df['类别'].values.tolist()\n",
        "targets = np.array(labels).reshape(-1, 1)   #(10000, 1)\n",
        "total_targets = torch.tensor(targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOtFemvJljQK",
        "outputId": "23a4e7df-cbab-4c25-8b59-b59ce74f0eda"
      },
      "source": [
        "total_targets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5226, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-x_Vc6DzjHf-",
        "outputId": "5bd751ed-79fd-4e5f-fd50-94f8eeeea348"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_tokens, total_targets, random_state=66, test_size=0.1)\n",
        "train_masks, test_masks, _, _ = train_test_split(attention_tokens, input_tokens, random_state=66, test_size=0.1)\n",
        "print(train_inputs.shape, test_inputs.shape)      #torch.Size([8000, 128]) torch.Size([2000, 128])\n",
        "print(train_masks.shape)                          #torch.Size([8000, 128])和train_inputs形状一样\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_masks[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4703, 128]) torch.Size([523, 128])\n",
            "torch.Size([4703, 128])\n",
            "tensor([   0,   60,   12,  160,  117,  470,   15,   74,   16,    5, 2928, 6743,\n",
            "        6726,  157,  791,  911, 4662,  106,    5,  263, 5821,  228,  640,    5,\n",
            "        3464, 6621,  408, 1074,    4,    2,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "tensor([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2In6YNSOlsXO"
      },
      "source": [
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSW1cz1Dl4ou",
        "outputId": "1beb667a-7234-46bf-979b-ac819f53cc6d"
      },
      "source": [
        "for i, (train, mask, label) in enumerate(train_dataloader):\n",
        "     print(train.shape, mask.shape, label.shape)               #torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 1])\n",
        "     break\n",
        "print('len(train_dataloader)=', len(train_dataloader))        #500"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 1])\n",
            "len(train_dataloader)= 294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-quJtByqpA-s",
        "outputId": "0016a6d3-075f-4d52-f39d-0c654a428ead"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ethanyt/guwenbert-base\")\n",
        "model = AutoModel.from_pretrained(\"ethanyt/guwenbert-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at ethanyt/guwenbert-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xb1P8IByl-Cm",
        "outputId": "96dfaccc-9d69-4f8d-806c-866c61d98206"
      },
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels = 2)     #num_labels表示2个分类，好评和差评\n",
        "model = BertForSequenceClassification.from_pretrained(\"ethanyt/guwenbert-base\", num_labels =6)  \n",
        "device = torch.device(\"cuda\")#\"cuda\" if torch.cuda.is_available() else \n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using a model of type roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at ethanyt/guwenbert-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.weight', 'lm_head.decoder.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.weight', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.1.output.dense.weight', 'lm_head.decoder.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.11.intermediate.dense.bias', 'lm_head.bias', 'roberta.encoder.layer.10.attention.self.key.bias', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at ethanyt/guwenbert-base and are newly initialized: ['encoder.layer.10.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.4.output.dense.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'pooler.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.query.weight', 'classifier.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'pooler.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'embeddings.LayerNorm.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'embeddings.LayerNorm.bias', 'classifier.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(23292, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfUyLqGGpTNq"
      },
      "source": [
        "# # model = BertForSequenceClassification.from_pretrained(\"bert-base-chinese\", num_labels = 2)     #num_labels表示2个分类，好评和差评\n",
        "# model = BertForSequenceClassification.from_pretrained(\"ethanyt/guwenbert-base\", num_labels =6)  \n",
        "# device = torch.device(\"cuda\",0)#\"cuda\" if torch.cuda.is_available() else \n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqsEVMXwmTFg"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = LEARNING_RATE, eps = EPSILON)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJQLM9jQmZG_"
      },
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': WEIGHT_DECAY},\n",
        "        {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr = LEARNING_RATE, eps = EPSILON)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lACgGrJGmd1G"
      },
      "source": [
        "def binary_acc(preds, labels):      #preds.shape=(16, 2) labels.shape=torch.Size([16, 1])\n",
        "  # print('pred is')\n",
        "  # print(preds)\n",
        "  # print(labels)\n",
        "\n",
        "#   tensor([[-0.6207, -0.5117,  0.2221,  0.7096,  0.5865,  0.1338],\n",
        "#         [-0.6637, -0.1734,  0.0489,  0.5567,  0.4895,  0.1555],\n",
        "#         [-0.7304,  0.1899,  0.0502,  0.1732,  0.5673, -0.0090],\n",
        "#         [-0.6466, -0.4081,  0.0429,  0.7352,  0.5475,  0.1929],\n",
        "#         [-0.5700, -0.9003,  0.3235,  1.0641,  0.5718,  0.1983],\n",
        "#         [-0.5476, -0.8967,  0.2668,  1.1331,  0.6050,  0.1603],\n",
        "#         [-0.7848,  0.9896,  0.5479, -0.6765,  0.0710, -0.4884],\n",
        "#         [-0.7449,  0.3604, -0.0929,  0.1121,  0.5175,  0.0084],\n",
        "#         [-0.5131, -0.0384, -0.1605,  0.5261,  0.6951, -0.0636],\n",
        "#         [-0.5233, -0.8732,  0.2598,  1.1383,  0.6104,  0.1456],\n",
        "#         [-0.7705,  0.7923,  0.7255, -0.5743,  0.0851, -0.5042],\n",
        "#         [-0.4873, -0.9013,  0.2035,  1.1127,  0.6868,  0.1336],\n",
        "#         [-0.7950,  0.9261,  0.5125, -0.6366,  0.0999, -0.4297],\n",
        "#         [-0.7784,  1.2285, -0.1008, -0.4990,  0.1477, -0.3198],\n",
        "#         [-0.5900,  0.3439, -0.2164,  0.1100,  0.8683, -0.2011],\n",
        "#         [-0.5321, -0.9551,  0.4726,  0.9874,  0.5740,  0.1277]],\n",
        "#        device='cuda:0')\n",
        "# tensor([[5],\n",
        "#         [5],\n",
        "#         [2],\n",
        "#         [5],\n",
        "#         [2],\n",
        "#         [3],\n",
        "#         [2],\n",
        "#         [5],\n",
        "#         [0],\n",
        "#         [5],\n",
        "#         [2],\n",
        "#         [4],\n",
        "#         [2],\n",
        "#         [1],\n",
        "#         [4],\n",
        "#         [2]], device='cuda:0')\n",
        "\n",
        "  correct = torch.eq(torch.max(preds, dim=1)[1], labels.flatten()).float()      #eq里面的两个参数的shape=torch.Size([16])    \n",
        "  acc = correct.sum().item() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnSZbuBCmibv"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "def format_time(elapsed):    \n",
        "    elapsed_rounded = int(round((elapsed)))    \n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))   #返回 hh:mm:ss 形式的时间"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmFqjN5LmmPf"
      },
      "source": [
        "def train(model, optimizer):\n",
        "    t0 = time.time()\n",
        "    avg_loss, avg_acc = [],[]\n",
        "\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # 每隔40个batch 输出一下所用时间.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
        "\n",
        "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "        loss, logits = output[0], output[1]\n",
        "\n",
        "        avg_loss.append(loss.item())\n",
        "\n",
        "        acc = binary_acc(logits, b_labels)\n",
        "        avg_acc.append(acc)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clip_grad_norm_(model.parameters(), 1.0)      #大于1的梯度将其设为1.0, 以防梯度爆炸\n",
        "        optimizer.step()              #更新模型参数\n",
        "        scheduler.step()              #更新learning rate\n",
        "\n",
        "    avg_acc = np.array(avg_acc).mean()\n",
        "    avg_loss = np.array(avg_loss).mean()\n",
        "    return avg_loss, avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjNAwlw5mn1O"
      },
      "source": [
        "def evaluate(model):\n",
        "    avg_acc = []\n",
        "    model.eval()         #表示进入测试模式\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_dataloader:\n",
        "            b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
        "\n",
        "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
        "\n",
        "            acc = binary_acc(output[0], b_labels)\n",
        "            avg_acc.append(acc)\n",
        "    avg_acc = np.array(avg_acc).mean()\n",
        "    return avg_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqeZGwCavoJV"
      },
      "source": [
        "epochs = 10\n",
        "# training steps 的数量: [number of batches] x [number of epochs].\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# 设计 learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeECDSGPljn-",
        "outputId": "f3b4854f-3881-4124-830d-6b49602e498a"
      },
      "source": [
        "model"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(23292, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pPPnFQ2bmsmH",
        "outputId": "a6dcc54d-5c74-4878-e5d5-9432ca258e6d"
      },
      "source": [
        "for epoch in range(6):\n",
        "    train_loss, train_acc = train(model, optimizer)\n",
        "    print('epoch={},训练准确率={}，损失={}'.format(epoch, train_acc, train_loss))\n",
        "    test_acc = evaluate(model)\n",
        "    print(\"epoch={},测试准确率={}\".format(epoch, test_acc))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Batch    40  of    294.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    294.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    294.    Elapsed: 0:00:54.\n",
            "  Batch   160  of    294.    Elapsed: 0:01:12.\n",
            "  Batch   200  of    294.    Elapsed: 0:01:30.\n",
            "  Batch   240  of    294.    Elapsed: 0:01:48.\n",
            "  Batch   280  of    294.    Elapsed: 0:02:06.\n",
            "epoch=0,训练准确率=0.8702947845804989，损失=0.3887704238295555\n",
            "epoch=0,测试准确率=0.684745179063361\n",
            "  Batch    40  of    294.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    294.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    294.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    294.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    294.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    294.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    294.    Elapsed: 0:02:07.\n",
            "epoch=1,训练准确率=0.8668934240362812，损失=0.39554604483755673\n",
            "epoch=1,测试准确率=0.684745179063361\n",
            "  Batch    40  of    294.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    294.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    294.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    294.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    294.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    294.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    294.    Elapsed: 0:02:07.\n",
            "epoch=2,训练准确率=0.8658304988662132，损失=0.3982192394228614\n",
            "epoch=2,测试准确率=0.684745179063361\n",
            "  Batch    40  of    294.    Elapsed: 0:00:18.\n",
            "  Batch    80  of    294.    Elapsed: 0:00:36.\n",
            "  Batch   120  of    294.    Elapsed: 0:00:55.\n",
            "  Batch   160  of    294.    Elapsed: 0:01:13.\n",
            "  Batch   200  of    294.    Elapsed: 0:01:31.\n",
            "  Batch   240  of    294.    Elapsed: 0:01:49.\n",
            "  Batch   280  of    294.    Elapsed: 0:02:07.\n",
            "epoch=3,训练准确率=0.8635062358276644，损失=0.39093485608899675\n",
            "epoch=3,测试准确率=0.684745179063361\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-8f5adc9f834d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch={},训练准确率={}，损失={}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch={},测试准确率={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-89165c29e5fc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m#大于1的梯度将其设为1.0, 以防梯度爆炸\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m#更新模型参数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m#更新learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             raise RuntimeError(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTXFgJBfn1tO",
        "outputId": "36f9f7c6-84ba-4fe6-fcb2-88fa29153627"
      },
      "source": [
        "model"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(23292, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1VlPSqcnFN0"
      },
      "source": [
        "#定义两个数组\n",
        "Loss_list = []\n",
        "Accuracy_list = []\n",
        "\n",
        "Loss_list.append(train_loss / (len(train_dataset)))\n",
        "Accuracy_list.append(100 * train_acc / (len(train_dataset)))\n",
        "\n",
        "#我这里迭代了200次，所以x的取值范围为(0，200)，然后再将每次相对应的准确率以及损失率附在x上\n",
        "x1 = range(0, 200)\n",
        "x2 = range(0, 200)\n",
        "y1 = Accuracy_list\n",
        "y2 = Loss_list\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(x1, y1, 'o-')\n",
        "plt.title('Test accuracy vs. epoches')\n",
        "plt.ylabel('Test accuracy')\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(x2, y2, '.-')\n",
        "plt.xlabel('Test loss vs. epoches')\n",
        "plt.ylabel('Test loss')\n",
        "plt.show()\n",
        "plt.savefig(\"accuracy_loss.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JvgM6gTmE7A"
      },
      "source": [
        "torch.save({'epoch': epochID + 1, 'state_dict': model.state_dict(), 'best_loss': lossMIN,\n",
        "                            'optimizer': optimizer.state_dict(),'alpha': loss.alpha, 'gamma': loss.gamma},\n",
        "                           checkpoint_path + '/m-' + launchTimestamp + '-' + str(\"%.4f\" % lossMIN) + '.pth.tar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yAqHELogTPv"
      },
      "source": [
        "atten_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR3YwEf_muO_"
      },
      "source": [
        "def predict(sen):\n",
        "\n",
        "    input_id = convert_text_to_token(tokenizer, sen)\n",
        "    input_token =  torch.tensor(input_id).long().to(device)            #torch.Size([128])\n",
        "\n",
        "    atten_mask = [float(i>0) for i in input_id]\n",
        "    attention_token = torch.tensor(atten_mask).long().to(device)       #torch.Size([128])\n",
        "\n",
        "    output = model(input_token.view(1, -1), token_type_ids=None, attention_mask=attention_token.view(1, -1))     #torch.Size([128])->torch.Size([1, 128])否则会报错\n",
        "    # print(output[0])\n",
        "    # tensor([[-0.1717, -3.0720, -1.0502,  2.4945,  2.9568,  0.8045]],\n",
        "    #    device='cuda:0', grad_fn=<AddmmBackward>)\n",
        "\n",
        "    return torch.max(output[0], dim=1)[1]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOclN7Uwtnbe"
      },
      "source": [
        "tf=pd.read_csv('/content/结果-20210808.csv',encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "4KQJh_O7tuH5",
        "outputId": "a4e2f8f2-9bfe-41db-e16f-5f24f613f028"
      },
      "source": [
        "tf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xuhao</th>\n",
              "      <th>fenlei</th>\n",
              "      <th>leibie</th>\n",
              "      <th>title</th>\n",
              "      <th>juzi</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>唐王冰注。</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>《汉书·艺文志》载《黄帝内经》十八篇，无《素问》之名。</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>後汉张机《伤寒论》引之，始称《素问》。</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>晋皇甫谧《甲乙经序》，称《针经》九卷，《素问》九卷，皆为《内经》，与《汉志》十八篇之数合，则...</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>故《隋书·经籍志》始著录也，然《隋志》所载只八卷，全元起所注已阙其第七。</td>\n",
              "      <td>b,d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   xuhao fenlei  ...                                               juzi label\n",
              "0      0    医家类  ...                                              唐王冰注。     b\n",
              "1      1    医家类  ...                        《汉书·艺文志》载《黄帝内经》十八篇，无《素问》之名。     d\n",
              "2      2    医家类  ...                                後汉张机《伤寒论》引之，始称《素问》。     d\n",
              "3      3    医家类  ...  晋皇甫谧《甲乙经序》，称《针经》九卷，《素问》九卷，皆为《内经》，与《汉志》十八篇之数合，则...     d\n",
              "4      4    医家类  ...               故《隋书·经籍志》始著录也，然《隋志》所载只八卷，全元起所注已阙其第七。   b,d\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5npN0hyt3Li"
      },
      "source": [
        "def get_label(juzi):\n",
        "  try:\n",
        "    label = predict(juzi)\n",
        "    if label==0:\n",
        "      return 'a'\n",
        "    if label==1:\n",
        "      return 'b'\n",
        "    if label==2:\n",
        "      return 'c'\n",
        "    if label==3:\n",
        "      return 'd'\n",
        "    if label==4:\n",
        "      return 'e'\n",
        "    if label==5:\n",
        "      return 'f'\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return \"\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "lhbwRCHsn8XY",
        "outputId": "246c18f0-f51e-497e-e6e0-7134c72cbf65"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xuhao</th>\n",
              "      <th>fenlei</th>\n",
              "      <th>leibie</th>\n",
              "      <th>title</th>\n",
              "      <th>juzi</th>\n",
              "      <th>label</th>\n",
              "      <th>Unnamed: 6</th>\n",
              "      <th>类别</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>案晁公武《读书志》曰：王冰谓《灵枢》即《汉志·黄帝内经》十八卷之九，或谓好事者於皇甫谧所集《...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>23</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>又李濂《医史》载元吕复《群经古方论》曰：《内经》，《灵枢》，汉、隋、唐志皆不录，隋有《针经》...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>或谓王冰以《九灵》更名为《灵枢》，又谓《九灵》尤详於针，故皇甫谧名之为《针经》。</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>苟一经而二名，不应《唐志》别出《针经》十二卷，是《灵枢》不及《素问》之古，宋、元人已言之矣。</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>26</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《灵枢经》·十二卷（大理寺卿陆锡熊家藏本）</td>\n",
              "      <td>近时杭世骏《道古堂集》亦有《灵枢经跋》， 曰《七略》、《汉·艺文志·黄帝内经》十八篇，皇甫谧...</td>\n",
              "      <td>d</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   xuhao fenlei           leibie  ... label Unnamed: 6 类别\n",
              "0     22    医家类  ●卷一百三·子部十三●医家类一  ...     d        NaN  3\n",
              "1     23    医家类  ●卷一百三·子部十三●医家类一  ...     d        NaN  3\n",
              "2     24    医家类  ●卷一百三·子部十三●医家类一  ...     d        NaN  3\n",
              "3     25    医家类  ●卷一百三·子部十三●医家类一  ...     d        NaN  3\n",
              "4     26    医家类  ●卷一百三·子部十三●医家类一  ...     d        NaN  3\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lFVWLeMHn954",
        "outputId": "e3f94655-0470-4e1d-86b4-7d15b5e40fd7"
      },
      "source": [
        "get_label(\"案晁公武《读书志》曰：王冰谓《灵枢》即《汉志·黄帝内经》十八卷之九，或谓好事者於皇甫谧所集\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'d'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xJLTWMToQKd"
      },
      "source": [
        "# 方式二：保存加载整个模型\n",
        "# 保存\n",
        "torch.save(model, 'pre')\n",
        "# 加载\n",
        "# model = torch.load(PATH)\n",
        "# model.eval()\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZUXI_FEo7lx"
      },
      "source": [
        "model = torch.load( 'pre')\n",
        "# model.eval()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWSdfKpaocWT"
      },
      "source": [
        "# 方式三：保存用于继续训练的checkpoint或者多个模型\n",
        "# 保存\n",
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            }, 'pre_check')\n",
        "# # 加载\n",
        "# checkpoint = torch.load(PATH)\n",
        "# start_epoch=checkpoint['epoch']\n",
        "# model.load_state_dict(checkpoint['model_state_dict'])\n",
        "# # 测试时\n",
        "# model.eval()\n",
        "# # 或者训练时\n",
        "# model.train()\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IPcneBooiaN",
        "outputId": "cfefe3aa-414d-43d5-d7bd-fc1bf6ed6610"
      },
      "source": [
        "model.train()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(23292, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEZ7x-6euHZC",
        "outputId": "0381261f-257b-4a05-f2b8-d712fc3d15f4"
      },
      "source": [
        "tf['pre']=tf.apply(lambda x :get_label(x['juzi']),axis=1)\n",
        "#  df.apply(lambda x: bd09towgs84(x['lng'],x['lat'])[0], axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n",
            "tensor([[ 1.0717, -1.4034, -1.7492,  0.3135,  4.7588, -1.1694]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9843,  0.3459, -1.0030, -3.7748,  3.4916, -1.0540]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8279, -2.5795, -1.4462, -0.5032,  3.5533,  0.2301]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3545,  4.9408, -1.6277, -2.6885, -1.9425,  0.1257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0339,  4.6992, -2.1089, -2.6570, -2.0846,  0.5055]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1335,  5.1731, -2.0085, -2.5353, -0.9640, -0.6864]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7559, -2.6932,  2.5218, -0.5860,  2.3561, -2.0171]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5490, -1.2217, -1.1541,  5.3560, -1.2110,  0.2977]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4504,  1.6693, -3.6087,  0.0861, -0.5485,  0.9099]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3025,  1.0573, -3.2748, -2.2800, -0.2408,  3.8047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5104, -1.9384,  1.4256, -0.5163, -1.6466, -1.0989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0383,  0.6988, -0.6425, -4.5300,  0.6786,  0.5829]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6794, -1.4146,  1.8650, -3.7727,  1.9527, -0.0476]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5852, -0.7000, -2.0543, -0.2247,  4.5403, -1.6125]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6530,  5.0505, -2.1322, -2.2725, -1.6829,  0.2603]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2308,  4.8177, -2.3009, -2.8925, -0.4968, -0.3984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4367,  4.3171, -2.7012, -3.1871, -0.2651,  0.1324]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7048,  2.1310, -1.9934,  0.5103, -2.6578,  2.0757]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8490,  0.4143, -3.0247, -1.5452,  2.7200,  0.1029]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2328, -0.6523, -1.8364, -1.2656,  2.4147,  0.8075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3409,  0.9534,  1.9986, -3.2337, -0.8802, -1.0111]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5383,  5.0283, -1.8080, -2.6497, -1.6009,  0.0934]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0190,  4.8347, -1.1835, -3.2899, -1.5041, -0.4218]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9584,  4.3793, -3.4546, -0.3150, -1.7149,  1.1756]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3745, -2.5070, -1.7283,  0.8211,  2.2268,  0.9382]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5300, -0.2450,  1.9188, -2.2922, -1.1207, -0.2187]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3202,  1.0040, -0.4784, -4.7710,  1.5030, -0.6168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8911, -1.9491,  1.9375, -0.9827, -1.0389, -0.8082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3183, -0.7612, -2.1375,  4.5391, -1.6651,  2.1660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3303,  0.1378, -1.3899,  1.2818, -3.1064,  2.8527]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1171, -0.8446, -1.8735, -1.0345, -1.7021,  4.5973]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7394, -1.1160, -0.7244, -0.7462,  1.7221, -2.3939]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7211,  5.1658, -1.8739, -2.2519, -1.6386, -0.0148]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4279,  1.9244, -3.1612,  3.4127, -0.5385, -0.8606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6581,  1.1433, -1.7396, -3.4532, -0.1599,  2.5078]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8491,  2.7337, -1.2567, -4.4940,  1.1620,  0.1582]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5372,  0.2330, -0.6218, -2.0827, -0.7497, -0.8305]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6347, -2.0793,  1.6488, -0.2152, -2.9429,  1.5735]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5062,  5.1127, -1.5830, -2.5653, -1.7047, -0.1626]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3766,  5.1345, -1.9926, -2.6733, -1.0896, -0.3167]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1113, -2.2873,  1.8729, -0.2636,  0.9853, -2.7966]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2712, -0.1188, -1.0556, -2.4440,  2.4096, -1.8100]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5641, -3.3766, -0.2231,  3.1948, -1.2406,  1.7775]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8572, -1.3567,  5.0574, -2.1930, -1.4531, -1.3789]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7574, -2.4136, -0.5722,  3.8327, -1.6197,  1.0509]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0418,  4.7040, -2.2031, -3.0092, -1.4050,  0.2985]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2167, -0.9741, -1.7588,  5.0082,  0.7974, -1.2726]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6828, -0.7856, -2.9393, -1.0418,  3.1591,  1.9399]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2682, -1.1356, -1.2717,  3.6926, -2.6945,  2.8291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1436, -1.8931, -1.2976,  5.0231,  0.9507, -0.4512]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8053, -1.6624, -1.9348,  5.1058,  0.8441,  0.4231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4831,  5.1078, -2.5288, -1.7549, -1.5944,  0.0477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0793,  4.4177, -1.5750, -3.7244, -1.2162,  0.3420]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6665, -1.0566,  5.0360, -2.2214, -2.1119, -1.0669]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2623,  4.2269, -3.6091, -1.8542,  1.0136,  0.1569]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5526,  4.4131, -1.1037, -3.1734, -1.0743, -0.9159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6549, -1.0336,  4.9550, -2.6005, -1.9770, -0.8598]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4522,  2.2678, -0.4458, -3.1767, -2.2436,  1.5382]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2090,  5.0482, -2.4841, -2.5139, -0.7550, -0.1918]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4846,  5.2051, -1.5764, -2.2270, -1.7452, -0.5698]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1603,  1.2635,  0.1449, -4.6054,  2.4341, -0.7094]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8188, -0.3221,  3.7181, -3.5824, -2.5449,  0.2990]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6336,  2.2115, -1.4469, -2.9245, -0.7918,  0.4577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1340, -0.3905, -0.7697, -1.0116, -0.8162,  2.1057]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9438,  0.6883,  1.8060, -1.9209, -1.9194, -1.1936]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5835, -1.5289, -0.2874,  5.0502, -2.2201,  0.6204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5249,  1.1628,  0.8492, -4.4265, -2.1296,  1.2257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5610,  5.1520, -1.9342, -2.4084, -1.4849, -0.0816]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8517,  4.9864, -2.7397, -1.6103, -1.6575,  0.5362]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7264,  4.0789, -3.2015, -2.5241,  0.1188,  1.3440]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8636, -1.6377,  1.8086, -2.6032, -2.4586,  2.8152]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4783,  0.0393, -0.4748,  2.2620, -3.2595,  1.8705]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1682, -0.9299, -2.5532,  1.8632, -0.3033,  3.6563]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9358,  5.0019, -2.8247, -1.3209, -1.5501,  0.4805]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0940,  5.0058, -1.5488, -2.9755, -1.2641, -0.6308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2278,  5.1578, -1.9339, -2.4130, -1.2731, -0.4763]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4593,  3.3732, -2.5030, -3.4993,  1.0393, -0.7390]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1320, -2.0101,  2.1940, -0.1141,  0.1151, -2.9095]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0547, -2.6420,  1.3723,  0.6054, -2.8060,  2.2395]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4324,  1.1462, -1.0125,  2.4396, -4.0486,  2.4103]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3812, -0.4492, -3.0529,  4.3495, -0.1611,  1.1331]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2463,  5.1766, -1.8651, -2.3666, -0.9583, -0.8135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1845,  2.5979, -2.5442,  2.7811, -2.2802, -0.4900]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1599,  0.7971,  2.0342, -3.6171, -3.0874,  1.5658]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4390,  1.3791,  1.2256, -4.6446,  0.5521, -0.7246]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3508,  1.6376,  1.9744, -3.7734, -1.4374, -0.9565]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0661, -1.2061, -1.5255, -0.3722,  4.9221, -1.1539]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8343,  4.7093, -2.9190, -2.3162, -0.6308,  0.7837]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3037,  4.4057, -2.4402, -3.4238, -0.0936,  0.0692]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5431,  3.4404,  1.3897, -2.4118, -3.0084, -1.2809]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4782, -1.9182, -1.3846,  2.2512,  4.2197, -1.4196]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8093, -1.1753, -2.0337,  5.0599,  1.4795, -0.2649]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3063, -0.4653, -3.2867, -0.2103, -0.5598,  4.2151]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6649,  0.6903, -1.1656, -3.8456,  2.0564, -0.9479]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0208,  2.0960,  1.1243, -4.2496, -0.0440, -1.7521]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2735, -0.5949,  3.0178,  2.0904, -3.4408, -0.9885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2947e-01, -9.9174e-04, -2.7280e+00, -2.1901e+00,  1.3657e-01,\n",
            "          3.8312e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5454,  0.0392, -3.6632,  0.8298,  1.8905,  2.2661]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4990, -1.9410,  0.5479,  1.1598, -2.9420,  1.6460]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4974, -1.7027, -1.7900,  4.2248, -0.9115,  2.6004]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6225,  4.9786, -2.2656, -2.4515, -1.4999,  0.4320]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3467,  4.6936, -1.2712, -3.3632, -1.4910, -0.4526]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0307, -0.5829,  3.2151, -2.5732, -0.4958, -1.8678]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4191, -0.5079,  0.0585, -2.6502,  4.2588, -1.4412]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2705, -1.4521,  0.1536, -2.2290,  4.1150, -1.9376]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8507, -3.2104,  0.4117, -2.1817,  2.1452,  1.3859]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4694,  2.4450, -3.5237, -3.0583,  0.6800,  0.9630]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0869e+00, -3.3790e+00,  3.7221e-01,  8.8408e-01,  4.6282e-04,\n",
            "         -6.3211e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6903,  3.6037, -1.5707, -4.1318, -0.3481,  0.1447]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2785, -0.1646, -0.7666, -1.3855,  0.4349,  0.0058]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1517, -1.3675, -1.2879, -0.8625, -0.8907,  4.3225]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9907, -2.3771,  0.6404, -0.9910,  4.7836, -1.2252]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2981,  2.0172, -1.3892, -4.1150, -0.6912,  2.3607]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5008, -2.5585, -0.8900,  3.4191, -1.2206,  2.6912]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5333,  5.1935, -1.4741, -2.2900, -1.8018, -0.4836]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1997, -0.2599, -1.3610,  5.1577, -1.5524, -0.9404]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9187,  3.5480, -0.7016, -4.3143, -1.2305,  0.0265]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1993,  1.1341,  1.7404, -3.9093,  0.1769, -2.0116]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5241,  0.3356,  2.2456, -4.7700,  0.9928, -0.9341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5845, -2.1935, -1.0432,  1.1586,  2.3913, -1.6288]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6709,  4.1712, -1.5664, -3.4023, -1.8737,  0.2723]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3289,  4.2352, -0.6621, -4.0385, -0.8338, -0.5316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5484,  4.6990, -3.2664, -2.0735, -0.8173,  0.7246]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1533,  5.0722, -1.6152, -2.5656, -1.4347, -0.6505]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2441,  4.0048, -3.3672, -2.6240,  0.7430,  0.7453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8836, -2.5314,  4.4167, -1.2282, -0.5661, -1.9454]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2215,  1.6468,  0.6445, -2.1613, -3.5944,  1.4938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6232, -1.3238, -2.7833,  4.3960, -1.0071,  2.1124]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7630,  5.1334, -2.2484, -1.8410, -1.7420,  0.1638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2851,  5.1874, -2.1173, -2.3665, -1.3618, -0.3678]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3595,  3.7100,  0.1828, -4.1883, -1.8392, -0.1964]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7999,  1.7748, -2.7595, -3.7337,  1.5595,  1.4082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5034,  1.0526, -2.2409,  3.1309, -2.2606,  1.2365]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8995, -3.6656,  0.5992,  0.6065,  3.0226,  0.1392]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6508, -1.9579, -1.0174,  2.6259, -0.7956,  1.5397]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6880,  5.1989, -2.0665, -2.1171, -1.5634, -0.0683]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4160, -0.3992, -1.8101,  5.5733, -1.1015, -0.3712]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1539,  3.1204, -1.7284, -4.3334,  0.4893,  0.0970]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1333, -2.2334,  1.1962, -1.1085,  4.5045, -1.8767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7786, -1.0558, -1.2801,  4.8008,  1.6958, -0.8423]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4109,  1.8166, -3.9024, -1.5557,  1.7378,  1.6795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4678,  5.0848, -1.8242, -2.6055, -1.5621, -0.0647]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0583,  4.8647, -1.3081, -2.9790, -1.6359, -0.4857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3848, -0.1365, -1.8966, -1.9221,  0.3262,  2.1573]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4340,  1.7350, -0.5927, -0.8446, -2.7329,  1.8519]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1406, -0.1671, -2.5137,  2.9988, -0.1793,  1.3858]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2942,  1.2440,  1.5800, -4.6505, -1.6326,  0.4047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0578,  0.4058,  2.4963, -3.0641,  0.1583, -2.3039]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6053,  5.1650, -1.6319, -2.6121, -1.4049, -0.2385]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0074,  4.7357, -1.0690, -3.4576, -1.3965, -0.3415]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1833,  4.3957, -0.6567, -3.8144, -1.3453, -0.4593]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7141,  3.5507, -2.8425, -3.0549,  0.4604,  0.3534]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0375, -1.1084,  4.6543, -1.7140, -1.9750, -1.3738]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4873,  0.5561, -0.7533, -3.6650,  3.9357, -1.1688]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7103, -1.2558, -1.2008, -2.6001,  4.0112,  1.0614]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5321, -1.1926, -0.4893, -2.7078,  4.0351, -0.3093]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7870,  4.2914, -0.5491, -2.8337, -1.2850, -1.4393]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8072,  5.1236, -2.3915, -1.6782, -1.5206,  0.1857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2690,  4.5532, -1.2356, -3.3842, -1.3446, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9798,  2.4918, -0.7078, -3.6388,  1.5284, -1.9202]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2265,  0.9952, -0.0966, -1.6435, -2.7764,  1.1168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3825, -0.8668, -0.9917,  5.5736, -1.1536, -0.6083]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7600,  1.9228, -4.1019,  2.0119, -0.7859,  1.8474]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9624, -0.2480, -1.6966, -3.9095,  2.8364,  0.6071]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5886e+00, -2.9732e-01, -2.7894e+00,  3.5275e+00,  1.6869e-03,\n",
            "         -6.5235e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8512,  4.9822, -2.4351, -1.8160, -1.7765,  0.5542]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4893,  5.1841, -1.7405, -2.5355, -1.4743, -0.2546]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1789,  4.1459, -0.5548, -2.6235, -2.8119,  0.2108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6405,  2.4020, -3.6070, -1.6095, -0.8227,  1.8894]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0451,  2.7505,  1.2239, -4.6179, -0.6518, -1.1935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0922,  4.1907, -0.9601, -3.2470, -2.2241,  0.3260]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1253,  2.0417, -3.6870,  0.3696, -0.1332,  1.4788]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3880,  2.6515, -1.0236,  0.9260, -2.1306, -1.6600]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6064,  0.2458,  2.4943, -4.8632, -0.8692, -0.0832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9566,  2.4725,  0.3916, -4.8095, -1.4863,  0.4438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3726, -1.7990,  0.7954,  0.5700,  2.5503, -3.1171]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7221,  0.5120, -0.8115, -0.2012, -3.6628,  3.6309]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8627e-04, -3.8618e-01, -1.2857e+00,  1.2902e+00, -3.6354e+00,\n",
            "          3.3264e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3823, -1.0757, -0.5392,  0.3542, -3.0062,  2.2993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6599,  2.1982, -2.4456, -2.2504, -2.1815,  3.4590]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0473,  4.2216, -0.7246, -3.0370, -2.8167,  0.3551]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4269, -1.9124,  0.2900,  1.4547, -2.2592,  1.3538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0035,  1.3685,  1.5706, -2.3055, -3.4626,  1.2713]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8161, -1.2568,  1.2828, -0.1898,  1.5536, -3.3690]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4095, -0.2009, -0.8821, -2.7177,  1.3650,  1.1011]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2926,  4.5404, -1.9838, -3.3101, -1.3714,  0.7842]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0943, -0.2715,  2.9328, -0.4051, -4.1827, -0.1324]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8513,  0.8154, -2.3407,  0.7644, -2.2243,  3.4739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2805,  0.0675, -1.7187,  4.5443, -2.6702,  1.6204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8210,  4.9385, -2.1468, -2.0349, -1.9477,  0.6003]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6615,  4.6898, -3.2863, -1.9597, -0.6745,  0.7944]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6276,  3.7892,  0.1637, -4.2279, -1.3406, -0.6996]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7151,  0.7458, -1.9197, -0.8987,  0.8086,  0.2656]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0606, -1.7252, -0.9281,  3.7123, -0.5007,  1.0923]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5339, -0.0656,  0.8351,  1.5657, -1.8968, -1.0834]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7852,  2.9404,  0.0548, -4.2334,  0.7676, -1.1128]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7157,  5.1244, -2.3366, -1.6761, -1.8194,  0.1505]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0126,  5.0609, -1.2744, -2.6097, -1.7970, -0.7747]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0464,  4.4365, -0.3603, -3.3119, -2.1974, -0.3726]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9753, -0.3731, -0.9477, -1.7312,  3.1577, -2.4270]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7481, -0.6577,  4.8689, -2.9768, -1.4840, -1.2799]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4162,  3.4908, -1.2445, -3.6169, -2.3182,  1.1910]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5448,  5.1316, -1.9100, -2.5221, -1.4288, -0.0864]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0601,  4.9918, -1.4627, -2.9565, -1.4927, -0.5024]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2928,  4.4089, -1.3317, -3.4611, -1.6713,  0.0788]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9216,  3.1132,  0.0331, -4.6299, -1.2522, -0.0157]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6445, -1.0993, -1.9619, -0.1070,  5.0042, -0.6869]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1259, -2.8140,  0.7049, -1.3491,  1.5299,  1.5615]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6419,  0.2580, -3.4429,  1.3425, -1.1486,  2.4513]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4534,  2.1297, -3.9085, -2.2110,  1.5308,  1.4930]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1397, -2.4490, -0.7615, -1.9926,  0.6410,  3.3699]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1338, -0.7411, -3.0180,  1.1801, -1.0250,  4.3594]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7235,  5.1244, -1.9109, -2.1857, -1.7789,  0.0872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0353,  4.9937, -2.0757, -2.9073, -0.9024, -0.3969]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9091,  3.6168,  0.2162, -4.0481, -1.3221, -0.8938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8083, -2.5630,  0.4770,  0.1032,  3.9629, -2.1600]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8637, -0.4910, -0.9889, -1.8101,  5.3168, -1.5515]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2279,  1.2634, -1.2523, -2.5911,  4.2164, -2.1795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4180,  0.6082, -3.5706,  1.9264, -0.8353,  3.3595]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9606,  4.8264, -2.2105, -1.8952, -2.0895,  0.8326]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7477,  1.3211, -4.5948,  1.1543,  0.7862,  1.0096]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6766,  3.9252, -3.3950, -2.0678, -0.3060,  1.5730]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4399e-01,  4.2791e+00, -3.2805e+00, -2.3372e+00,  3.7536e-03,\n",
            "          6.5797e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0024,  1.3163, -1.4866, -1.8226, -1.0666, -0.6640]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3457,  1.6882, -1.7230, -2.2804, -2.7277,  3.5259]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2633,  1.7339, -1.2565, -2.7019, -0.0940,  0.5816]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8024, -1.5164,  4.5348, -2.1835, -2.2431, -0.1516]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6334,  0.0162, -2.0601, -3.3627,  3.0217, -0.4441]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4315,  2.0127, -0.1915, -4.4181,  1.2713, -0.7979]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9233,  0.7236,  0.4588, -4.4542,  1.8188,  0.3344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2114, -0.0233, -0.3242, -4.0078,  3.4054, -1.3394]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1179, -1.2325, -2.0615,  2.0722, -2.4698,  3.6735]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1831,  4.3019, -1.5749, -3.6798, -1.3502,  0.3861]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2817,  3.9133, -3.6781, -1.7336,  1.6174,  0.0284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8437,  4.3894, -3.1947, -2.2245, -0.7860,  1.3196]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3424,  4.8087, -2.0599, -2.8862, -0.5319, -0.7485]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8186, -0.7872,  4.9895, -2.5990, -1.3758, -1.6205]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3658, -2.2708,  1.6549,  0.2218,  2.3539, -3.1133]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4772, -0.4637, -1.9473,  5.2290, -1.4677,  1.1460]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6175, -1.8329,  1.0089,  0.4612,  2.1749, -1.6243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6952, -0.0847,  2.5373, -3.6445,  0.9406, -0.4308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4079, -2.1806, -1.2536,  3.3384, -2.3665,  2.2824]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6581,  5.1904, -2.1814, -2.0306, -1.5495, -0.0128]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3307,  4.8359, -1.5292, -3.0435, -0.4946, -1.1952]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1065,  4.1517, -1.0912, -3.7664, -1.8390,  0.7010]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2548, -1.9688,  4.9274, -0.9230, -1.7756, -1.6200]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4636, -2.3884, -1.1954,  0.4041,  3.2547, -0.0776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2942,  1.2998, -1.2644, -4.3657, -0.7428,  2.0368]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8478, -1.2424, -2.7368, -0.4486,  4.6999,  0.2595]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1547, -3.0400, -0.7968,  4.6650, -0.3549,  0.7814]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7381,  5.1964, -2.3077, -1.8570, -1.5479,  0.0359]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6700,  3.2983, -3.8406, -2.0156,  0.8612,  1.6931]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5214, -1.3473, -0.2247,  3.9076, -1.6645,  1.1700]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5808,  0.1846, -3.8814,  0.1658, -0.2206,  3.9449]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3390, -1.2252, -0.0165, -1.3549, -2.9405,  3.0225]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0583, -0.6359, -2.8682, -0.5760,  4.5427, -0.1766]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9445,  0.6049, -2.6188, -1.4137,  4.6493, -1.0241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9473,  0.2202, -3.2950, -2.6128,  3.0388,  1.4959]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3583, -2.8676,  1.2709,  0.2283,  0.1442, -1.7441]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4008,  5.0551, -1.3556, -2.6996, -1.8149, -0.2812]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1014,  4.9460, -1.2276, -3.0322, -1.2995, -0.8936]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7711, -1.2165,  5.1241, -2.4667, -1.3056, -1.3587]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3493, -0.3364, -1.2586, -2.1986,  4.8299, -1.2902]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1043, -1.9297, -1.4879,  4.1647,  1.4465,  0.1281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8684,  0.3656, -2.8136, -3.0980,  2.7444,  1.6660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5903,  0.9944, -2.6192, -3.5085,  0.0277,  2.9937]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4332,  5.0782, -1.6443, -2.6037, -1.7214, -0.1418]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2743,  5.0786, -1.4402, -2.5828, -1.9208, -0.3931]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5981, -1.2242,  1.4884, -3.6516,  3.3467, -0.8612]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8277, -1.4682,  2.4057,  0.9918, -2.5208, -0.0739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4118, -0.6947, -2.7410,  3.4019,  2.6825, -0.9111]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7772,  0.5759, -3.4305,  0.2783,  4.1750, -0.8486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5708, -0.6986, -2.6909,  1.3373,  3.6272, -1.3949]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3448, -0.9180, -3.6704,  1.2008,  1.2623,  3.0013]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4839,  5.1966, -2.0155, -2.4424, -1.1840, -0.2666]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4447,  4.9762, -3.0543, -1.6235, -0.6595, -0.0088]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5476, -0.7016,  4.9041, -2.4952, -2.2275, -0.9203]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6512, -1.0440, -0.4073, -1.2032, -1.1096,  2.0411]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7390, -2.1798,  1.0413, -0.7436,  2.8933, -2.6823]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6984,  0.4849,  1.7228, -4.0316, -0.7098, -1.2183]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4712,  5.0670, -1.9066, -2.5628, -1.6593,  0.0560]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6764,  4.9532, -2.0009, -1.4073, -2.5054,  0.2377]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4119, -1.8326,  2.3844, -2.3964,  2.4881, -2.4144]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7872, -0.6846, -3.2809,  4.6510,  0.8487,  0.9559]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8850, -0.6069, -3.0987,  1.0024, -0.1810,  2.5316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7992, -1.1719, -2.0153, -0.5579, -0.5742,  1.3025]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2376, -3.1662, -0.3994,  4.2328, -0.3311,  0.8204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0388, -0.5928, -0.5880, -2.7902,  3.7555, -1.1313]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5145,  5.1187, -1.6047, -2.5124, -1.7745, -0.1721]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3174,  4.7752, -1.4074, -3.1808, -1.5290, -0.4907]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6095,  2.4338, -1.3926, -4.6187,  0.0667,  0.4178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3564, -1.0226,  0.3088, -2.0275,  4.7868, -2.1757]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5299, -2.9544, -0.9458,  1.4961,  2.0991,  1.5058]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6429,  5.1059, -2.1292, -2.3302, -1.5327,  0.1107]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1991,  4.9011, -2.2749, -2.8024, -1.1757,  0.1413]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1208, -1.8848,  1.1474,  3.6499, -2.0157, -0.8477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9121, -1.6562,  2.6348, -2.3475, -2.8578,  2.2079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3765, -2.0540, -0.8019, -1.9201,  1.9086,  0.7879]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4091, -0.7273, -3.1854,  0.6482,  3.8526, -0.4501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7172, -2.3713, -1.1884,  0.0988,  4.1223, -0.8072]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2921,  2.2976, -4.0809, -1.6590,  1.4238,  0.4745]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5316, -1.3277, -0.6269, -1.4643,  4.9257, -1.6744]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7302,  5.0529, -1.9199, -2.3011, -1.8082,  0.2647]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7140,  1.8008, -1.9833, -1.1800,  0.7310, -1.7934]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7186, -0.3212,  1.8990, -0.5889, -3.9672,  1.1944]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3114, -0.3707, -1.5569, -1.8955,  5.0026, -1.3514]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3775, -0.1925, -0.4801, -2.6239, -1.7860,  1.5235]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3496, -0.3939, -3.8578,  2.7897,  1.8029,  0.7156]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5415,  5.1531, -2.6406, -2.0706, -0.8439, -0.0472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9032,  2.5768, -2.5601, -2.7031,  1.8639, -1.1711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5820,  4.1005, -1.9628, -3.3532,  0.7677, -0.8390]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1760, -1.1108,  1.9592, -3.8116, -0.2195,  0.2572]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7652, -2.3698,  2.5719, -2.0018,  2.3067, -1.4154]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9470,  4.7658, -2.3166, -2.3025, -1.6241,  0.9618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0177,  4.6303, -1.6490, -3.5753, -1.0002,  0.1143]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4783,  0.4502,  3.4907, -4.3416, -0.9730, -1.0493]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2726, -1.3421, -1.2146, -0.2293,  5.4584, -1.0557]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3795, -1.6248, -0.1715,  0.5306,  3.1337, -2.9159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2974,  1.8209, -2.4689, -3.8446,  0.0743,  2.5486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3208,  4.9755, -0.9046, -2.9877, -1.6811, -0.5351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0148,  5.0463, -1.4880, -2.6715, -0.6711, -1.0715]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2534,  3.9289, -0.4618, -4.1964, -1.3874, -0.0187]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8829, -1.1119,  4.9974, -2.7854, -1.0437, -1.4518]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5061, -1.3090,  1.1479, -0.5268,  2.6210, -3.2893]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4500, -2.0768,  0.1955, -0.4599,  3.4074, -2.2265]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3673,  0.5764, -1.9194, -3.3958,  2.5028,  1.9344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3079, -1.9531, -1.4357, -1.3370,  4.1079,  0.4831]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5743,  1.2563, -2.6943, -1.0554, -2.7575,  3.1817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5841,  4.9287, -1.6894, -2.6481, -1.9046,  0.2851]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4462,  4.7372, -0.9624, -2.7977, -2.1766, -0.0154]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5887,  4.3163, -0.9071, -3.6684, -1.0656, -0.7814]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9367, -2.9765,  3.9179, -1.5987,  0.7024, -1.4562]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6008,  0.2158, -0.4788, -3.6544,  3.7173, -1.0390]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0438,  1.8617, -3.3943, -2.7903,  0.4527,  2.7993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7927,  3.2882, -1.6767, -4.2224,  0.1911,  0.4665]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2915, -1.5576, -0.4518, -1.4432, -0.8406,  3.9355]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6317,  5.0703, -2.1684, -2.4039, -1.4780,  0.2696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0390,  4.9882, -1.4432, -2.8802, -1.7532, -0.3531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2219,  2.9837,  0.6240, -4.4593, -0.9114, -1.0362]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9003,  1.1031, -2.3715, -2.4007,  4.3483, -1.0108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1054,  2.6016, -4.4509, -0.5366,  0.9394,  1.3407]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8041, -3.0710,  2.9095, -1.1320,  2.5948, -1.9211]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6688, -1.3572, -1.8948,  3.2851, -1.9955,  1.8606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0548,  1.2785, -3.3332, -1.2347, -0.0912,  2.7170]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7077,  4.0460, -2.9477,  0.5706, -1.5673,  0.3284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7593, -2.4618, -2.0442,  0.4308,  4.1253,  0.6913]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6575,  5.1904, -2.3312, -1.8742, -1.4828,  0.0097]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9494,  4.9907, -2.3955, -1.2458, -2.0870,  0.4124]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6528,  1.4441, -1.0072, -2.4946, -2.5314,  2.4701]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7924, -0.1988, -1.2156, -0.5273,  2.5139, -0.9344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8912,  3.8702, -1.9131, -3.2901,  0.7040, -0.8660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1905,  4.8307, -1.6430, -3.2326, -0.9104, -0.5784]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3809,  4.8526, -2.8970, -2.3250, -0.1758, -0.0064]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7266, -1.2956,  4.3330, -2.7752,  0.2962, -2.2940]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3110, -1.0175, -1.0864, -1.0113,  5.1267, -1.7986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3625,  0.0341, -0.5686, -0.1833,  3.7286, -2.5900]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1506, -1.2554, -2.7110,  2.4148,  3.1251, -0.8561]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7737,  0.5890, -3.3696,  3.7027, -1.5748,  1.8727]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0923,  5.0810, -1.7131, -2.8359, -0.9164, -0.7060]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7073,  0.6538, -2.9098,  3.9263,  0.7942, -1.4284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9198,  3.6576, -1.9666, -3.4556, -1.3313,  0.5109]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3456, -1.9640, -0.5135, -2.4389,  0.8252,  0.4986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0298, -1.0044, -1.4670, -2.1556,  0.4371,  1.1395]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8409, -1.8703, -1.4590,  4.9516,  1.2201,  0.2693]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4579, -1.9440,  0.3139, -0.2477,  3.3699, -2.6697]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2417, -1.8628, -0.9921, -1.9173,  0.6783,  2.9174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3736, -1.8466,  0.2938, -2.8042, -0.4648,  2.9510]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2873,  0.4209, -1.1557, -2.6918, -1.5370,  3.8696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2433,  1.5181, -3.0433,  2.8440, -2.4975,  2.2231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5516, -1.5485,  1.5594, -0.7179, -0.5811, -2.3501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2970, -2.1756, -0.1990, -2.5982,  2.7799,  0.3792]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2894,  1.5724, -2.8550, -2.4939, -0.3858,  1.9311]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0511, -1.6889, -1.6694,  2.5061, -0.8805,  3.3048]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0548,  4.8704, -1.4806, -3.1757, -1.0891, -0.4716]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3044,  4.7776, -1.0874, -3.3045, -1.1068, -0.9148]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5536, -1.5707, -0.3624,  0.8990,  2.6432, -2.6997]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6892,  2.0207, -2.8239, -2.4172, -1.2544,  3.5725]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0376,  4.9705, -1.5838, -3.0488, -1.0310, -0.5508]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4665,  5.0430, -2.1022, -2.5181, -1.6558,  0.1636]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9658,  4.0349, -2.3679, -3.0932,  0.5600, -0.7345]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1516, -1.0787,  4.5778, -2.3243, -1.4253, -1.0320]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8723, -1.2521, -0.8817,  0.5232,  4.8334, -2.1366]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4368, -1.0206, -2.5823,  2.9798,  3.3897, -1.0936]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3518,  5.1717, -1.8613, -2.5689, -1.0375, -0.4058]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0794,  4.8576, -2.0969, -3.0228, -1.3110,  0.1601]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7254,  3.2069, -0.1803, -3.6798, -0.4624, -1.5862]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9957, -1.2385,  1.0587, -2.8302,  3.2858, -1.2243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9962,  3.2241, -3.6036, -2.1335, -0.4721,  1.2043]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4067, -0.6779, -1.9847,  2.5413, -2.9448,  3.2306]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8846, -1.2731, -0.1476, -1.2752, -2.6620,  2.7288]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0142,  4.8234, -1.6038, -3.1734, -1.1960, -0.2196]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0472, -0.6528, -1.9587,  5.3052, -1.1535, -0.1254]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3524, -1.9152,  4.3083, -2.3013, -1.7680, -0.2243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1825, -0.0260, -1.1493,  2.0383,  0.2626, -0.6648]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2220, -0.9470, -3.7363, -0.5422,  2.1177,  2.1885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0740,  4.7581, -1.0393, -3.3561, -1.4092, -0.5236]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4900, -0.4760, -2.9573,  4.4573,  0.1646, -0.1134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1324, -1.6208,  0.2714,  4.1745, -2.2813,  0.6779]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4035, -1.2240,  2.1354, -1.8163, -1.4226, -0.3021]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1324,  0.3831,  1.6532, -1.6731, -2.4648, -0.8339]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2620,  3.3066, -3.6377, -2.1716, -0.2779,  1.4849]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2938,  0.6133, -2.0179, -3.9218,  2.4932,  0.9691]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2720, -2.4396, -0.4615,  4.9394, -0.4917,  0.2832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3243,  0.9340, -0.5847, -4.0773, -1.1377,  2.7767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1801, -0.9359, -0.3845, -3.8247,  0.1517,  2.9061]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8626, -2.2315,  0.1002, -0.6671,  4.4341, -0.5878]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3932,  1.2303, -2.7582, -0.2930,  4.3207, -1.4183]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8602,  1.5266,  1.6193, -4.4612, -2.2672,  0.7707]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7272,  1.3867, -0.8313, -2.8022, -1.9913,  0.2319]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5342,  1.1591, -3.4232, -2.0966, -0.1014,  1.8478]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7617,  0.0764, -3.0741, -1.0776, -0.5711,  4.5073]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2227,  3.2388, -3.8997, -2.3484,  1.1168, -0.0602]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8907, -3.3895, -0.3003,  3.1150,  0.3819,  0.7741]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7915, -0.3387, -2.8332, -0.1207,  1.6127,  1.7565]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4237,  0.3094, -3.0940,  3.8548, -1.6174,  2.4650]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1945, -2.3750, -1.8209,  0.5854,  1.2601,  2.2376]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7771, -0.5578, -0.9811, -2.0875, -2.1332,  3.6408]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4006,  4.5724, -0.0601, -2.9004, -1.4196, -1.6779]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9923,  0.0877,  2.6124, -1.1934, -3.6730,  0.1075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7971,  1.9861, -1.2225, -4.2522,  1.7643, -0.7306]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9704, -1.9604,  2.7285, -0.7426,  0.1679, -2.9149]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6781, -0.3599, -0.5484, -3.3767,  3.2741, -0.3316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8067, -2.3385,  1.6729, -2.6181, -0.7130,  0.6028]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5048, -0.3484, -2.6604, -1.9346,  0.0807,  3.7423]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4160,  4.4501, -0.1467, -3.1794, -1.5364, -1.2876]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0885,  3.9116,  0.1461, -3.6030, -0.9956, -1.7669]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0696,  0.3411, -2.4612, -0.3945,  2.0971,  1.3093]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9534, -0.8523,  2.4461, -1.5164, -2.0749,  0.5776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3491,  2.7695, -2.6666, -3.6059,  0.6945,  0.4054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3427,  1.3976, -0.1526, -1.8100, -4.0127,  2.3433]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7776, -3.0305,  1.6157, -1.9712,  2.5891, -0.0460]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1041, -0.6355, -3.2412, -1.0381,  3.4371,  1.3179]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1327, -0.5854, -2.7267, -1.8373,  0.8033,  4.0192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1685,  4.8565, -1.6009, -3.1908, -1.1699, -0.4582]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3465,  4.3335, -2.2962, -3.5752, -0.3042,  0.1780]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9542,  3.8889, -1.8196, -3.4042,  0.5134, -0.9238]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0029,  1.0493, -2.7609, -2.7789,  3.0587, -0.6802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2867, -3.4897,  1.3745,  0.0072, -0.5049, -0.4760]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1801,  2.5508, -1.2946, -4.0221, -1.5073,  2.0611]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2325,  0.8439, -2.9808,  3.8695, -2.2352,  2.0826]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6063, -0.7538,  2.1208, -2.6292, -1.7463, -0.5586]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2199,  2.0576, -3.0600,  1.9262, -0.5368,  0.4347]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3754,  2.5419, -1.2528,  0.6200, -0.5993, -1.0010]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1440, -1.3420, -2.5944,  2.3301, -1.5378,  3.4867]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1448,  5.0573, -1.8358, -2.7315, -1.1177, -0.3647]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1779,  4.9615, -1.5974, -3.1097, -1.1958, -0.3461]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0142,  3.9761, -1.7276, -3.7828,  0.0722, -0.6866]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1960, -2.2441,  1.5870, -1.3045, -2.0623,  3.2769]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1429,  0.6625, -3.4841, -0.7636, -0.0937,  2.2420]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7037, -0.1227, -1.7465, -1.1331,  4.6405, -1.9260]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3129e+00,  2.0534e-03, -3.6437e+00,  3.4768e+00, -6.3504e-02,\n",
            "          2.4587e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5591, -0.4031, -2.1098, -1.0786, -1.7801,  4.6415]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4105,  4.5984, -1.1642, -3.4933, -0.4324, -1.0173]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0202, -0.2551, -0.4140, -3.7948,  1.5307, -0.7182]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4126,  2.4450, -1.3447, -3.9725, -0.9530, -0.2067]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1495,  3.1582, -2.1509, -1.2906, -3.2938,  1.9049]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6594,  4.1330, -1.5540, -3.7516, -0.5403, -0.3556]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2697, -3.3196, -0.9311,  0.6896,  1.2190,  2.9874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0233,  5.0283, -1.4943, -2.4016, -1.7679, -0.5864]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7009,  2.1049,  0.7562, -4.4598,  0.8728, -1.7266]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6562, -1.5136,  2.5929, -2.9196, -0.5720, -0.8357]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1145, -1.3697, -0.1650, -1.5530,  2.7654, -1.9075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4368, -3.5494,  2.3177, -1.1085, -0.0756,  1.5315]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1854,  5.0428, -1.4904, -2.8342, -0.9769, -0.6597]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8191, -1.1239, -1.5003,  4.9674, -2.0512,  1.4513]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8094, -0.5619, -2.2226,  4.3136, -2.0200,  1.8928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6634, -1.7757, -1.1352,  4.9229, -1.2145,  1.1874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2251, -2.8587,  1.7144, -0.4588,  0.3952, -0.1402]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8806,  0.2213, -2.5532, -2.1471, -0.1018,  3.0722]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5820, -0.2696, -1.5919, -2.4328,  0.2731,  3.0831]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3121, -1.2684, -0.4265, -2.3342,  2.3753, -1.4472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7315, -1.3727,  0.0520, -3.2514,  0.5550,  0.8280]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4146,  4.8346, -1.9357, -1.7791, -2.6150,  0.2830]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8696,  1.9695, -0.8067, -2.7796, -3.2764,  2.0868]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8197, -1.8731, -1.6101,  2.1068, -0.3295,  0.7386]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.1297e-03, -3.9786e-01, -3.8175e+00, -7.2057e-01,  1.7430e+00,\n",
            "          3.1203e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5855,  0.8836, -2.2936, -3.5851,  0.4798,  2.9256]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6215, -0.3884,  4.0809, -3.5671, -0.3841, -1.8772]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7311, -0.2871,  3.0835, -3.5027, -2.4249,  0.0535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9439, -1.6199,  0.2350,  2.2659, -3.0531,  3.1295]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5443, -0.1315,  0.2160,  2.4073, -4.3823,  2.0344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2468, -1.1917, -1.5239, -2.3059, -0.8881,  3.5336]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2688, -1.2280, -1.9110,  0.9821,  4.8942, -0.9108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4739, -1.0173, -1.6760,  5.2681, -1.2170,  0.5178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9099, -0.9843,  0.8555, -1.2373, -1.2431,  0.6622]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2989, -2.9408,  1.4278, -0.4069, -2.1041,  2.4539]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3480,  5.1149, -1.8906, -2.6879, -1.2229, -0.2269]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6457,  4.2280, -3.4697, -2.0598, -0.9092,  1.4438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6575, -0.6768,  2.8945, -4.0088,  1.6624, -1.5557]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9576, -1.8049,  2.1328, -2.0070,  1.6315, -2.6307]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6691, -1.4446,  2.6249, -3.5707,  1.2907, -0.4992]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5974,  3.4011, -2.2126, -2.5157, -2.3991,  2.3572]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7309, -2.3188,  1.4296, -0.0749, -2.5332,  1.5209]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1918,  5.1338, -2.1149, -2.5003, -0.6776, -0.6656]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4343,  3.8365, -2.2151, -3.9572,  0.2349,  0.3858]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9336, -2.7759,  0.7328,  0.8462,  3.4903, -1.1943]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0251,  1.2568, -0.7117, -3.0110, -2.6686,  3.1405]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0708, -2.3812,  1.3194, -3.4852,  0.4433,  1.5902]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9930,  1.9087, -1.4555, -4.0134,  1.3638, -0.3346]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6684,  5.1381, -2.7105, -1.8823, -0.8292, -0.0849]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8450,  4.6289, -3.5157, -1.3875, -0.7861,  0.9289]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3011, -0.7563, -2.6113,  5.1124, -0.3345,  0.3546]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4932, -0.9885,  3.4971, -3.5098, -1.8284,  0.3268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0122, -0.4983, -0.9277, -4.3301,  2.0450,  0.8607]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6221, -0.5023, -0.8299,  0.3450, -3.2398,  4.0192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5380,  1.0428, -0.7724, -4.6276,  2.2949,  0.0428]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3789,  2.4247, -3.5280, -2.5726,  0.2050,  2.7937]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0688, -2.2033, -1.0490,  2.3300, -2.2468,  3.4269]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2371,  1.3375, -0.8106, -4.0589, -1.5651,  1.9838]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1357,  0.4253,  2.0188, -2.1198, -3.9398,  1.8291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3599, -0.2235,  0.1350, -3.5571, -2.0511,  2.7885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 6.9848e-01, -3.1548e-02,  3.6722e+00, -2.6112e+00, -3.0749e+00,\n",
            "          2.1511e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1839,  5.1109, -2.2378, -2.3766, -0.3390, -0.7744]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2064,  4.9133, -1.2463, -3.0744, -0.9491, -1.0785]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5757,  2.6443,  0.3349, -2.5931, -2.4086,  0.1846]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1108,  1.8064, -2.1491, -1.5698, -0.8158,  0.2832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7861, -0.8992, -2.7084,  3.0979, -0.3338,  0.1105]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0432, -0.6084, -4.0701,  1.0683,  2.2946,  2.1611]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4866, -0.3887, -1.7825, -3.0109,  3.3615, -0.5738]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2631,  2.8263, -3.7057, -2.3206,  2.5220,  0.3684]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0001, -3.5798,  0.1528,  3.3099, -0.4620,  0.6566]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4103,  1.2019, -3.3585,  1.2248, -2.7034,  2.5614]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0669,  0.0354, -2.0232,  3.0323, -2.3452,  1.9370]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6043,  1.0319, -2.8869,  1.1332, -2.3112,  3.3432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3733, -1.1095, -1.0312, -0.1826, -2.7604,  3.9935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2895,  2.1781, -0.1920, -4.1451,  2.4829, -1.7833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3047,  1.8745, -2.1360,  0.1871, -2.7582,  3.1357]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7441,  1.8849, -4.6088,  0.6524,  1.2436,  1.9932]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7599, -1.2135, -2.5492,  4.7457,  0.8225,  0.8149]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5919,  1.7283, -0.8490, -0.0565, -3.3860,  1.4900]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2453,  5.1463, -1.6978, -2.6487, -1.2834, -0.5269]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0619,  5.0955, -2.0861, -2.5751, -0.9470, -0.7421]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2976,  4.4593, -2.4359, -3.2015, -0.9986,  0.8722]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0001, -1.5076,  4.8993, -1.5552, -2.2979, -1.1811]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6033, -1.9633, -0.2236,  0.3072,  4.2659, -2.2412]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2096, -1.9551, -1.5029,  2.0469,  4.3066, -0.8770]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3184,  2.0535, -1.6912, -0.8795, -3.3090,  2.6392]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7045,  4.0195, -1.0796, -3.7550,  0.5453, -1.1906]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1523,  4.9589, -2.0070, -2.8651, -1.0124, -0.4927]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1621,  4.2885, -1.0921, -3.6549, -1.7245,  0.0955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2706, -0.7366,  0.4837, -2.5175,  4.6375, -1.9154]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3521, -2.0471,  0.5891,  0.8479,  2.6548, -2.9335]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4823, -2.2805, -0.8973,  4.1980, -0.3897, -0.6731]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 4.0862e-01,  1.0693e+00, -1.3687e+00,  3.1275e+00, -2.5988e+00,\n",
            "         -3.1100e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0113,  0.8698,  1.4663, -2.5776, -2.7189, -0.3401]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5008,  0.2007, -1.8955,  1.2944, -1.2960, -0.3142]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2580,  0.6937,  3.2144, -1.9506, -3.0196, -0.2991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2945, -2.3506,  2.3065, -2.0636, -1.0885, -0.5083]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8498,  0.9825, -1.8785, -3.5265,  0.6482, -0.0568]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7645, -0.9958,  2.5315, -3.1122, -2.0989, -0.1554]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2855,  0.5929, -2.7985,  4.8627, -1.3750,  1.0290]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6385, -2.4952,  0.8675, -1.1468, -0.1347, -0.7715]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0134, -3.2802,  3.4435, -1.0414, -0.5411,  0.7656]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2813, -2.8912,  4.5451, -1.7963,  0.1186, -0.9395]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3219, -1.8813,  0.6824,  0.7723,  2.5911, -3.0630]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1662, -1.7001, -2.2975,  1.1454,  1.9652,  2.0597]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5857, -2.4450, -0.1618,  2.4671, -0.6766, -0.8305]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9777, -1.5142, -1.4094,  0.7504,  1.4757, -1.3580]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5628, -2.8607,  0.7876,  2.9146, -0.3594, -0.7974]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2824,  4.8212, -1.9547, -3.1714, -0.9725,  0.2268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0824,  3.6472, -2.2112, -3.7973, -0.2407,  1.2045]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3038, -0.5092, -2.7051,  2.2424, -0.4865,  2.4941]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4300,  1.3069, -2.7662, -2.3916,  1.4710,  0.7921]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6819, -3.4979, -0.8532,  0.5450,  1.8020,  2.4509]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7741, -2.4814,  0.8098,  2.1161,  2.1405, -2.6138]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0623,  3.6565, -0.3794, -4.2451, -0.6557, -0.8518]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4778,  2.7805, -3.4375,  2.2056, -1.3656, -0.3282]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2268,  3.2432, -3.8182, -1.1968, -0.3638,  2.4556]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3417,  1.5380, -2.1533,  2.1869, -3.0562,  1.7192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1125,  4.8801, -2.4874, -2.5601, -1.1507,  0.1888]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1609, -1.1048, -2.1585, -1.3101, -0.0559,  3.9856]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0956,  5.0295, -1.7936, -2.9267, -0.7149, -0.5850]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0081,  4.8318, -1.4102, -3.3752, -0.9826, -0.4320]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1997,  4.3421, -0.2930, -3.5167, -2.1286, -0.4933]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7252,  0.3291, -0.4698,  2.1592, -2.5359,  0.3466]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2308,  4.8840, -1.2680, -2.9391, -1.6300, -0.7298]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3243,  4.6663, -0.8122, -3.3611, -1.5498, -0.7788]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8604, -1.0898,  5.0437, -2.4755, -1.4853, -1.4713]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5656, -2.7858,  0.6512,  2.3372, -0.4942, -1.3692]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5405, -1.1855, -2.0188, -2.5432,  2.7594,  0.5263]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2109, -1.6411, -1.4159,  3.0296, -1.6279,  2.3164]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2975, -0.6639, -3.0585,  4.3059, -0.6524,  2.2872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1284, -2.5739, -2.0117,  2.7296,  0.1889,  1.5227]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4030, -1.7256, -2.2340,  5.0336,  0.8594,  0.2249]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3419,  4.8327, -1.4933, -2.9710, -1.2374, -0.7430]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2724,  4.7398, -1.1331, -3.3274, -1.5795, -0.5638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9512,  3.9918, -0.8055, -3.9277, -0.2080, -1.2465]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9833, -3.3658,  0.8492,  2.5069,  0.7324, -1.3376]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7211, -1.3178, -1.5973,  1.2930,  3.7910, -2.0341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2501, -1.2479, -0.5226, -1.1848,  5.1593, -1.8358]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7910, -1.2217, -1.8169,  1.4207,  4.5758, -1.6847]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3001, -0.8026,  0.8027, -0.2471, -3.0471,  2.6439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6239, -2.4095, -0.7832,  1.9214, -1.1009,  3.5605]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2084,  5.1183, -2.4480, -2.2215, -1.1182, -0.2566]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2601,  4.9247, -2.5405, -2.5600, -0.6078, -0.5745]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8947,  2.1106, -0.9400, -1.0809, -0.7289, -1.1031]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2286,  1.5184, -0.8037,  0.3309, -3.2890,  1.9243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0657,  2.6531,  1.1410, -2.8799, -1.7143, -1.2936]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7056,  2.5269, -3.3329, -2.7255,  1.0731,  1.2032]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2182, -0.0569, -0.4255, -4.2563,  0.1511,  1.0851]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5855, -2.1559,  0.1524, -1.2020,  4.8426, -0.5874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7501,  0.0491, -1.2488, -1.5101,  2.2935, -1.5363]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0407,  2.8785,  0.7188, -3.9635, -0.6336, -1.1862]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0059,  5.0252, -1.7594, -2.7430, -0.5552, -0.9494]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5800,  5.2220, -2.5119, -1.8185, -0.5202, -0.6005]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5546,  3.6792, -0.1429, -3.7912, -2.5670,  0.1210]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5790, -1.9607,  2.8829, -1.5263,  0.5115, -2.1314]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5094, -0.2593, -2.1556, -0.2243,  1.1892, -1.6516]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5466, -2.3457,  0.2205,  3.2481, -0.9135, -0.3905]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7956, -2.3856, -1.3226, -1.4744,  1.6189,  2.9955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2835,  5.1529, -1.9879, -2.4193, -1.1603, -0.4447]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1427,  5.1440, -2.0247, -2.5243, -1.1293, -0.5201]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8687,  4.0143, -1.8132, -3.8407, -0.7967, -0.0490]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6960,  2.2354, -0.2678, -3.8216, -0.5011, -0.4232]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0462, -2.9594, -0.0602,  3.3127,  0.9526,  0.7544]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4835, -1.1791, -2.2853, -0.8712,  3.1198,  1.0102]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4253, -2.5550,  0.2560,  3.6462, -0.1959,  0.3237]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0139,  4.7764, -1.2496, -3.4119, -0.6051, -0.6485]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2408,  4.6284, -1.3706, -3.5962, -0.9457, -0.4081]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0010,  3.3883, -0.4217, -2.4369, -3.3773, -0.0206]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3334,  1.0153, -2.9239,  1.9880, -2.1795,  3.2291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8815,  2.4367, -2.9201, -2.8468, -1.0046,  2.0374]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7108, -2.9241,  4.2804,  0.9214, -0.5165, -1.5986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5218, -0.4338, -0.2263, -1.6967,  4.3176, -2.2251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5180, -1.9124,  1.0761,  1.9523, -3.0469,  2.6089]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2027,  5.1404, -1.6709, -2.6917, -0.9206, -0.7635]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 9.7248e-04,  4.9902e+00, -2.2046e+00, -2.5956e+00, -2.2770e-01,\n",
            "         -9.3962e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6530e-03,  4.1152e+00, -1.1213e+00, -3.5855e+00, -2.1241e+00,\n",
            "          5.8003e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9317, -1.8889,  0.2101, -1.2026,  5.0427, -1.2716]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7028,  1.0982, -0.6425, -0.9636, -2.9748,  2.0187]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5244, -1.2651, -2.7093,  1.5822, -0.6414,  2.8581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4075, -0.1743, -1.9943, -3.2518,  0.6765,  3.4422]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6155,  0.4803, -2.0339, -1.7191,  5.1059, -1.2724]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7258,  2.4873, -2.3451, -3.6147,  2.8542, -0.2704]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7352, -1.3850, -2.3124,  1.5062, -0.8102,  4.0498]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8896,  1.4828, -0.9642, -4.5246, -0.1630,  1.8657]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4715,  5.1843, -2.3753, -2.1103, -0.9466, -0.2888]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1301,  4.8920, -2.8671, -2.2593, -0.7122,  0.0287]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1251,  4.4119, -2.6016, -3.2393, -0.3749,  0.6971]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4628,  1.7542, -2.2511, -3.1669,  0.9302,  0.6823]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0441,  3.6525,  0.0116, -3.6167, -2.0061,  0.2050]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0902, -2.0055,  0.7599,  0.1200, -1.5003,  1.8990]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1199, -0.6217, -2.0760,  4.8514, -1.7621,  1.6283]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0827,  5.0150, -1.2904, -2.4806, -1.9447, -0.6741]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6023, -0.3781, -1.5073,  5.5213, -1.6653, -0.1432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1610,  0.0069,  1.4737, -3.7654,  1.3399, -1.3703]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0111,  3.5584,  0.1010, -3.5654, -1.1436, -1.1007]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5796, -2.9042,  3.9555, -0.4083,  0.6540, -2.1438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4078, -0.4287, -1.1674, -3.5270,  1.1414,  2.0657]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2115,  4.9845, -1.5432, -2.4388, -2.1797, -0.1755]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5992,  4.6193, -1.3582, -3.2228, -1.7043, -0.4935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9748,  2.9861,  0.1653, -4.1117, -1.9997,  0.0419]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8958,  2.5496,  0.4367, -3.9684, -0.5817, -1.5650]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5979,  1.2867,  1.6305, -0.7313, -0.2644, -1.8817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6144, -1.4131,  4.2092, -0.3425, -2.7319, -0.4439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0160, -2.6716, -0.1525,  0.0911,  4.6011, -1.0424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7658, -2.2205,  0.1857, -0.1544, -1.9665,  3.2415]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2050,  5.1024, -2.0778, -2.6362, -1.2115, -0.2782]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0464,  4.6011,  0.1506, -3.0536, -1.7971, -1.2622]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7777,  4.1323, -0.6577, -3.3692, -1.0822, -1.1996]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5320,  1.9064, -0.2582, -4.8519,  1.0653, -0.2817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8786, -1.0377, -1.1482, -0.4532,  5.2900, -1.8038]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2711, -1.7286, -0.7549, -0.1776, -2.2225,  4.4136]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0379,  4.8896, -1.1843, -3.1626, -1.2440, -0.5197]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5009,  4.6534, -0.9029, -3.3874, -1.3161, -0.9294]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3325,  1.0592, -3.6164, -2.5847,  2.1274,  1.3471]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8410, -1.0308,  0.6617,  2.2137, -2.6336,  2.1033]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1611,  0.5525, -2.5641, -2.9518,  1.9355,  2.5955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5414,  1.0313, -1.1367, -3.5417, -1.7833,  2.0793]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2377, -0.1316, -0.9635, -2.9811, -1.8696,  3.0541]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0146,  2.8130, -2.2433, -3.7741,  1.4428,  0.0439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5026,  1.6326,  1.0860, -3.0595, -2.2922,  0.7917]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6742,  4.2198, -0.5317, -3.7939, -0.6886, -1.0938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5816,  3.9803, -3.3341, -2.6301,  0.9519, -0.1305]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1237,  2.8578, -2.7082, -3.3966,  0.0341,  2.0531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9492, -1.1297,  4.0816, -3.3944, -0.6841, -1.4906]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7181, -0.6369, -2.2961, -0.0486,  4.9871, -0.9822]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0421,  4.8136, -2.1389, -2.8965, -0.3736, -0.2839]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0921,  4.9073, -1.8526, -2.6983, -1.6176, -0.3911]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3502,  4.9915, -2.6153, -1.5705, -1.7328,  0.0596]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0613,  2.2233, -2.9869, -2.9179,  0.3446,  0.2315]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6835,  0.2099, -1.9644, -2.5705,  3.3990, -0.1879]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6602, -2.7004,  4.4585,  0.6207, -0.4057, -1.8971]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3650, -0.2822, -1.2548,  4.3262, -2.1092,  0.9872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5321, -2.6808,  0.5616,  0.5535,  2.7474, -2.4315]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5889,  0.0118, -3.0259, -1.0155, -0.5126,  2.4295]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0539,  5.0898, -1.7726, -2.6811, -0.9302, -0.8420]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0461,  4.9574, -1.9580, -3.0267, -0.5212, -0.5638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6750, -0.8617, -0.0706,  2.9422,  0.0166, -0.9192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9679,  2.7848, -2.3440, -3.6054,  2.5063, -0.6802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5236, -2.5826,  1.3075,  1.6720, -1.3136, -1.0243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7950,  0.8976, -3.6348, -0.7481,  0.4278,  3.4377]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5671,  0.1014, -3.0050, -2.1190,  0.4337,  3.4150]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9081, -2.3681,  0.3266,  3.0437,  0.9910, -1.0780]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2835, -2.3487, -0.5654, -1.2874,  4.2525, -0.0745]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7576, -1.6159, -1.6020,  5.1491, -1.1094,  1.1739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0475, -0.1527,  0.7352, -3.7040, -1.9887,  1.4981]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7756,  0.8916,  1.3435, -3.9094,  0.0232, -1.9725]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4847,  3.3587, -2.7477, -2.8556,  0.5748, -0.5646]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1586,  1.6629, -1.9204, -3.9008,  2.6072,  0.1538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1035,  1.2868, -2.1522, -3.0735, -1.1279,  2.4184]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0623, -0.9702, -3.5138,  2.2285,  3.4147,  0.6265]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3358,  0.0716, -2.1211,  0.2230, -1.0233,  3.3598]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4027,  1.6850, -3.9851,  1.4062, -1.3850,  2.1243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2138, -1.7514, -2.1454,  3.7318, -0.6820,  2.8912]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2888,  5.1279, -1.9862, -1.9528, -1.9405, -0.3202]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5129,  2.9529, -2.3135,  1.9299, -3.2869,  1.5342]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0793, -2.7940, -0.9178,  3.8135, -1.5181,  2.1795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6139,  0.4472, -3.0765,  1.3229, -1.7718,  3.3579]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0230,  2.1959, -2.5771, -3.7444, -0.2692,  1.8935]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3917,  5.2529, -2.1972, -1.9271, -1.3442, -0.4077]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1903,  5.2128, -1.8793, -2.3922, -1.1876, -0.7671]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3093, -0.3105,  2.9764, -3.6461,  1.0483, -1.4272]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4575,  5.2151, -1.8642, -2.2891, -1.4642, -0.3521]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1922,  5.1305, -1.6362, -2.6225, -1.5314, -0.5217]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7448,  3.0106, -3.2484, -2.5727,  1.0422, -0.4938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8572,  0.3028, -2.8157, -2.1364,  3.3323,  0.9467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2930,  1.9484,  0.3743, -4.4806,  0.1484, -1.4472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6537, -1.2860,  1.8834, -0.4833, -2.8321,  1.7214]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7634, -2.4201,  4.2041, -0.9126, -1.9497,  0.1259]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3170, -2.1292, -1.6947,  3.7339,  2.4849, -0.4366]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1892,  4.7214, -0.5799, -3.1604, -1.8291, -0.8980]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2727,  3.2743, -0.4973, -2.9033, -2.6346,  0.9108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4177, -1.3143,  1.4680, -1.1453,  0.4562, -2.6132]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0937,  2.4490, -3.4384, -2.8533,  1.5788,  0.5923]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4318,  1.9986, -0.3283,  0.1143, -0.8229, -1.0037]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0093,  0.0527, -1.5243,  5.3116, -1.6074,  0.0222]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4729, -0.3697, -1.8507, -1.5301, -1.7262,  4.6070]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0671,  4.9298, -2.3597, -2.6293, -1.4039,  0.1602]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4469,  5.0993, -2.4923, -2.0610, -1.5152,  0.0866]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3129,  4.3664, -2.8268, -2.6073, -0.2645,  0.0306]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4984,  1.3297,  1.9665, -4.8919, -1.3854, -0.2021]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9066, -2.7970, -0.4509, -0.6288,  4.2083,  0.3794]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3798,  4.3777, -2.6896, -0.8157, -2.4494,  0.6808]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9043,  0.6595, -0.6568, -4.4615,  0.2383,  1.0044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8364, -0.3656, -1.9048, -0.4890, -2.4257,  2.5366]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5755,  5.0960, -1.9620, -2.4677, -1.5448,  0.0668]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2295,  5.1075, -1.6161, -2.8348, -1.1819, -0.5679]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3335,  4.4218, -1.2114, -3.4325, -1.7638, -0.1846]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0446,  3.4213, -1.3181, -4.3423, -0.5981,  0.1733]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8038,  0.5532,  1.6580, -2.2558, -3.6500,  1.2268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9055, -0.5821,  2.0246, -2.9532, -1.5566, -0.8319]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7311, -1.3343,  2.8338, -3.6935, -0.8858,  0.6192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6404,  3.2734, -3.2625, -0.9543, -2.0558,  2.2873]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7008,  5.0952, -1.9807, -2.2375, -1.7546,  0.1353]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4358,  3.5459, -3.6194, -1.0049,  0.8224, -0.1686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8356,  2.7468, -1.8290, -1.2521, -1.6248, -0.5509]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0714,  3.3034, -0.0591, -4.4478, -0.7420, -0.7537]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2457, -1.3016,  2.9240, -2.9410, -1.8572,  0.1686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1560, -0.6989, -1.4013,  3.9043, -1.9519,  2.1253]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4074,  0.8428,  1.7737, -4.8476,  0.4086, -0.5342]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9790, -0.9041, -1.4767, -0.3755,  2.7867, -1.9719]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5334, -1.7160, -1.4468, -0.7964, -1.4901,  4.2962]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8220,  5.0200, -2.1547, -2.2004, -1.7291,  0.4438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0308,  4.7520, -1.9107, -3.2658, -0.7927, -0.1337]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9150,  3.0687, -2.5393, -4.0182,  0.2677,  0.8797]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1917, -1.2017, -2.1528,  1.2003,  0.6800,  1.1441]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0427, -2.1714,  2.3243,  0.0308, -0.0911, -2.7696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5999, -0.8635, -1.5741,  4.1561, -2.2067,  2.5297]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7770,  5.0043, -2.0864, -2.3095, -1.7131,  0.4512]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9503,  2.5063, -3.8928, -1.4915,  0.1981,  2.8533]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7338,  1.4864, -2.9894, -2.5812,  0.9914,  0.8453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6003, -1.8645,  0.1086,  0.3748,  4.7248, -1.8058]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0662,  2.2153, -2.6209, -1.7503, -2.1164,  2.7492]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6143,  5.0616, -1.9296, -2.4352, -1.7347,  0.1467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7446, -0.1734, -3.3524,  1.7613,  1.4337, -0.1410]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5363,  3.4479, -0.5433, -3.8330, -1.2677,  0.1089]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6509, -1.3443, -2.7006, -0.3382,  4.2014,  0.7239]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6892,  0.6235,  0.3057, -2.9431, -2.4989,  2.3517]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4555,  1.6300,  0.1593, -4.9051, -0.0154,  0.2642]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6019, -1.6426,  1.4170, -0.5094,  2.4077, -3.2813]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3454,  0.2224, -1.0046, -4.3796,  0.5222,  1.9996]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5755,  5.0948, -2.2155, -2.2848, -1.5067,  0.0986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3618,  5.1567, -2.2597, -2.3200, -1.3080, -0.2109]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9796,  3.7005, -0.0515, -2.5051, -2.7113, -1.0486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6937, -2.8667,  2.5331,  2.9491, -2.2439, -0.3803]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2498, -1.3002, -2.1702,  1.5984, -2.0684,  3.8741]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1083,  4.1209, -1.5582, -3.2890, -2.2378,  1.1135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3081, -0.4751,  2.2556, -3.7586, -1.5884,  0.0839]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3055,  1.2307,  0.7787, -3.9477, -0.7534,  1.2222]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4673, -0.9397,  0.2306, -2.2569,  0.9865, -1.4577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6104, -1.1651, -3.6544,  0.0709,  1.3453,  2.0003]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9385,  0.8365, -2.3250, -3.2891,  0.8774,  2.1403]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9591,  0.1700,  3.0463, -2.1849, -2.6272, -1.1818]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4093,  5.1043, -1.9524, -2.4757, -1.6567, -0.0771]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1040,  4.8705, -1.8270, -3.1901, -1.0361, -0.3563]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5643,  3.9565,  0.0674, -4.0686, -1.3698, -0.7857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2052, -2.6750,  2.8489, -2.0346,  1.9008, -1.5101]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4993, -1.4267,  1.0674, -0.8635,  1.0443, -2.8778]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9988,  1.8039,  0.1878, -5.1473,  0.1117,  0.5855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6006,  5.0991, -2.0774, -2.5056, -1.3353,  0.1465]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3516,  3.5345, -1.5818, -4.0596,  0.3625, -0.7618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1032,  2.7899,  0.7674, -4.5105, -1.3241, -0.5005]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5544, -2.3021, -0.6084,  2.1772, -0.0585,  2.7052]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5527,  0.1608, -2.8932, -2.9440,  1.1266,  2.9347]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5090, -2.1636, -2.9243,  0.7364,  0.5054,  2.5527]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6765,  4.9963, -2.2481, -2.1819, -1.7665,  0.4673]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0967, -1.0048, -0.5215,  5.1622, -2.3340, -0.2899]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8252, -2.2018,  2.7080, -1.2226,  1.0923, -1.2534]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0207, -0.8273, -1.2084,  1.0330,  4.6511, -1.4993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2702,  0.1888, -1.7213, -4.0112,  3.1506,  0.8820]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5617, -2.0653, -0.0284, -0.5973,  4.5436, -1.8813]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8715, -2.1458, -1.0580, -1.0894,  4.2171, -0.5404]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6603, -2.6534,  0.9481,  2.9916, -0.1074, -1.2513]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7637, -3.6331, -0.6155,  0.0469,  1.3723,  2.8218]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4729,  5.0744, -1.7494, -2.7969, -1.3124, -0.1005]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0383,  4.7304, -1.3366, -3.3953, -0.8592, -0.5781]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4095, -2.7685,  2.6480,  0.5321,  0.4263, -2.3763]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2456, -1.0606, -3.7635,  0.1884,  1.1562,  3.2890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7509,  0.2326, -2.5845, -1.4612, -0.8562,  4.5383]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6643,  5.0134, -1.5165, -2.5165, -1.9757,  0.1108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3710,  4.3251, -0.5485, -3.9317, -0.9436, -0.7750]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6572,  3.4166, -3.1488, -2.1874, -1.4770,  2.5213]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8301,  3.6011, -1.8983, -3.2919,  0.3469, -0.4984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7981,  4.0237, -1.6240, -3.3463,  0.1462, -0.6304]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3179, -0.6581,  0.9413, -1.1237, -3.5391,  2.9413]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7070, -0.9546, -1.9692, -0.5001, -1.2581,  4.7845]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4491,  5.1282, -1.6552, -2.4786, -1.7065, -0.2731]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2164,  5.0955, -1.8149, -2.8012, -1.0670, -0.5405]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4842,  3.9836, -0.2126, -3.9099, -0.4675, -1.0581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7198,  1.4774, -2.6784, -3.8606,  1.4874,  1.8623]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1457, -3.5177,  3.1225,  0.4757,  1.3026, -1.1501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7453,  5.0542, -1.3568, -2.2342, -2.1772, -0.0722]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0736,  4.8382, -0.7976, -3.1831, -1.5277, -0.8711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2444, -1.7890, -0.2610,  2.0491, -0.2738, -0.9728]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1466,  0.4246, -1.2172,  1.5036,  1.4603, -1.2653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6512, -1.0254, -1.8756, -0.0215, -0.6857,  3.9552]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3915, -2.4415,  1.1503, -1.3885,  1.5364, -1.8535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6337, -1.0708,  4.9937, -1.6040, -2.1818, -1.2755]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9602,  0.4580, -2.0730, -0.6323, -2.3910,  4.5146]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8175,  5.1270, -1.9550, -1.8230, -1.9746,  0.0921]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0035,  5.0145, -2.1783, -1.3692, -2.1607,  0.3499]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0169,  2.3189, -0.6775, -4.1809,  0.3591, -0.8559]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2543,  0.6984, -3.7179,  3.4678, -1.0627,  2.2994]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5995,  0.9732, -1.5582, -2.9542,  2.8638, -1.8423]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4314, -1.1505, -1.3686, -0.8463,  4.3414, -0.7558]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0837,  4.3644, -2.2937, -2.7300, -2.0572,  1.1038]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4164,  1.3567, -3.6804,  2.4236,  1.7746, -0.0506]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8398,  2.9064,  1.2943, -3.4088, -2.2417, -0.9156]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3183,  3.9432, -0.2650, -3.3341, -2.8368,  0.0857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2445, -2.5284, -0.3781,  3.8282, -0.2933,  0.7581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4965,  0.6252, -2.6285, -2.6700, -0.3811,  3.3261]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4900,  3.4375, -1.3444, -4.3339, -0.6614,  0.7135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3172,  1.6232,  1.7943, -3.3659, -2.7082,  0.5631]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1128, -0.4464,  2.8968,  1.5313, -4.1573,  0.1417]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6425,  1.4206, -2.5282,  1.0703, -2.8313,  1.6750]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6682, -2.6970,  3.3679, -1.2931, -1.7624,  1.6017]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0683, -0.0910, -1.0556,  0.8478, -3.0692,  3.7171]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6344,  5.1248, -1.8889, -2.2384, -1.7751,  0.0116]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0630,  4.8666, -1.1432, -3.0751, -1.6807, -0.5895]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3356,  4.1243, -1.4973, -3.9327, -0.4763,  0.1391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7031,  2.9151, -1.6276,  0.4740, -0.7538, -2.4788]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2265,  0.3213, -2.8986, -0.6003,  0.4579,  1.7424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3037, -2.4458,  1.3087, -0.6967,  4.1204, -1.8975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0232, -0.0102, -2.3979,  0.0509,  5.2098, -0.9102]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4033,  0.1673, -3.8214,  1.9989,  3.4048,  0.4399]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3582, -1.6212, -2.1615, -1.0366,  3.0561,  1.4048]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2130,  3.6809, -0.7774, -3.9420,  0.3160, -1.4915]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0883,  4.9967, -1.6311, -2.9551, -1.4685, -0.3023]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0754,  4.9918, -1.1284, -2.9784, -1.5147, -0.7058]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7911, -1.3660,  1.9554, -2.3631, -2.0945,  2.2472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5330,  2.0318, -3.4424, -0.6575, -0.1285,  1.5589]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2941,  5.2020, -1.9986, -2.4265, -1.0454, -0.5326]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3252,  5.1373, -2.6125, -1.9949, -1.1952, -0.1500]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5232e+00,  2.6036e+00,  4.0233e-01, -4.7135e+00, -8.3638e-04,\n",
            "         -1.0648e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5719,  0.3085,  3.1023, -3.6518, -0.0507, -1.6285]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9120, -1.3193,  0.7535, -2.8294,  1.7298,  0.2610]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2406, -0.9790, -1.8198,  4.9935, -1.6599,  1.6521]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7869,  0.9428, -2.3150, -2.2718, -1.1449,  4.2142]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8248, -2.8207, -1.2218,  0.3611,  2.6174,  1.5998]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1269e-03,  1.3547e+00, -3.3165e+00, -2.3869e+00, -8.1766e-01,\n",
            "          3.5942e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0549,  5.0862, -1.7003, -2.7317, -0.8214, -0.8769]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3254,  5.0365, -2.4925, -2.4402, -1.1146,  0.0544]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1246,  1.7499, -3.1129, -1.5027, -0.0669,  2.4850]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9102, -0.3126,  0.0150, -4.1441,  2.4610,  0.0231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0645,  0.2674, -2.8934, -2.3592,  0.3238,  3.6632]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2649, -0.5822, -3.1043, -1.0819,  0.2792,  3.7028]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8656, -2.3335,  3.9908, -1.9774,  0.4203, -1.5430]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3182, -1.5031, -0.8665, -0.8163, -2.0135,  4.5928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6184,  1.5678, -1.5442, -1.2533, -3.1504,  3.3425]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4929,  2.0472,  2.0556, -3.4757, -1.1283, -1.9887]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7664, -1.2513,  0.5815, -0.9272,  1.5627, -2.0164]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7103,  2.2957, -3.4436, -2.5085,  2.7513,  0.2174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7320,  3.0101, -1.9441, -2.0433, -2.8875,  2.6495]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3412, -0.8086,  1.6399, -2.2679,  0.4116, -0.9073]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6547, -0.7791, -1.6517, -1.5163,  2.9310,  1.4095]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1749, -0.2400, -1.5559,  5.1952, -1.0876, -0.9219]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2222,  5.0844, -1.1691, -2.2863, -1.6664, -1.0497]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2113,  4.7062, -2.3277, -2.3537, -1.8782,  0.6431]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1561,  2.5292, -3.6654, -1.4274, -0.7806,  3.2169]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2520,  4.9606, -1.9684, -2.3690, -1.9020,  0.0230]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9621,  4.1043, -1.3114, -3.7219, -0.4929, -0.8054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2730,  2.1979, -1.8676, -2.5981, -2.3721,  2.6746]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3498, -0.0403,  1.2018, -3.3733, -0.1638, -0.5865]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9378,  0.6998, -1.2798,  1.0888, -2.9237,  1.3959]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0368, -1.3276, -1.1775, -0.0265, -1.4008,  4.6575]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3473,  4.5837, -0.7787, -3.5500, -1.0549, -0.8736]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1955,  4.9479, -2.2458, -2.8051, -1.1793,  0.0848]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4990,  4.7017, -1.7819, -2.2863, -2.1337,  0.4045]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9576, -1.3695,  2.8928, -4.2047,  0.8656, -0.5871]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5601, -1.4100, -1.8563,  2.3472,  4.0777, -1.4962]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8784,  2.8053, -3.2647, -2.9361,  0.2375,  1.3353]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7875, -1.8359, -2.0034, -1.2849,  3.2185,  1.9183]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1173,  4.8121, -0.4305, -2.8602, -1.8969, -0.7884]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1519,  2.0333,  0.3790, -1.5029, -3.3163,  0.9216]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4283,  1.0341, -3.6503,  0.2735,  0.2018,  1.2660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7675,  1.7276,  3.1449, -3.4306, -2.1091, -1.3618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9675, -1.5070,  3.6531, -2.2396, -2.2720, -0.3413]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4541, -1.6301, -0.9179,  1.5055,  3.8326, -2.4212]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1726,  4.9515, -2.7127, -0.9485, -1.3376, -0.5742]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4578,  2.1203, -2.3637,  3.3206, -1.9705, -1.0252]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5768, -0.7999, -1.2640,  0.6189, -2.4206,  1.8490]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0444, -0.3400,  3.3277, -3.7946, -0.5104, -1.1711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7755, -2.1194,  2.7607,  1.2957, -2.4381,  0.1897]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9934, -1.1674,  4.7444, -1.9891, -2.0943, -1.2270]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9157, -0.7927, -1.1084, -3.0724, -0.5073,  2.5840]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3590,  5.2445, -1.9381, -2.2729, -1.3093, -0.5466]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1272,  5.0094, -2.6334, -2.3363, -1.1065, -0.0266]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5966,  2.0362, -3.1658, -2.4080, -0.5157,  2.3021]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7959, -3.0614,  0.7455,  4.1924, -0.0706, -1.0180]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6925,  0.8954,  0.4737, -4.5093,  2.0940, -1.0843]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5694,  0.2186,  1.5227,  0.8730, -2.0488, -0.4421]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4924, -3.4937, -0.0798,  0.6619,  3.5027,  0.6729]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5457, -0.5990, -2.0403,  5.0837, -0.5530, -0.9032]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1714, -1.7151,  2.6944,  1.0195, -3.0181, -0.1491]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9811, -1.0009, -1.1540, -0.7619,  5.2800, -1.7301]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3500, -2.1751,  1.1829, -0.0044, -0.4977, -1.5275]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4471,  5.2162, -2.1167, -2.1600, -1.4933, -0.2375]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7247, -0.6111, -2.0589,  5.6114, -0.5864, -0.1065]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4009,  4.3712, -1.2743, -3.5299, -1.6136, -0.0134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5645,  3.6514, -2.0065, -2.8936, -1.6594,  1.8248]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2159,  1.1395, -0.9757, -2.5671,  1.2834, -0.9808]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0200, -1.7352,  3.0138, -2.9844, -1.5632,  1.5065]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1363,  4.7638, -2.3152, -2.9545, -0.5265, -0.1927]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3686,  4.8962, -2.7493, -2.5070, -0.1237, -0.0836]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5225,  0.0622, -2.4315, -3.3050,  3.4567,  0.5937]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0735,  1.8284, -0.3216,  0.4226, -3.2905,  0.7605]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2872, -0.5182,  0.1444, -3.7620,  0.8408, -0.7621]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3252,  0.0224,  3.6745, -3.8768, -1.3834, -0.9825]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9205,  2.8656, -1.1440, -4.0025, -1.4131,  0.9057]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1629,  4.1282, -2.8632, -3.1447, -0.6404,  1.1748]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7630,  1.8663, -4.0293, -1.6556, -0.5115,  2.5989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2097, -1.9518, -1.4494,  0.0633, -1.1917,  4.5089]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1488,  4.9664, -1.4784, -2.9676, -1.0744, -0.8415]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3174,  5.1017, -1.3685, -2.6893, -1.7054, -0.4829]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6536,  4.9465, -1.5820, -1.7718, -2.5592,  0.1010]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5773,  2.8371, -0.4252, -1.6826, -3.3080,  0.4811]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8576,  0.9810,  3.2380, -3.5582, -2.1387, -0.8031]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9134, -2.6253, -0.0236,  2.4040,  2.7665, -1.2117]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1761,  5.0540, -1.6762, -2.9245, -1.0995, -0.4591]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2695,  5.1285, -2.2800, -2.4456, -1.1112, -0.3185]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4298, -2.1745,  3.2433, -2.2423, -0.3509, -1.0585]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-5.2566e-01, -3.2139e-03, -4.4469e+00,  2.6344e+00,  1.1165e+00,\n",
            "          2.0990e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1731, -2.5863, -1.1107, -1.1088,  0.9506,  0.7622]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3287, -0.0362, -1.5890, -2.8291, -0.5982,  4.0772]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7363,  3.4185, -3.3422, -1.4457, -1.5613,  2.4654]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2587,  3.7564, -0.6997, -3.7495, -0.0054, -1.5778]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5072,  2.2714, -0.1616, -3.7631, -2.3226,  1.3352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6149, -2.2991,  1.5393,  1.8140,  0.0374, -2.7249]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8239,  0.2498, -1.8701, -0.7410, -2.4486,  4.4361]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5314,  4.3114, -2.5572, -2.7982, -0.8769,  0.3132]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5084,  0.6000, -2.4346, -0.7328, -2.5478,  4.2322]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3051, -0.1283,  3.4339, -2.0018, -3.0063, -0.6014]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2682, -3.3060,  0.4579,  1.0944, -0.7310,  2.9973]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4150, -1.5231, -0.8423,  1.4117,  2.3764, -2.2330]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5235,  5.2294, -1.8607, -2.3544, -1.3559, -0.3511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3101,  5.0728, -1.9968, -2.2845, -1.7691, -0.0874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7152, -1.8670,  4.4306, -0.0708, -2.7227, -0.7283]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0455, -0.4869,  0.3532,  0.2924, -2.8687,  2.4498]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6585, -2.7300,  1.0248, -0.0271, -1.2581,  2.6315]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9009, -0.0544, -1.7707, -1.8248, -1.1622,  2.2412]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7509, -3.0972,  0.1376, -1.8820,  0.5251,  1.5927]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3412, -0.4456, -1.6364, -0.1695, -2.8419,  4.4044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4976,  0.0191, -4.1670,  1.2336,  2.8442,  0.9344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2978, -1.1253, -1.1991,  3.3719, -1.4145,  0.2628]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6934,  3.8245, -3.7875, -0.2811, -1.6514,  1.5492]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8029, -0.0429, -2.1373, -0.2347, -1.6476,  2.8121]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9231,  1.8103, -0.5586, -3.2940, -1.8056,  1.2802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0898, -1.1502, -1.7379,  4.2929, -2.1839,  2.4398]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2386,  1.5002, -0.6750, -3.9758, -2.0076,  2.7042]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1015,  4.4562, -2.5355, -3.1632,  0.0990,  0.2199]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0705,  4.6357, -2.9505, -2.6948,  0.0905, -0.0099]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4282,  1.7531,  2.1867, -4.2039, -1.7760, -1.0757]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0518,  0.0468,  0.3842, -4.3709, -0.6315,  2.2022]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2372,  2.2090, -0.4680, -5.0324,  0.6985,  0.0174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3750, -0.3254, -3.1998,  0.3707,  4.4095,  0.1237]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2998, -1.0277, -2.6798,  1.1705,  4.1646,  0.5645]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9741, -0.9254, -2.2365, -1.5685,  4.3417,  0.7033]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0974, -1.5982, -2.0620,  0.5315,  0.6972,  3.3028]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2314, -2.8241,  0.5663, -1.7891,  2.8905, -0.2403]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1710, -1.6912, -0.1199, -1.0114, -1.9099,  3.1117]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2939, -0.6622,  1.2909, -2.5348, -2.4072,  3.3059]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1061, -0.9231, -3.1590, -1.3661,  2.1593,  2.3616]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8253, -2.1635, -1.4383,  0.8145,  4.5460, -0.6258]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4025, -1.4317, -1.2309,  5.2967, -0.2161, -1.0696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6994, -3.0073, -0.0678,  1.7529,  0.4406, -0.7308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5064, -1.0295,  3.8465, -0.0169, -2.4136, -1.8863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3402,  1.6368, -1.6991, -3.5943, -0.1759,  1.4369]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0301, -3.0648,  1.2498,  1.8232,  1.7860, -2.3698]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1933,  0.6734,  2.0280, -4.7449, -0.2783, -0.0572]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.0543e-04,  4.9452e+00, -1.8105e+00, -2.2556e+00, -2.2782e+00,\n",
            "         -1.7125e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0211,  1.1902, -2.2311,  0.6717, -3.2981,  3.7247]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0246,  0.9912,  3.4174, -2.4438, -3.1973, -0.2382]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5010,  2.2329, -4.0875, -1.0957,  0.3537,  1.6057]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3869, -2.9656,  0.5597,  1.9100, -1.6828,  2.4791]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7990, -2.3902, -0.7663, -0.3425, -1.0467,  3.6210]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4691, -0.5775,  4.1030, -3.0353, -1.4395, -1.3740]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6122, -1.3296,  1.6631, -3.7545,  2.3902, -0.2418]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0523, -1.8358, -1.8777, -0.1522,  4.8003, -0.3465]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1950, -2.1647,  1.8211, -3.0892, -0.9626,  2.5594]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7872, -0.6544, -3.5004,  1.5103, -0.5441,  4.0276]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7611,  4.9766, -2.2066, -2.2262, -1.7133,  0.5028]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0374,  0.3658, -2.9926,  4.7329,  0.0938, -0.4839]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2521, -1.1614,  1.3420, -0.2842, -2.9790,  2.4399]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3533, -2.1741, -0.5656, -0.8815, -0.6324,  1.8750]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6776, -3.0215,  0.1365, -0.4339, -0.9215,  3.6709]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1036, -2.9493,  2.8205, -2.4233,  0.1581,  0.4612]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8668,  0.1181, -2.2447, -1.1171, -1.6146,  4.6203]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7092,  5.1515, -2.0028, -1.8735, -1.9523,  0.0546]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0060,  4.3314, -3.1227,  0.7269, -1.6660,  0.2848]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0218,  4.8105, -1.5536, -2.9337, -1.6289, -0.2288]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9718, -2.6266,  3.8683, -2.2605,  0.4095, -1.1589]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9249, -0.3109, -3.2732, -0.6628,  1.2786,  2.3966]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4310, -1.4958,  1.3439, -3.8758, -0.9873,  1.5181]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4893, -0.3772,  3.8558, -3.5812, -1.3221, -0.9483]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9982, -0.7148, -1.0515,  3.5913, -1.7439,  0.1117]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5970,  1.4144, -2.0177, -3.1830,  0.2212,  1.0064]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5029,  1.8075, -1.8871, -4.1592,  0.1974,  2.0618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3666,  3.7060, -2.6157, -2.4699, -0.5199,  0.5903]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7395, -0.2478, -2.8211,  1.1335, -1.9078,  4.2427]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1772, -1.4103, -1.5061,  2.4755, -0.3214,  1.7891]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1958,  0.3800, -3.1398, -1.7605, -0.5385,  4.1301]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4964,  5.1189, -1.8244, -2.4030, -1.7796, -0.0857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0479,  4.9102, -2.2801, -2.6891, -1.4959, -0.0471]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3762,  3.7748, -1.1830, -3.3723, -1.7536,  0.5184]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6706, -2.7613,  2.4891,  1.1204, -2.6317,  1.4424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0514, -3.4530,  0.2497,  0.3942, -0.5067,  2.8002]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8979,  0.2692, -1.7876, -0.0191, -2.9657,  2.7701]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3757, -0.0544, -2.9596, -0.0227, -1.7050,  4.3010]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3824,  3.6907, -1.5898, -4.2708,  0.0235,  0.4085]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2095, -3.0015,  2.3490, -2.5068, -0.0847,  0.9885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4836,  5.2253, -2.0689, -2.3112, -1.2430, -0.3172]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9173,  4.2968, -2.4408, -3.2494, -0.1283, -0.4247]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2393,  5.0577, -1.6480, -2.4137, -1.3422, -0.6501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5641, -2.3519,  2.4684, -0.9453, -0.7773, -0.8238]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1204, -0.2462,  0.1946, -2.9529,  0.8029,  0.1565]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3845, -1.9261, -0.0850,  1.0050, -2.3845,  3.0580]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9213,  0.5564, -0.9819,  2.3287, -3.2033,  2.2769]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6973, -0.2588, -2.3174, -0.8273, -1.5693,  4.6968]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4496,  5.1061, -1.9413, -2.6674, -1.1493, -0.2004]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4732, -0.7396, -2.3560,  5.3326, -1.0116,  0.5165]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9260, -1.4486, -3.0561,  2.3077,  2.9943,  1.7656]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9484, -1.8841, -2.9889, -0.3740,  1.9170,  2.6630]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4235, -0.8865, -2.4833,  3.5602, -1.5694,  3.1689]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5543,  2.1552, -2.7285, -3.8025,  0.0785,  2.1474]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6580, -0.3805, -2.7069,  2.5302, -1.3130,  3.1322]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6747,  5.0047, -2.0521, -2.2855, -1.8588,  0.3671]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4730,  4.8073, -2.2040, -2.1418, -2.2727,  0.5989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0564,  4.2592, -1.7158, -3.8578, -0.8350,  0.5465]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2186, -2.0367,  0.7189,  2.4075, -3.4792,  2.0856]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9558, -1.0947,  1.7151, -4.5191,  0.4931,  0.7102]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9325, -0.5993, -2.0764,  5.0214, -1.9535,  1.3658]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5618, -0.0595, -3.5999, -1.9246,  1.7990,  2.7473]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6889, -1.9076, -2.0499, -1.0772,  3.2622,  1.9412]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3295,  2.8440, -2.1938, -2.9412, -2.0365,  2.6535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5203,  2.2281, -0.8873, -3.7397, -1.3060,  1.5844]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5830,  0.3131,  1.3236, -1.4581, -4.0057,  1.8729]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1318, -1.6279, -2.5799,  3.1596,  1.2764,  1.5125]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6311,  5.0136, -2.1267, -2.4658, -1.5577,  0.3581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1801, -0.4278, -2.1842,  5.3906, -1.0925, -0.0987]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7281, -3.4124,  1.2557,  0.7026, -0.5223,  1.1504]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2550,  0.3137, -0.8517,  4.7495, -1.9942, -1.1680]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9813, -3.5383,  0.1676,  1.0992,  2.6940,  0.2559]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5470, -0.9399, -3.3506,  1.1716, -0.0163,  3.7773]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0277, -0.5717, -1.2396,  2.0745, -1.5096,  2.9845]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6263, -1.1438,  0.2356,  4.6106, -2.8827,  0.6441]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7307, -1.1624, -0.9394, -0.4056,  5.3416, -1.8135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2807,  0.6784, -3.8704, -0.3001, -0.3028,  3.5104]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3681, -1.3124,  2.7265, -2.3688, -0.7197, -0.8993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3442, -0.4653, -1.1124, -0.1442, -3.1446,  4.1060]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5877,  5.0757, -2.0424, -2.2756, -1.7831,  0.1312]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0099,  5.0278, -1.4514, -2.6907, -1.7981, -0.5739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5878,  3.9787, -1.0555, -3.8627, -0.1549, -0.6527]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2491, -1.2301, -1.0411,  4.3079, -1.2190,  0.2327]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2528, -1.7622,  3.4167, -0.4928, -1.6786, -1.6990]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5929, -2.9702,  1.0942, -0.9471,  0.8126,  1.0866]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0767, -1.3125, -0.7769,  2.9111,  0.2848, -1.5536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1992,  4.8483, -2.9399, -1.0741, -1.3166, -0.1611]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0375, -1.3609, -1.8616,  0.4926, -1.1747,  1.9874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2879, -1.6734, -2.1519,  2.8244, -1.1284,  1.4423]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3013, -1.5697,  0.5554,  3.0985, -3.5124,  1.8182]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3674,  2.2210, -0.5730, -2.2260, -3.5506,  2.5859]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0883,  4.6406, -0.8858, -3.2162, -2.0684, -0.2811]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3944,  5.0850, -1.1874, -2.7692, -1.5898, -0.5451]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6816,  3.9309, -0.0411, -4.0585, -0.7852, -1.1439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3072,  4.7314, -0.9368, -3.3674, -1.0235, -1.0587]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2983,  4.8940, -1.9740, -2.9660, -1.1351,  0.1246]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4765,  1.3270,  0.7967, -4.5647,  2.3166, -1.6168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2493, -1.9806,  4.6457, -1.8696, -1.0008, -1.1148]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8939, -1.6017, -1.2747, -1.0166,  2.2504,  1.8424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0177, -2.1937, -0.6969, -0.4684,  4.0834, -0.0568]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2431,  0.8025, -2.3898,  2.0988, -3.2345,  2.5533]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0715, -1.6715, -1.0800, -2.1396, -0.2540,  2.6064]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2744,  0.0177, -2.8200,  3.0038, -1.0061,  1.4033]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0374,  0.0852, -2.5034,  2.2831, -2.0989,  3.3207]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8594, -0.0666, -3.6964,  3.7419,  0.1585,  1.9114]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3069,  2.7360, -2.9846, -2.5724, -0.6751,  2.1214]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7415,  0.0925,  0.8431, -3.4539, -2.6900,  2.6381]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5802, -0.1415,  0.2454, -4.0748,  3.2845, -0.5903]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9475, -2.5228, -1.9327,  3.2059, -0.6087,  1.8432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7110,  0.0512, -2.3754, -0.6535, -1.9013,  4.5391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0341,  4.3798, -0.6037, -3.2623, -2.5176,  0.0194]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2781,  4.6492, -0.9184, -3.3091, -1.6632, -0.6594]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3039,  3.3993,  0.0736, -4.5212, -1.3580,  0.1854]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0013,  3.2838, -0.9678, -4.5066,  0.1327, -0.2899]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9087,  4.3522, -2.9179, -0.9991, -0.5082, -1.3082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5080, -2.6192,  1.3141, -1.8851,  2.2229, -0.6496]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2610,  2.6320, -3.6179, -2.7019,  0.0080,  2.2402]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4517,  0.4360, -0.4478,  0.1050, -4.3593,  2.5631]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4556,  5.0990, -2.1817, -2.4749, -1.4012,  0.0162]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5255,  4.4555, -2.2203, -3.3684,  0.1069, -0.5311]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1015, -0.3523, -1.0343, -3.4870,  2.4599,  0.4498]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1144, -0.8175, -2.3191,  2.9204, -2.1880,  3.5470]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7767,  4.1028, -0.8112, -3.1554, -2.2683, -0.4267]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1240, -2.5204, -1.0204,  2.5816, -1.4386,  1.8329]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1907,  1.6046,  0.8673, -3.6911, -1.6936,  0.4467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3908, -1.4276, -1.7211,  5.2277, -0.8959, -0.1903]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4073,  1.3022, -2.1315, -2.5024, -1.9496,  3.8291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7764, -1.6846, -2.3534,  0.3166,  1.8383, -0.0152]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2245,  0.3357, -0.9334, -4.3183, -0.5601,  1.6660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6836, -2.8673,  1.7521,  2.2477, -2.3577,  1.1043]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0461, -2.3853, -0.7107, -0.1003, -0.6852,  4.0564]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6114, -2.1093,  0.2083,  1.0945,  3.6138, -2.5579]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5086,  0.0554, -3.7500, -0.2592,  0.3864,  3.7432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1883,  0.1167, -3.8337,  0.5991, -0.9501,  3.5776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4049,  1.0153,  1.4138, -4.7069,  1.4024, -1.0031]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0262, -1.5400, -0.0616,  0.1000, -1.3578,  4.0392]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5812,  0.3265,  2.5338, -3.8573, -1.0854, -0.6871]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5110, -0.0226, -1.3222,  0.1612, -2.5140,  1.8330]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1668, -1.3981, -3.4214, -0.1579,  2.0920,  3.2439]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1822,  2.2697, -1.9125, -1.8970, -2.9573,  2.8247]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7537, -1.3712,  2.9329, -0.0833, -1.0144, -1.7229]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5550,  1.5743, -1.3113, -3.8177, -0.6822,  2.3433]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6514, -0.7621, -1.5612, -1.4596, -0.9918,  3.5508]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3714,  1.4189, -3.4573, -2.9729,  1.7211,  2.1775]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6038, -1.0946,  1.7884, -2.9901, -1.1522,  2.1937]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2219, -0.2388, -1.4709, -3.2181,  4.4040, -0.2049]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9497, -2.6268,  2.4093, -0.2841,  3.1897, -1.7246]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3914,  0.8776, -2.1721, -3.7481,  3.1477,  0.2600]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2499, -1.8569,  1.4642, -1.5306, -2.6010,  3.4067]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0486,  4.4655, -1.7394, -2.6147, -2.3214,  0.4563]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0837,  5.0579, -2.5620, -2.3135, -1.0264, -0.2545]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7793,  4.1997, -2.8041, -2.8953,  0.1521, -0.3051]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2814, -1.7452, -0.6496,  5.2134, -1.7394, -0.1946]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0149, -3.2099, -1.2552,  3.4758,  0.0776,  1.0531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0025, -1.9725, -0.9360, -1.3197, -0.8950,  2.8122]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6424,  0.5685, -3.4813,  0.9310, -0.9061,  2.5387]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7570, -2.8299, -1.7167,  2.7281,  0.6971,  3.0284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4393, -0.1315,  3.8839, -2.6519, -1.9986, -1.3526]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4227, -1.4444, -2.5086, -0.5747,  1.1446,  2.4044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0198, -1.4766,  0.0050, -1.1899, -1.9606,  4.0899]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0184,  4.9300, -1.6500, -2.5796, -0.2582, -1.1854]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0974,  4.8573, -2.2672, -2.9882, -1.1003,  0.1189]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2472,  4.6646, -0.8414, -3.1797, -1.7744, -0.6525]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8545, -2.9835,  0.7837, -1.5649,  2.1733, -0.6755]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3481,  1.5045, -2.4126, -0.3274, -2.7079,  3.8752]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-4.7162e-02,  3.6955e-01, -3.8629e+00, -2.2331e-03,  9.9469e-02,\n",
            "          3.3622e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2782,  5.0503, -2.5026, -2.4475, -1.1055,  0.0453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1700,  4.9234, -1.9438, -2.9376, -1.1714, -0.3598]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 9.3526e-01,  4.2959e+00, -3.0148e+00, -2.4735e+00, -1.1011e+00,\n",
            "          3.1926e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4270,  4.1971, -1.6829, -3.7904, -0.6398,  0.0841]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8125, -0.4510, -0.4801, -4.1725,  1.3575,  1.3977]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9518, -1.6429, -2.8258,  0.4154, -0.0393,  3.2776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2635,  1.3079, -3.0892,  0.3255, -1.9152,  2.4866]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1848,  1.2392, -3.4581, -0.1070, -1.0843,  2.8110]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8086, -1.8405, -1.9021,  3.2541, -0.9813,  1.7564]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2248, -0.6096, -2.7762,  1.2978, -1.4284,  3.7351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2311,  5.1740, -1.9731, -2.3423, -1.5191, -0.4806]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6927,  0.0470, -2.6602,  4.4414,  0.3942, -1.1070]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7160, -4.0964,  0.0421,  2.0170,  1.1455,  0.3718]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2658, -0.3743, -0.3556, -0.3310, -2.9334,  3.0238]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1254,  1.8000, -2.6587,  1.7931, -2.7210,  2.4026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8792, -1.2818, -1.8289, -2.3644,  3.9533,  0.1729]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0872,  5.0925, -1.7841, -2.7452, -1.1477, -0.5806]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2812,  4.0295, -3.5133,  0.1239, -1.5497,  1.3523]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1354, -1.5730,  1.1904, -0.6679, -0.4442, -1.5166]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9501, -1.1606,  4.9657, -2.1733, -1.3225, -1.6453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0178, -2.3095,  1.5704,  0.3942,  2.8224, -3.0989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4452, -1.4083,  0.5541,  0.4106,  2.6171, -3.3242]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0705, -2.2738,  0.0917,  1.8976,  2.4977, -2.6310]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8358, -0.8035, -2.7228, -0.1393, -0.4313,  4.5365]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1450,  3.5367, -2.6139, -0.4664, -2.8732,  2.1928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6190, -3.1513, -0.5429,  2.0375,  0.4967,  1.9533]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2340,  4.9208, -2.3493, -2.4833, -0.6038, -0.6357]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0578,  5.0260, -1.7690, -2.8211, -1.2823, -0.5880]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5023,  4.0872, -0.4951, -3.5676, -1.8869, -0.4441]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9079, -2.8796,  0.7574,  1.3764, -2.4355,  2.4314]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0039, -0.3155,  1.1976, -4.2470,  1.8934,  0.4543]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3261, -2.5766,  1.4029, -3.0044,  0.1604,  2.5197]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0133,  4.7054, -2.1540, -3.0989, -0.0814, -0.2680]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0331,  4.6466, -2.7047, -2.9121,  0.1667, -0.1854]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5187, -1.9803,  4.4105, -0.6198, -2.1281, -1.3996]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8698, -0.7760, -1.0294, -0.2791,  4.9999, -1.9344]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3521, -3.2497,  1.6967, -1.3235,  2.7335, -1.2781]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6149, -0.0208,  2.1842, -2.5371, -1.8611, -1.1178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9821,  0.1081, -1.6481, -0.6778, -2.7147,  4.4535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2026, -2.5227, -0.1126,  4.6475,  1.1438, -1.1389]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4813,  3.9032, -1.9543, -3.0858, -1.2918,  0.5157]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3577,  4.4809, -1.1344, -3.7052, -0.3715, -0.8227]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6720,  3.9775, -1.1975, -4.1078,  0.1181, -0.6397]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1164, -1.5433,  1.0894, -2.3276,  3.7334, -2.1138]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1168,  1.8534, -4.3783, -1.2120,  0.2919,  2.8311]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9768, -1.1071, -0.8478, -0.7532,  5.2579, -1.9136]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8136, -1.6261, -0.0401, -3.5891,  1.2807,  1.7827]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2820, -0.1684, -2.2978,  4.7198, -1.7140,  1.6511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2362,  1.4806, -0.8456,  1.9444, -2.3046, -1.1140]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8249,  1.0820, -3.4970, -0.0490, -1.4057,  3.9887]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3208,  5.1724, -2.1962, -2.3806, -0.9416, -0.3894]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2126,  5.1776, -2.1301, -2.4204, -0.6948, -0.7458]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5126,  3.6174,  0.6844, -4.0096, -1.8014, -0.7888]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4085, -3.6381,  1.5443,  1.8369,  0.1629,  0.0388]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1195,  1.2000, -3.3135,  3.4752, -2.0604,  1.9437]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0438,  0.9821, -3.9919,  0.6426,  1.2218,  1.7806]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6055, -0.5768, -1.8418, -1.3422, -1.0858,  4.4931]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6344,  3.3208, -3.7917, -2.5612,  0.4224,  1.0496]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2776, -0.5457, -2.3740,  5.2342, -0.9704,  1.1396]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2232,  5.0072, -1.8725, -2.7530, -1.5931, -0.0122]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3576, -0.2797, -0.7177,  4.2679, -3.2572,  0.1558]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0965, -0.9334,  1.7770, -4.3351, -0.0714,  0.8326]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0519, -1.2714, -1.9609,  2.1907,  0.1593,  1.2157]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7415, -0.2495, -1.7558, -1.3054,  5.0767, -0.8777]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5950,  0.1506,  1.7422,  1.5122, -4.3804,  0.2668]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3056,  1.5439, -3.4143,  0.3071, -0.5873,  2.4618]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2754, -1.5939, -2.6643, -1.2789,  2.4171,  3.2022]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6377, -1.6192, -1.9325, -2.1444,  1.3772,  3.5050]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4097, -0.6616,  1.0272, -3.7661, -1.3006,  2.9289]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0625,  4.9723, -1.8998, -2.9336, -0.4862, -0.6016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1195,  5.1464, -2.0764, -2.5442, -1.0338, -0.5822]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1533, -1.1733, -1.7501,  5.2820, -0.5453,  0.8987]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0807, -1.1113,  1.7654, -3.7661, -1.4219,  2.2869]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2855, -0.0719, -1.5239, -2.4919, -1.4414,  3.9927]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8544,  3.4546, -0.8528, -2.8413, -1.6687, -1.1961]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4471,  4.6074, -2.1193, -3.1046,  0.2490, -0.9601]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4420,  3.2081, -3.0862, -2.2325, -1.5286,  2.6268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.5018, -2.3030, -0.5138, -0.6141, -0.1378,  0.1128]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5397, -0.8098, -2.7570, -1.3478, -0.3543,  3.9641]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3941, -0.9312, -2.5156,  4.1235, -0.7145,  0.9948]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6205, -2.1619, -1.3783,  1.9045, -2.2454,  3.2231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1774,  5.1140, -2.2912, -2.5184, -0.6814, -0.4159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1154,  5.1107, -1.7165, -2.7633, -1.1931, -0.6172]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0490,  4.4661, -0.1545, -2.2878, -2.8119, -0.8397]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6998, -1.9924,  3.7782, -1.6186, -1.5330, -0.5486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9332,  0.9442,  0.0906, -4.5847,  2.1282, -0.8664]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1453, -2.6169, -1.1940,  4.3492,  1.9899, -0.4778]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3768e+00, -1.6029e+00,  2.9838e-03, -2.6880e+00,  3.9213e+00,\n",
            "         -1.3571e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2672, -1.7728,  0.5995, -0.7407, -2.4829,  4.0052]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6093, -1.8012,  1.4851, -1.0807, -1.7736,  0.4068]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6603, -4.0888,  0.7812,  2.1959,  0.0533,  0.4389]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0346,  5.1141, -1.3257, -2.3326, -1.5078, -1.1252]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1033,  4.8847, -0.9676, -2.7321, -1.9500, -0.8320]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2227,  3.9526, -1.9083, -3.6010, -0.3120, -0.5726]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9818, -3.1999,  3.6411, -1.8340,  1.2567, -1.2188]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6450,  2.3396, -2.0778, -2.6862, -2.1976,  3.2325]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1494,  0.5716, -3.6749,  1.8845, -0.5966,  2.4134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1863,  0.3584, -3.2131,  0.2956, -0.7335,  2.1350]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5786,  4.7174, -2.1689, -2.0614, -1.9292,  0.7062]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7677, -0.4624, -2.1340,  5.5048, -0.3730, -0.0881]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2793,  4.5590, -1.7916, -3.3123,  0.2007, -0.7321]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0064,  4.9169, -2.5920, -2.5418, -0.4719, -0.3219]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2091,  4.9880, -1.6071, -2.8450, -1.6499, -0.1955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8047, -2.6310,  3.0212, -1.1444,  0.6420, -2.1424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0967, -0.0306,  1.3798, -0.0850, -3.9935,  1.7778]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1442, -2.3939,  0.6994,  0.5423,  3.1582, -2.6944]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3394, -3.0069, -0.6831, -0.1613,  0.9275,  3.2716]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4164, -1.5857,  0.1983,  0.7687, -0.2729, -2.0843]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0156,  2.0848, -1.1525, -3.7249, -2.1073,  2.7001]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3638, -1.6197, -1.8581, -0.2101, -1.1156,  4.6558]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4627,  5.2111, -2.1095, -1.7051, -1.5779, -0.3791]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4897,  4.5688, -2.9052, -0.0813, -2.0831,  0.2174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8471,  0.8366,  3.6700, -3.2331, -2.6165, -1.0696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5790, -0.3112, -0.1266, -2.7769,  3.3125, -2.0764]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1697, -2.0273, -1.0915,  4.2035, -0.1212,  0.6955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 6.0865e-01, -2.6536e+00, -1.3652e+00,  8.9848e-04,  3.6210e+00,\n",
            "          1.1577e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0105,  2.7493, -0.2020, -4.1810, -2.0177,  0.6583]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0506,  4.9759, -1.5559, -2.6925, -0.6505, -1.0158]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0329,  5.1349, -1.9158, -2.2814, -1.2026, -0.9562]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5696, -1.3915,  3.6335, -1.6594, -2.7065,  0.9043]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4056, -2.7647,  3.2538, -0.1548, -0.3234, -2.0975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3502,  0.7230, -2.4876, -0.7876,  4.5484, -0.6634]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0767, -2.5043, -0.7408,  1.8832, -1.8404,  2.5192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6814,  1.9278, -3.2670,  1.2451, -1.2605,  0.9039]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4141, -4.1236,  3.0829, -0.8362,  0.3814,  0.6765]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9274,  0.5895, -3.6445,  0.9422,  0.6037,  0.2795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1015,  1.8408, -3.3694, -2.1518, -0.7329,  3.3329]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3491, -1.8341,  0.9465,  0.9908, -1.2808, -0.5930]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8875,  0.7552, -4.1054,  1.7267, -0.7815,  3.3161]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 8.5954e-04,  3.2078e+00, -1.8030e+00, -4.0589e+00, -8.8108e-01,\n",
            "          1.7536e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7367, -2.8211,  1.0027,  0.6612,  1.1662, -1.6489]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5531e-01, -2.1450e+00, -1.3978e+00,  4.4001e+00, -7.4606e-04,\n",
            "          1.0295e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4745,  4.1288, -2.1653, -3.5282,  0.3227, -0.1364]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6163, -1.2333, -1.7415,  5.2308, -1.6919,  0.9942]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9910, -1.0179, -0.9938, -1.8829,  0.9624,  2.1403]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1686, -3.3039,  0.9227,  3.9474, -0.1136,  0.0606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3165,  0.7700,  0.6756, -5.0082, -0.8267,  1.2256]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0332, -2.0113, -2.0075,  4.0731,  2.2594, -0.1024]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0632,  0.7787, -3.8137,  4.0182, -0.3225,  0.3758]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5104, -3.0969,  3.9890, -2.0769,  0.3652, -0.2984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2902, -1.5248, -1.5760,  0.5424,  4.6896, -1.6832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2756, -1.4484,  2.0384, -3.3331,  2.5572, -1.5127]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5337,  5.0650, -2.1979, -2.6075, -1.0617,  0.0938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0750,  4.8550, -1.8269, -3.2265, -0.7843, -0.4577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7301,  4.0005, -0.3031, -3.8785, -1.0489, -0.9863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6580, -3.6019,  3.0792,  0.3635, -0.6981, -0.1268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5632,  2.5663,  0.3887, -4.4032, -2.1136,  0.9909]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2303, -0.0153, -2.2919,  4.1285, -2.3244,  2.2577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.7503e-03,  5.0192e-01, -2.0511e+00, -2.6758e+00, -7.3599e-01,\n",
            "          3.7564e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7517, -1.2062, -2.6383,  2.8158,  1.2163, -0.4519]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5200,  1.6878, -1.4317, -1.9688, -3.1585,  3.4592]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3896, -1.4394,  3.0182, -1.6578, -3.3220,  0.8607]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1126, -1.1478, -0.7110, -1.2947,  5.2249, -1.6498]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0279, -1.5224, -1.1272,  0.3077,  4.9567, -1.7833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6542, -0.9507, -1.8412, -2.4077,  4.0364,  0.1861]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8767, -0.9311,  0.7500, -3.0423,  2.8728, -0.7651]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6454, -0.0733, -3.7314,  3.5940,  1.3503, -0.1681]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0337, -1.6887, -0.9934,  1.2273,  3.4093, -2.2603]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1482,  1.9029,  2.1349, -2.7766,  0.4563, -2.9418]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9012, -0.8499, -1.6797, -2.8019,  0.0974,  3.4651]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2741, -0.7367, -1.1997, -2.0124, -1.5218,  4.1551]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2712,  2.2103, -3.9432, -2.0826, -0.0251,  2.3653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4255,  5.1186, -1.7873, -2.4906, -1.6156, -0.2382]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3540,  4.7853, -1.5194, -3.2686, -0.8576, -0.8352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7296,  3.7781, -0.0546, -4.0270, -1.1724, -0.7993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7892,  2.6903, -1.3315,  1.8063, -2.6206, -1.2074]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0238,  1.0119, -3.8203,  0.3023, -1.5654,  2.2712]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7508,  3.7769, -2.1100, -3.8714,  0.5795, -0.1760]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4826,  2.5001, -3.0157, -1.8621,  1.3325,  0.6684]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3190,  3.6588, -2.2406, -3.4646,  1.5538, -0.0817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0672, -1.4957,  0.5661, -2.1058, -1.3833,  0.6607]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8631, -0.8822, -0.2121, -1.5204,  4.8668, -1.6391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0613, -2.2989, -2.1972, -0.7652,  0.5378,  2.6349]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5851,  0.5681, -2.5574,  4.4102, -1.3681, -0.5016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0747,  2.4313, -1.7412, -2.0824, -2.4603,  1.3080]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0470,  2.6131, -1.8300, -4.0922, -0.8502,  1.2579]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6288,  2.0146, -1.6206, -3.2425,  0.7443,  1.0199]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7422, -2.0210, -0.6345, -1.1668, -1.3197,  3.8988]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0841, -2.6541,  3.9707, -1.5093, -1.2563, -0.9220]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9869, -1.8063, -0.0688, -1.8755,  3.0380, -1.5347]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9089, -2.9585, -0.7902,  1.9909,  2.5108, -1.2094]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2534, -0.8120, -3.0315,  4.2933, -0.6181,  2.3069]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9360, -2.6037, -1.9439,  1.4153,  1.2144,  2.1130]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4666, -2.7662, -1.2683, -0.5372,  1.0318,  3.5291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5665, -2.2802, -1.8335,  3.8269, -0.9122,  2.6481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6708,  0.0870, -2.5322,  0.2636,  2.4248, -1.5846]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1890,  2.2434, -2.5198, -3.7963, -0.2996,  1.6608]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5663, -2.8311,  3.0997, -2.2399, -0.5127, -0.2815]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7660, -2.4499, -2.5628,  1.5486,  0.6629,  1.7336]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6108,  4.9637, -1.8209, -2.5984, -1.7925,  0.3432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7592,  0.5540, -2.9059,  4.3477, -2.2109,  1.4208]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0331, -0.7993,  2.8580,  0.1335, -3.5324,  0.7898]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9418, -1.5732, -0.9882,  0.0799, -1.4085,  2.1079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4712,  5.1896, -2.0685, -2.4700, -1.0956, -0.2596]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0598,  0.6933, -2.9651,  3.7082,  0.1996, -1.2064]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2999, -2.0948,  1.6632, -3.3146,  1.1921,  0.4120]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5569, -0.4191, -2.1206, -0.8772, -1.3843,  4.5162]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6100,  5.1370, -1.8715, -2.3295, -1.6819, -0.0244]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0797,  5.1296, -1.9333, -2.6372, -0.7228, -0.7963]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8650,  4.1855, -1.6014, -0.6118, -1.8330, -1.6176]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7273,  1.5524,  0.7467, -5.1046,  0.2064, -0.2184]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2703, -0.6659, -1.6214, -2.6850,  3.2084, -0.0555]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1195,  3.8440, -3.7406, -1.5343, -0.4362,  1.2772]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4003,  5.0133, -2.0397, -2.7021, -1.4518,  0.1383]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1484,  4.7374, -2.2008, -3.2234, -0.5842, -0.1879]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7891,  3.6172, -2.1340, -1.5627, -2.5056,  0.3536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9875, -1.0630, -1.1174, -3.0478,  0.5501,  2.3284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0441e-01,  5.5835e-01, -3.5422e+00, -1.6901e-01,  4.2680e+00,\n",
            "         -5.5569e-04]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6988,  1.5116, -2.6658, -2.6120,  3.7835, -0.3537]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7434, -1.9196, -0.7320,  0.2883,  1.8301, -1.0972]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2556, -0.5790, -1.6506, -0.1301, -1.6990,  2.7002]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4618, -1.8579, -0.9585,  0.2724, -0.7908,  3.3006]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3563,  0.2438, -2.7697,  0.9065,  0.1158,  1.9774]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5831, -3.3963, -0.4497,  0.8202,  2.7105,  1.3260]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6182,  5.2010, -2.0293, -2.1351, -1.5369, -0.1732]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5866,  5.0764, -2.9562, -1.5343, -0.4305, -0.3468]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0285,  1.2747, -3.1871, -2.9181,  1.3752,  2.8106]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9707, -0.6566, -0.0074, -4.0236,  1.7221,  0.6526]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2951, -0.5048,  0.1536, -1.2270, -3.7534,  3.4297]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0782, -0.2870, -1.7344,  4.9113, -2.2524,  1.2481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7043,  2.6416,  1.3474, -2.5641, -2.6603, -1.0166]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8801,  0.1845, -2.2704,  1.1753, -2.9902,  3.9263]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0057, -2.0402,  0.0054, -1.5076, -1.0331,  4.1979]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3127, -0.1193, -2.6371,  0.8927,  4.9394, -0.8998]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4095, -2.4052, -1.3605,  2.2759,  3.0658, -1.1893]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2440,  0.2210, -2.9615,  2.6448,  0.9226,  1.7924]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6216, -0.1636, -0.4699, -3.9371, -0.1908,  3.0013]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6054, -1.0966, -0.5541, -0.9398,  0.0405, -0.8771]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4460, -1.9511,  0.1687,  1.5807,  1.5803, -2.2452]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1240,  3.2877, -2.2845, -3.7043, -1.4286,  1.0959]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4678,  1.3476,  0.2144, -4.6049,  0.3691,  0.1359]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2331,  1.0749, -2.6645, -1.3535, -1.2994,  3.5852]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6187,  0.2378, -0.4741,  1.6685, -3.5564,  0.3655]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2338,  1.5642, -3.4449, -1.4669,  0.7231,  1.4945]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9646, -1.4426, -0.5572, -3.1872,  1.8047,  1.4837]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3358, -0.2400, -1.5437, -2.5463, -1.4915,  4.1016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1160, -0.0840,  1.0389, -3.4094, -2.7091,  2.3341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7322, -3.3334,  3.1408, -1.1343,  1.3259, -0.8905]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5320, -1.0552,  0.1300, -3.2045,  2.7603,  0.2680]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4406, -2.4336,  2.7921, -0.2475,  1.9018, -2.0783]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2905,  4.5846, -2.7503, -2.6112, -0.1197, -0.2871]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0907,  4.8355, -1.8907, -3.0070, -1.6690,  0.1787]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2344, -1.6738, -2.3248,  4.4198, -1.2162,  1.4341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1031,  5.0446, -2.2053, -2.5681, -1.2043, -0.2461]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2687, -0.5560, -0.0198,  4.9563, -1.9229, -1.3747]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0731,  0.9380,  0.9206, -4.5764, -0.7632,  1.0664]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2809, -1.5550, -0.3088, -1.5323,  0.7417,  0.8387]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5206, -2.2352,  0.7989, -1.8627, -1.4504,  2.7145]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7968, -1.5058, -0.1207, -2.5779, -1.2939,  2.7942]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1275,  1.1177, -0.5716, -3.7946, -1.7388,  3.1019]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1843, -0.8503, -1.5523,  4.5260, -2.3476,  2.0616]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1249,  5.1654, -1.8468, -2.4566, -1.2199, -0.6945]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4004,  4.6751, -0.8492, -3.3467, -1.2819, -1.0601]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0726, -1.7810, -1.0244, -1.6672,  3.9127, -0.4251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6757,  1.9252, -1.3451, -4.2195, -0.8777,  2.1991]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6508,  5.1719, -2.2703, -2.1994, -1.2607,  0.0209]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2980,  1.0502, -3.0779,  4.6949, -0.6309, -0.4369]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0352, -1.0446,  2.2535, -4.5024,  1.0791, -0.0940]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2746,  0.9466, -3.6546, -1.0318,  2.8671,  1.1579]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4522, -1.1649, -2.3578,  0.0524,  0.5325,  3.7244]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2541, -1.1991, -2.5763, -0.9253,  1.0597,  2.6298]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3923,  2.7804, -0.9332, -3.1360, -0.6705,  0.6542]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3764, -0.9706, -1.7428, -0.1876,  4.0931, -0.7502]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7795, -0.3443, -3.8120,  2.1765,  0.1388,  3.0804]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8080,  3.8312, -2.4452, -2.4252, -0.8073,  0.0340]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7998,  1.5742, -3.2210, -0.0776, -1.6020,  1.9653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4796, -0.2884, -2.2887,  1.9636, -2.0035,  4.0015]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0170,  5.0166, -1.6355, -2.9149, -0.9248, -0.7191]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5370,  4.7736, -1.6997, -3.1082, -0.8981, -0.8288]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5503,  4.2847, -2.0875, -3.1140, -1.0964,  0.0945]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1603,  0.3849, -3.2047,  4.2564, -1.5807,  1.0855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1391,  4.3185, -2.5268, -2.6313, -1.8628,  1.3040]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9664, -0.5326,  2.0445, -4.0819,  1.4159, -0.8895]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0742, -1.5983, -1.2930,  0.2542, -1.2735,  3.8706]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4373, -3.7968, -0.3746,  3.3069,  0.8137,  1.0975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5425,  3.5691, -1.5789, -3.4397,  2.0388, -1.3670]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8214, -0.6241, -2.4453,  2.6681,  3.4039, -1.6395]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2861, -0.1576,  0.7765, -4.5259,  1.2618, -0.2530]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5467,  2.1963, -0.6126, -3.3032, -1.5440,  1.3001]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6955,  1.8668, -2.7772, -3.7283,  1.9780,  1.2681]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1592, -2.7870,  1.6023, -3.0334,  1.9145,  0.7151]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0816, -1.5859, -2.5107,  3.4402,  3.0677, -0.1453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6411,  4.1732, -2.0346, -3.6690,  0.4639, -0.6050]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2196, -1.1136,  1.2605,  4.3481, -2.7866, -0.8997]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2999, -0.6587, -1.4452,  3.8436, -2.6183,  2.5915]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2211, -2.1560, -0.2808,  5.3188, -0.7457, -0.7628]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9873,  2.3899, -1.2291, -1.2823, -1.4528, -1.0864]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6310,  1.7180,  1.2517,  0.2570, -4.2345,  0.7667]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1364,  2.0835, -0.9997, -2.4504, -2.6814,  2.2505]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0932,  0.2116,  3.0680, -3.0225,  0.6482, -1.8267]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5367,  2.8166,  1.0936, -3.1163, -2.1302, -0.5231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2796, -1.7253,  2.4750, -0.7637, -3.3334,  2.2255]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0110,  4.7788, -1.2869, -3.2357, -1.7338, -0.1343]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0450, -0.1510, -2.8941,  4.5591, -0.1620,  0.1580]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5241, -0.1678,  2.0210, -3.2143, -2.9525,  1.9823]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0156,  4.5902, -0.6296, -3.0644, -2.4070, -0.2486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1336,  0.7108, -0.1140,  4.6314, -2.7076, -0.3387]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7834,  0.2355, -0.0348,  1.3758,  1.9210, -2.3048]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0033, -1.4706,  3.6065, -1.1727, -2.7792,  0.2286]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0990, -2.3387, -0.3935,  4.4237, -1.7837,  1.0485]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8553,  2.2055, -3.5143, -1.9193,  0.8174,  0.0674]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6502,  0.9628, -3.5409, -2.9456,  1.4555,  1.5122]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3628, -0.5677, -1.6416, -3.1919,  1.2731,  2.3555]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0345,  0.9518, -4.2408, -0.7630,  0.4507,  3.2486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8700,  2.5774, -3.2845, -1.4939, -1.4941,  3.2135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3485,  2.7581, -2.0038, -2.5309, -2.1347,  2.6019]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1188,  4.7066, -3.0861, -1.7274, -1.3149,  0.5365]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6728, -3.4129,  2.8675,  0.8706,  0.3625,  0.0561]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2284,  1.0427, -2.1426,  0.0242, -2.9692,  3.9727]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9962,  0.2623, -1.7052,  1.3074, -2.4056,  3.3531]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8532,  2.6878, -1.8312,  0.9755, -1.7440,  0.7653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2072, -0.2123, -1.1053,  0.6454, -3.5390,  2.2453]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1546, -2.6351,  1.0562, -2.1975,  2.7840, -0.3435]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6151, -1.5063, -0.2739, -2.6185,  3.7189, -1.4442]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5305, -2.4252,  2.2610,  0.3422, -1.9345, -0.7293]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1813,  0.0638, -1.8338,  5.0995,  0.0903, -0.3024]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1554, -0.3362, -1.0802,  5.6192, -1.3911, -0.2013]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3881, -2.2147,  3.1007, -0.8250,  0.3932, -0.9296]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2257,  2.6689, -2.0562, -4.0658, -0.4187,  2.0914]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9782,  3.0524, -3.4613, -1.4067, -0.0759,  2.3510]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9626, -1.1466, -0.2844, -0.3561, -2.1950,  1.8417]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0572,  2.6402,  0.6321, -2.7308, -2.9700, -0.3172]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5770,  3.3267, -0.0511, -1.8662, -3.8904,  1.1929]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1997, -2.2409,  4.0925, -1.0753, -2.1326,  0.9401]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1862,  2.9214, -1.9191, -1.0929, -1.1960,  1.0947]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2525,  1.7349, -3.5604, -2.4960, -0.2622,  3.1055]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6741,  4.9664, -2.2110, -2.5622, -1.3574,  0.4427]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6471,  3.7203, -3.6149, -2.0409, -0.4137,  2.0205]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7582,  4.2671, -0.8653, -3.1757, -0.9215, -1.3162]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0035,  1.8323,  0.9965, -4.6007, -0.0540, -1.2843]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4981,  2.9812, -3.2900,  1.0345, -2.1454,  1.4857]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4608, -1.8014,  0.9440,  1.5590,  0.6746, -0.0874]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1353,  1.1828, -0.1211, -2.8386, -2.8807,  2.9724]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5589, -0.3801,  3.6235, -3.9907,  0.5110, -1.7199]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3767, -0.1303, -0.5462, -4.0622,  2.9468,  0.5425]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1042,  0.8061, -4.1617,  0.7502,  1.1621,  2.1697]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1922, -2.2830,  3.9620, -1.9874, -1.4650, -0.9066]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3664,  0.7898, -0.2801, -4.4714,  1.0512,  0.8536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8459, -1.2490, -2.0617,  5.4052, -0.5915,  0.7456]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6201,  5.0712, -1.5634, -2.5837, -1.7372, -0.0513]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0346,  5.0050, -1.0760, -2.9076, -1.3162, -1.0209]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7208,  4.0105, -0.8016, -4.1214, -0.4746, -0.7397]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6590, -1.6908,  3.7952, -2.7499, -1.3675, -0.0853]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5744,  3.7786,  0.2822, -4.1675, -0.5909, -1.1426]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8624, -1.1271,  2.4970, -4.4829,  1.4647, -0.4998]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8655, -0.0410,  2.0968, -1.7111, -2.6857,  0.8132]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3233,  1.9123,  0.2232, -2.8198, -3.3520,  2.2523]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9216,  1.5520, -0.9616, -2.7449, -1.6375,  1.6496]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0265, -0.1011,  1.6399, -4.0666,  1.3367, -1.1701]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5292, -0.9191, -2.5058,  4.9426, -0.8799,  1.2120]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0048,  1.0861, -2.5874,  1.1363, -2.4682,  2.3833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4130, -1.5698, -1.7041, -0.1525, -1.4342,  4.7146]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6556,  5.1054, -2.0519, -2.3485, -1.5562,  0.1374]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3506,  4.9601, -2.8268, -2.3524, -0.3444, -0.0346]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1543,  2.2610, -1.0524, -4.2345, -0.8331,  2.3753]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6936,  1.9200, -2.1554,  1.8296,  0.0225, -0.8067]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4814,  2.3576, -0.5808, -2.5132, -1.6891,  0.0723]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9485, -0.3216,  0.9617, -3.9721,  0.5370,  1.5660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2934, -0.6186, -1.3823, -1.1625,  5.5215, -1.0772]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6398, -0.6183,  3.5058,  0.2244, -3.3872, -0.6371]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6153,  0.1614, -1.1740, -0.8831, -3.1866,  3.3228]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4047,  5.0593, -1.7769, -2.7985, -1.3421, -0.1530]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7471,  5.0838, -2.5585, -1.4465, -1.7896,  0.1696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6555, -0.8212,  2.9347, -1.6744, -3.1282,  1.1444]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2750, -0.8387, -1.2684, -0.7913,  5.5371, -1.1686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7083, -1.7072,  1.8037, -2.7819, -0.2655,  1.2680]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8885, -1.2212,  2.0116, -4.0973,  2.5175, -0.9767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3458,  2.0847, -3.3987,  2.9664, -1.9081,  1.7449]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7513,  4.5244, -1.7763, -2.0537, -2.7005,  0.9790]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3571,  1.9904, -2.6433,  3.6709, -0.7216, -1.4613]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4835, -1.7333,  4.7948, -2.3064, -1.5512, -1.1144]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2482,  3.6051, -1.7595, -2.9383, -1.7911,  1.0277]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3730, -3.0822, -0.0120,  1.8712, -1.4335,  2.8720]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5577,  5.1023, -1.4994, -2.6589, -1.6070, -0.1928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5058,  5.0808, -2.2175, -2.4479, -1.4328,  0.1068]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2012,  4.1188, -0.9913, -3.7466, -1.7726,  0.2677]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8564, -3.4586, -0.0720,  2.5290,  1.9672,  0.0377]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1512, -0.3232,  0.2807, -3.6596, -0.1275,  0.9954]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5879,  5.1268, -2.3164, -2.3477, -1.1126,  0.0325]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.7528e-01,  4.9950e+00, -2.8700e+00, -2.1533e+00, -6.7172e-01,\n",
            "         -1.6925e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3773,  1.3329,  0.5962, -1.2154,  0.1362, -1.7604]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1140,  3.8998, -2.2066, -3.5904, -1.3117,  1.2789]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9118,  3.2818, -1.6983, -4.0559,  1.1216, -0.2152]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1785,  3.1335, -2.4208, -3.8006, -0.5946,  1.8986]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5323,  3.0212, -2.7285, -3.5213,  1.6853,  0.4591]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4001, -3.6456,  2.2499,  0.5081, -1.0408,  2.2316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0354, -2.2565, -1.3355, -1.1251,  0.1199,  2.5821]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0298,  2.0077, -0.3788, -2.3120, -3.5774,  2.4641]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5691,  1.5369, -1.5170, -2.0026, -2.2694,  2.4747]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3711, -1.0571,  3.0169, -3.0902, -2.8087,  1.1530]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4632, -1.6977, -0.0262,  4.8397, -1.8601,  0.5640]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9143,  1.1926, -0.5794, -3.9077,  3.8171, -1.2092]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5796, -1.5994,  1.7924, -1.0407,  0.5058, -0.3779]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5431, -1.7549,  2.6106, -2.8769, -1.3853,  0.2806]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1507, -1.0574, -2.5799,  1.3833, -1.0244,  3.3817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5496, -1.0756, -2.2878,  0.6690, -1.4985,  4.3933]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0247,  1.8598,  0.4822, -2.9114, -2.6172,  0.5150]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5658,  1.5664, -1.1841,  2.6493, -2.1852,  0.4335]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1536,  3.6214, -3.7323, -1.8332,  0.3311, -0.1724]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6496, -1.9616,  4.3270, -3.1261, -0.3863, -0.8175]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6794, -1.5548, -1.1082,  3.9170,  0.4171, -0.5684]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2797, -1.5479, -0.2014, -2.2866, -0.8332,  3.9739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2126, -1.4705,  0.6732, -0.4272, -0.1665, -1.4977]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0513,  4.5030, -1.2790, -3.1513, -1.7144,  0.0159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3873, -2.3366,  3.5551, -0.5549, -0.5374,  0.0922]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4711, -1.3926,  0.2904, -2.3386,  1.6947, -1.6656]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9170, -2.2746, -0.7985,  4.6893, -0.2237, -0.6000]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3219,  0.7064, -1.0918, -2.4872,  3.3901, -2.3257]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6081,  0.5096, -3.2358,  2.1237, -0.9346,  2.6022]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0197,  0.3759, -1.7506, -2.9633, -0.9036,  3.9314]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3719,  4.9512, -1.4170, -2.9793, -1.6382, -0.0652]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4286,  4.3432, -1.2440, -3.9218, -0.6160, -0.4566]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4374,  5.0035, -1.3083, -1.7883, -2.3427, -0.4224]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9523, -2.2456,  0.6311,  0.2218,  4.0388, -1.3963]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2735,  0.7768, -2.2210, -2.3351,  4.4851, -1.1186]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9005, -1.6141, -2.7443, -0.5589,  2.3142,  2.3538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9088,  0.2805, -2.2109,  4.6641, -2.4731,  1.2186]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4636, -2.6968,  3.3606, -1.8544, -1.1648,  0.8528]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9044,  2.2873, -3.2237, -0.8785,  2.3505, -0.7974]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9994, -1.3340, -1.0051,  5.1655, -2.0386,  1.2093]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8771, -1.6485,  1.9621, -1.4922, -2.9812,  1.3351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7692, -0.7900,  0.9754, -4.1125, -0.8901,  0.7943]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6778, -0.5015, -1.1393, -0.7404, -2.3738,  4.4587]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6986,  5.1504, -2.2864, -1.9652, -1.6482,  0.1396]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1006,  4.5873, -3.4275, -1.7110,  0.4696, -0.2238]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4247,  2.5789,  1.3469, -4.0293, -1.4726, -1.3901]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4844, -2.1686,  1.4158,  0.3234,  2.2438, -3.0975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4634, -2.3682, -0.8515,  1.5593, -1.7441,  4.0432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2024,  2.0667, -3.6019, -2.7923,  0.1682,  2.7232]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5516,  2.2634, -0.6655, -2.6275, -0.6582, -0.3642]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6006, -0.2709, -2.4012, -1.8567,  4.3434,  0.5341]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.7511, -1.9062,  1.1432, -1.6246,  0.7736, -2.1138]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9849,  3.1034, -2.0571,  2.3885, -2.9923,  0.4023]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7210,  1.9574, -3.5350,  2.9014, -2.2120,  1.4202]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3401,  0.7673, -2.5610,  4.2046, -2.4936,  1.7214]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1365,  5.0124, -1.4240, -3.0002, -1.3250, -0.4830]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4426,  4.7300, -1.5143, -3.1986, -0.3750, -1.1834]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4243,  3.8834, -0.7594, -4.1693, -0.7750, -0.0431]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0786, -0.6196,  4.6342, -3.1895, -0.3242, -1.8854]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0691, -1.4113, -0.9528,  4.6467, -0.3589,  0.0808]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0183, -0.0377, -1.2435, -2.4756, -0.1086,  1.2893]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1843,  1.0700, -2.6200, -1.8959, -1.2662,  3.6851]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2869, -1.2258, -2.3797,  5.0607, -0.1009,  0.6444]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.3555, -1.9668,  0.6547, -1.6661,  1.5701, -1.6006]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1325,  2.7514, -0.6374, -3.5876, -2.6268,  2.0281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3683,  5.1557, -1.8277, -2.5261, -1.5235, -0.3293]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4872,  0.6917, -2.7438,  4.7569, -1.9191,  0.4629]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8425, -0.8596,  3.6555, -2.2641, -2.3699, -0.9880]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1988,  0.5780,  3.7919, -3.7290, -0.9278, -1.6681]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5335,  0.5044, -0.0550, -3.6484,  3.7757, -1.6329]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1433e+00, -2.3527e-04, -3.6390e-01, -2.3509e+00,  4.8275e+00,\n",
            "         -1.9943e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3237, -1.2725, -0.9118, -0.4971, -1.8379,  4.4119]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1758, -1.6042, -1.8084,  4.5851, -0.6332, -0.3555]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4572,  0.1635, -3.0841, -0.4745, -1.1234,  4.2388]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2791,  4.2816, -0.9829, -3.8264, -1.6718,  0.0553]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1643,  2.9518, -1.7784, -3.3031, -1.4076,  1.7075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1577,  5.0247, -1.6846, -3.0060, -0.9919, -0.5087]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9901,  3.8256, -0.2228, -3.5962, -1.7450, -0.9116]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2662,  2.8655, -2.2396, -3.6990, -0.8899,  2.0666]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0275, -0.9549,  3.2629, -3.6789, -1.7665, -0.0039]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6013, -2.0463,  1.7144, -3.3019,  0.4122,  1.5229]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9966,  3.5486, -0.9725, -3.3034,  0.3243, -1.4225]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5508,  0.0213, -2.0790, -1.2144, -0.1888,  3.7756]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4241,  2.5761, -3.1810, -3.2301,  1.1899,  1.3109]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4999, -0.4592, -2.3580, -1.5678, -0.6256,  4.5890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1138,  4.4920, -2.5877, -2.9855,  0.7240, -0.2934]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6166,  3.0232, -2.2958, -3.4482,  2.5961, -0.8151]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2536,  1.5514,  2.7085, -4.4901, -0.6231, -1.3274]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3191, -2.1043, -1.5688,  1.0899,  4.5447, -0.2201]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2657, -1.3551, -2.9540,  0.1271,  2.4581,  2.3455]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9029, -1.3228, -1.4059, -1.5776,  0.2965,  3.1352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6226,  4.3422, -0.5535, -3.3482, -2.1829, -0.6216]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2787,  4.0724, -1.5241, -3.3145, -1.6024, -0.4609]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5209,  0.9551, -2.1274,  3.3610, -2.0971,  0.0643]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5382, -0.8036, -1.1898,  0.6603, -2.9280,  4.0506]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0345,  0.7651,  0.3232, -4.0528, -2.1181,  2.1550]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5593,  3.6142, -0.7418, -2.3577, -1.6830, -1.4697]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8424, -1.0999,  1.7297, -1.1660, -1.6744,  0.2134]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7111, -2.1472,  3.9595, -0.7574, -2.5426,  0.4872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5354,  0.2047, -1.2783,  2.1565, -2.5839,  1.3733]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0097,  4.6942, -1.5221, -3.5042, -0.8045, -0.1159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3223,  1.3659, -3.3334, -0.5957, -1.6907,  3.3743]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9479, -1.5470,  1.9537, -2.3599, -2.0891,  1.2576]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7610,  2.0565, -3.1661,  1.2068, -2.5553,  2.5679]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5260,  0.7287, -2.8663, -0.6097, -1.0126,  2.7732]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 4.3939e-01, -1.9346e-03, -1.4233e+00, -3.5618e+00,  1.2580e+00,\n",
            "          2.7051e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4923, -1.2548, -1.0663,  5.2337, -0.6902, -1.0167]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4893, -0.5828,  3.1324, -0.1596, -3.1279, -0.9767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4895,  2.1790, -2.1191, -2.5815, -0.9628,  2.1211]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6531, -1.7199,  1.7396,  0.5846, -2.6199, -0.6475]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4754, -0.2003, -0.6944, -3.6206,  3.9159, -0.4195]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1601, -1.8831, -1.9442,  3.4611,  2.0569,  0.5758]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1914, -0.8072, -0.5403, -2.1136,  0.1191,  1.1994]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7608,  0.7070, -2.4892, -1.8007, -1.3464,  4.3294]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1346, -2.7097,  1.6749,  0.6185,  2.9731, -1.7796]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4272,  1.7245, -2.0429, -4.1679,  1.4809,  1.6843]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6301,  0.1667, -2.7147, -1.2287,  0.1371,  1.8775]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1345,  0.7518,  2.3562, -1.6517, -1.2112, -2.7316]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4141,  0.2322,  2.7885, -2.0595, -1.9874,  0.1505]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1905,  1.5164,  1.0656, -4.4155, -0.8713, -0.8186]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8201, -1.4393,  3.5221, -2.7740, -1.7394,  0.7135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6916, -1.2284, -3.4709,  0.9383,  1.3899,  3.5700]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1600, -0.1378, -2.6206, -1.5869,  4.1757,  0.0229]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8388, -2.5919, -0.9153,  2.5580,  0.8931,  0.9409]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5281, -1.4661,  4.8365, -1.2765, -2.1839, -0.7984]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5746, -1.5582, -2.7395, -1.0233,  2.8531,  1.6285]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6377, -0.8239, -1.9054,  5.3957, -0.8648,  0.4438]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3816, -1.7566, -1.2807,  3.1487,  2.2082, -0.5674]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1894,  1.4431, -2.5963, -3.5661,  2.8036,  0.5826]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2969, -1.2422, -2.0214,  2.5184,  2.9158, -1.5534]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4766,  0.4991, -3.9032,  1.9865,  0.5940,  0.2352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4670,  5.0178, -2.2635, -2.2784, -1.5058,  0.2024]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3880,  5.1931, -2.0306, -2.1226, -1.6724, -0.3473]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7067, -1.6158,  4.6446, -0.9344, -2.2938, -0.7850]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1840, -2.3344, -1.1282,  2.8998, -1.2524,  2.8751]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3499,  5.0231, -2.0640, -2.7091, -1.0943,  0.0406]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2359,  3.7028, -3.5889, -2.4750,  0.6784,  0.8225]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6771,  1.6276, -1.9876,  0.4785, -2.8822,  2.6719]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9363, -3.7697,  2.6925, -0.8088,  0.5200,  1.3066]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1347,  0.3950, -3.3554,  3.3734, -0.8553,  2.2055]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2250, -1.7407, -0.4553,  3.8160,  0.5315, -0.3345]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3752,  5.2003, -2.0435, -1.7980, -1.5516, -0.5478]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1999,  4.7613, -2.6913, -2.3424, -1.4419,  0.4633]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4927,  4.0653, -0.2231, -3.8215, -1.9683, -0.3979]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3701, -0.2612,  2.8180, -4.1612, -2.2427,  0.7876]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9432, -0.5459, -0.7710, -3.8502,  3.4220,  0.8633]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7131, -1.8099,  0.5225, -0.3846,  2.9223, -2.8081]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8202, -3.6777,  1.3675,  0.7702,  1.0653, -0.3198]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5745,  2.7809, -3.0673,  0.7705, -2.3498,  2.6721]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5247, -1.7355, -1.4001, -1.6624,  4.4762,  0.0165]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1393, -0.0876, -1.3053, -3.7273,  2.1893,  0.4492]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2038,  4.6683, -1.9687, -3.2700, -0.0723, -0.5114]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1351,  5.1049, -2.2064, -2.6122, -0.8549, -0.5096]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3104,  3.1719,  0.5832, -3.9571, -1.3499, -1.2741]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9390, -1.2946,  3.7816, -1.0626, -2.0594, -0.5776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2618,  1.7761,  1.7647, -4.6350, -1.2096, -0.3985]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9586,  2.1079, -1.4924, -3.9758,  2.8806, -0.7455]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0224,  5.0024, -1.8429, -2.6964, -0.5087, -0.8985]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5103,  5.0562, -2.6173, -2.1922, -1.1884,  0.1736]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3564,  4.2426,  0.0937, -3.6382, -1.6306, -1.0340]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1040,  0.8375,  2.9544, -4.2473, -2.1599, -0.1563]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0518, -2.0149, -0.0156, -1.6766,  3.0737, -0.3181]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2514,  1.7718, -0.4904, -2.0832,  1.0216, -0.9889]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2323, -1.3925, -2.3431, -0.6171, -0.5971,  4.6246]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9930,  1.0870, -1.7294, -4.2939,  1.0481,  1.7789]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5683, -2.7144, -0.8998,  2.1821,  3.6474, -0.4485]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8139,  2.3032, -2.9050,  0.6408, -2.1127,  2.4187]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6097, -2.0268, -1.6192, -2.3283,  2.0900,  2.2793]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0623, -1.7808, -2.3873,  3.1700,  3.1911, -0.0890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1974,  2.0296, -3.2501, -3.2982,  1.1021,  0.1597]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4688,  3.1780, -2.1384, -0.7825, -3.0005,  1.1184]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3151, -1.7153, -0.4188,  5.1808, -0.3275, -1.1845]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1570,  0.2838, -2.6881, -1.6019,  4.8728,  0.0393]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8561, -1.8752, -1.7035,  0.0414, -1.5301,  1.9092]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1319, -1.6226, -1.0704,  1.7888,  2.7888, -1.0661]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5296, -0.1233, -1.2846,  0.0708, -3.5012,  4.0462]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0688,  0.0552, -3.2492,  2.6569, -1.7245,  2.4800]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6370, -1.6807,  0.7515,  0.3302,  1.5232, -2.4005]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9577,  0.5593, -2.0652, -3.8037,  2.4432,  1.4979]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0753,  1.5403, -0.7884, -4.0390, -0.2752,  1.4082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4627, -0.4284, -2.7310, -2.3623,  1.0023,  3.5016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4608,  0.3013, -1.8520, -3.2701,  0.0306,  3.2274]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6762,  2.0044, -3.2588,  1.3601, -0.2097,  1.3577]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3936, -0.3514, -2.2213,  0.7873, -2.8562,  3.5146]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1434, -2.0458,  0.4664, -1.4687,  2.1971,  0.7891]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4943, -3.3751,  3.2079, -2.0700,  0.2397,  0.7744]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5151, -1.1373, -1.6307,  5.2961, -1.2373,  0.5414]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1722,  1.5948, -1.3875, -4.0076,  2.3532, -1.3721]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6981,  0.3301, -2.9212, -2.5264,  3.9666,  0.8590]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9488,  2.0123, -4.1826, -1.9834, -0.2077,  2.2634]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5743,  3.1688, -1.1886, -3.9165, -1.7743,  1.2110]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1844, -1.7964, -0.3420, -0.0759, -1.9493,  2.8216]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0449,  3.0974, -3.4934, -1.9542, -1.1872,  2.0343]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2702, -1.9721, -1.9187,  2.3802, -1.3431,  2.0603]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8059,  4.5197, -3.2689, -1.5789, -1.3953,  1.2571]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0103,  0.0294, -1.5271, -3.0205, -0.4822,  2.9785]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3116, -0.0078,  1.1033,  2.2553, -4.0632,  0.3144]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1410,  0.2417, -3.0532,  2.6621, -1.5592,  3.0990]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0566,  4.6974, -1.5396, -2.8232, -2.2803,  0.2636]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4216, -0.6658, -1.6076,  5.5994, -1.2167, -0.2885]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6792, -0.8156, -0.2963, -3.0977,  0.2665, -0.5161]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6242, -1.9958,  0.4600, -0.2469,  1.1455, -2.4870]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8009, -1.0036, -1.9046, -0.7131, -1.7332,  3.8861]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1517,  1.7686,  0.1816, -5.1413,  0.3299,  0.2810]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8961,  0.7497, -3.1601, -2.0420,  1.2460,  0.8287]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8178,  0.3631, -2.0743, -2.8597, -1.1863,  3.5198]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2577, -0.7429, -1.0080,  5.4147, -1.8690, -0.3115]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6065, -0.2305, -2.1776, -1.6928,  5.0592, -0.3606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2437, -0.3609,  1.3003, -3.8585,  0.8772, -1.7840]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0345, -2.9175, -0.7246,  2.3917, -1.0006,  2.9845]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9274, -1.3714, -0.2167,  4.6011, -1.0168, -1.3617]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1227, -0.3924, -3.1463,  1.7002,  3.4679, -0.9407]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7508, -1.4836, -0.0067, -1.8307,  4.3022, -1.2629]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8608, -1.1690, -2.2179,  4.0518, -1.8852,  2.6013]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4609, -1.9968,  2.8367, -0.9486, -2.3422,  0.9470]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0889,  2.5605, -3.3642,  0.9928, -2.2532,  1.3129]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5666,  2.0747, -2.1440,  0.6068, -0.0651, -1.1900]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4758,  3.9047, -2.0928, -3.7321, -0.0305,  0.2838]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3043,  1.8826, -3.9424, -1.7615,  0.3404,  3.0385]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2162, -1.2489, -3.0720,  1.3559,  2.4247,  1.6026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5513, -0.1314, -1.3625, -2.2182, -1.2365,  4.3130]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1280,  2.5095, -1.7842, -0.9191, -3.4454,  2.9814]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1981, -0.2957, -1.7466,  1.3100, -2.9295,  3.5352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1080, -1.9928,  2.9252, -0.4449, -2.7215, -0.1619]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5317, -2.0594,  0.6911,  2.0463,  0.1610, -2.1824]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4530, -0.7641, -2.4930,  4.9259, -0.8869,  1.7040]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5293, -1.1915, -3.5156,  0.6974,  1.4081,  3.5690]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1435,  5.1132, -2.1364, -2.5003, -0.8179, -0.6776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8195, -1.7315,  0.1393,  4.2366,  0.6216, -2.1227]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4536, -1.6975, -0.5616, -0.3063,  4.5040, -1.5606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3497, -1.4568,  3.0986, -0.8959, -3.7491,  1.5535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6186, -2.5212, -0.7627,  2.9501, -0.9860,  1.6189]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2487, -0.2765,  0.1756, -2.1252, -3.2205,  3.5416]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6216, -0.2626,  1.4675,  1.1200, -3.8045, -0.3638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8247, -0.9885,  1.2076, -0.3590,  1.2050, -3.1427]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1689, -0.6051, -1.4246,  4.8374, -2.5103,  0.3889]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1816, -2.3221,  0.2599,  0.0160, -1.7490,  4.0539]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5770,  3.5410, -3.2079, -2.2258, -1.3566,  2.3846]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2944,  1.9448, -3.0445, -2.4509, -1.1086,  2.9802]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8171, -1.3356, -2.5880,  3.9422, -1.1505,  2.5921]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7850, -0.3425,  3.1508, -2.6062, -3.0797,  0.7583]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0307, -2.1444, -2.2110, -0.3081,  4.3438,  0.5448]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8966,  1.8974,  1.3238, -3.0732, -3.1754,  0.3535]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6431,  5.2587, -2.3023, -1.8093, -1.2914, -0.3455]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9715,  0.7474, -0.9726,  1.9732,  0.6198, -2.9061]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4831,  0.2372, -2.5405,  4.7504, -1.7151,  1.5710]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5790, -1.3796, -0.6625,  3.9455,  0.3475, -2.1743]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7290,  0.7623, -3.1330, -1.8800,  3.8635, -0.8273]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.8606,  1.2675, -2.9208, -2.2973,  1.9753, -1.0017]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4985, -1.5292, -2.2979,  3.5546,  1.5963, -1.0430]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0578, -1.7553, -0.1259, -1.2602, -2.1633,  3.5763]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2381, -2.4316, -0.6317,  0.7105, -1.4939,  4.0764]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4895, -2.1819,  0.0327,  3.1831,  0.2826, -1.1973]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0185,  1.3752, -2.8683, -0.6755, -2.4531,  3.3253]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4085,  1.2096, -1.9746, -2.7699, -0.0045,  1.6110]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3355,  2.6656, -1.9477, -1.8104, -3.0541,  2.5890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1424, -1.0767, -1.6844, -0.9405,  5.3323, -0.2514]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3064,  2.4575, -2.0869, -3.2168, -1.7749,  1.5164]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7735,  3.8667,  0.3244, -4.0468, -1.0169, -1.2828]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0047, -0.6363, -0.9277,  3.9844, -0.9689,  0.1784]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2296,  0.6260,  0.1940, -2.3544, -3.2847,  3.0386]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2662, -1.7509,  0.5620, -2.2067,  3.2055,  0.1109]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6020, -1.6749, -0.4590,  5.0044, -0.0299, -1.6172]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0446, -3.7368,  1.9776,  1.7249, -0.7243,  1.6688]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0798, -0.1101, -2.4392,  1.5270, -2.4031,  4.0149]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4553, -0.4458, -0.7565, -1.9632, -2.1555,  4.3276]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 8.7082e-01, -1.9880e+00, -1.8290e+00,  1.0822e+00,  3.9975e+00,\n",
            "          1.8780e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2050, -1.2318, -2.5793,  4.6804,  1.3412,  0.9174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3186, -3.2937,  0.7973,  3.3826, -0.8696,  1.5149]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4773, -0.8619,  0.7171, -1.6307, -2.8918,  2.2133]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7784,  0.3810, -3.1750,  0.1473, -1.8024,  4.3100]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3591,  1.2119, -1.6563, -3.2559,  4.0232, -1.2382]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6419,  0.3641, -4.3892,  1.0142,  1.4422,  2.7105]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6897,  1.1234, -0.5345, -4.8332,  0.2076,  1.7855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5655,  5.1496, -2.3231, -2.0586, -1.4629,  0.0074]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2615,  3.4478, -1.5856, -2.7875, -2.8338,  1.9445]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7598,  1.5785, -2.8609, -2.6554,  3.7961, -0.2643]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6589,  2.1748, -2.3207, -2.9502,  3.5965, -0.8351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0481,  0.3162, -2.0753,  1.7923, -1.0338, -0.1481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7459,  2.0892, -3.5241, -2.2834, -0.0483,  3.2660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9015, -1.8283, -1.1125,  4.7845,  0.2396, -1.2352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6705, -0.1974, -2.4157, -0.4871,  4.4832, -1.5755]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5260,  0.4272, -3.2932, -1.0323,  1.1844,  0.2626]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0664,  0.5351,  0.3040, -2.8650, -3.1897,  3.1613]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6104, -1.9527, -2.2644,  3.1843,  1.4531, -0.4780]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3715, -2.8099,  0.1306,  3.3809, -2.2684,  1.7939]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1114, -1.6489, -2.7304,  1.9377,  0.5313,  3.6077]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0048, -0.8067, -2.0296,  3.6014, -2.3180,  2.7759]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7056,  0.9385, -1.0355, -2.2452, -2.6376,  3.8563]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9938,  1.8708, -3.1511, -1.1508, -1.3291,  3.6795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0665,  1.0225, -2.5447, -3.6859,  1.8767,  1.6923]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6555,  1.1844, -2.7039, -1.6361, -1.8134,  4.0820]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6673,  1.9278, -1.5110, -4.4802, -0.2066,  1.9611]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4655, -1.0057, -1.5422,  4.0630, -2.6552,  1.1495]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0296, -0.7417, -2.3595, -2.2240,  0.8079,  3.9041]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2059, -0.4030, -0.6481, -2.1550, -2.1638,  4.2079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3522, -1.2647, -0.9949,  2.7031, -3.1903,  3.1093]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5755, -1.6338, -2.0189,  0.4013,  4.8562, -0.4205]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.4917, -2.0558, -0.8857,  0.8245, -0.1381, -0.4220]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3916,  0.3070,  2.1217, -1.1449, -2.9955, -1.5594]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.1452,  0.2807, -0.6435, -3.2675,  1.0377, -0.6994]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9235,  0.4953, -0.1807,  1.3828, -3.7664,  2.5322]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4212, -1.8465, -2.3633,  2.9596,  3.3553, -0.3474]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2124,  1.1977, -2.7724,  0.6195, -2.5119,  3.8061]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1565, -0.1474,  0.0562, -0.5599, -3.9306,  3.4281]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3276,  1.8520, -3.6997,  0.8452, -1.7182,  2.0104]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2000, -0.8121, -1.2551,  1.3079, -2.7529,  4.1810]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0995, -1.8119,  2.0111, -2.7753, -1.9965,  2.5391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2216, -2.0270,  0.5284,  0.3517, -2.5932,  3.6661]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1848, -2.6813,  2.8191,  1.5795, -3.1710,  1.2397]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0222,  2.2665, -3.2282, -2.2272,  0.4378,  3.0049]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6155,  5.0835, -1.9992, -2.3628, -1.6361,  0.1496]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2390,  4.0311, -0.7480, -3.7763, -1.3884,  0.0151]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6332,  3.5006, -1.9236,  0.6663, -3.5012,  0.9204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4343,  0.3705, -0.1037,  0.5165, -4.0390,  0.9982]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5398, -0.9796, -1.1320, -2.5969, -0.9106,  4.0553]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5362, -1.7655, -0.3294,  2.4972,  0.5796, -2.2198]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6599, -0.3794, -1.1580,  1.8297, -3.1434,  2.0160]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0944,  0.3314, -1.3009,  1.0224, -3.6123,  3.7356]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9967, -0.1344, -3.1178,  0.9205, -1.5001,  4.3284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7466,  0.9851, -0.7592,  0.6170, -3.4685,  2.7715]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1679, -2.5170, -1.4352,  3.5818, -0.0179,  1.9434]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1297,  0.9081, -1.5275, -1.7838, -3.1646,  3.7767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0385, -2.5902,  1.2388, -0.0235, -2.4398,  2.5876]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7428,  3.2384, -1.2331, -2.3543, -3.0954,  2.2588]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1269,  0.5529, -1.4898, -1.8240, -1.9644,  3.4104]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2722,  1.9303, -3.8651, -2.2220,  1.2239,  2.6273]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7524,  0.2550, -1.7087, -1.7282, -2.0753,  4.4746]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2267,  1.5113, -2.8784,  2.0758, -2.8400,  2.8705]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3748,  4.1749, -1.8695, -2.4895, -2.6961,  1.3231]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8460,  4.6603, -2.9466, -1.3682, -1.9171,  1.1054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4364, -0.7071, -1.3259, -1.2312,  5.4724, -1.1288]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0768, -1.7676,  2.0333, -0.9501, -2.3956,  1.6175]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2182, -1.0398, -0.1229,  2.1389, -2.4927,  2.9174]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7264, -2.0960, -0.0539, -0.0481, -1.8147,  4.3926]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3118,  1.7483, -1.9889,  2.7516, -3.1224,  1.7765]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4925,  2.8899, -2.4951,  0.7407, -3.1444,  2.3616]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5441, -0.4914, -2.2479, -1.3564, -0.3967,  4.3164]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7057, -1.8707, -2.3789,  3.3367, -0.9906,  3.0956]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0985,  2.9492, -2.2368, -3.1819, -1.4378,  2.1241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3680,  0.3386,  0.0882, -1.1550, -3.9231,  2.8079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1675, -0.4186, -1.6451,  1.7985, -3.0407,  3.9738]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0765,  1.5638,  0.0113, -4.2965, -1.7207,  2.3701]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.5207, -1.1798, -1.9164,  4.1463, -1.5832,  2.6970]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5622, -1.7512,  2.9773,  0.1365, -2.9960,  0.7744]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6832, -0.5753, -1.2978,  5.0893, -2.4135,  0.7932]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0475,  0.2710,  2.4679, -2.8166, -3.1360,  1.6199]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2181,  0.1409, -0.1514,  2.3675, -4.0163,  1.3860]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1766, -0.2745,  1.7882, -0.9934, -3.8935,  1.1054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7582, -0.9316, -0.5490,  2.8904, -2.5928,  2.4523]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7513,  2.5997, -3.5654, -0.7346, -1.4607,  3.0270]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2493, -1.1605,  0.0853,  4.0950, -2.3992,  0.2192]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3898,  3.1104, -3.3553, -2.6829, -0.1431,  1.5338]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8075, -2.4334,  3.3648, -3.1695, -0.0575,  0.2486]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5533,  0.2313, -0.7236, -0.8667, -3.3281,  3.8768]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4894, -1.3079, -1.0078,  0.3633, -2.6088,  3.5408]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7826,  1.3627, -4.2036, -0.9077,  1.2242,  3.1184]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5807, -1.1460, -0.9656,  0.4218, -2.1224,  4.2237]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0826,  4.9514, -1.7559, -3.0497, -0.8007, -0.7107]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0194,  1.1593, -2.4330,  2.7578, -2.4911,  1.2824]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1977,  0.6701, -4.3362,  0.6960,  1.5807,  0.8851]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0005,  1.0022, -3.7758,  2.3386,  0.4046,  0.0447]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0717, -1.2541, -1.1517,  5.4347, -0.7928, -0.6963]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1514,  0.3282, -2.5879, -0.6331, -2.1253,  4.0378]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0904,  2.2648, -2.7787,  3.2356, -2.3676,  0.9570]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6536, -0.0100, -3.5164, -0.2496, -0.5555,  4.2674]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3468, -1.6004, -1.9597,  1.1068, -1.7482,  3.7492]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0858,  3.0904, -0.5540, -1.4973, -3.6069,  1.0384]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2062, -1.0375, -3.6184, -0.0798,  0.4853,  2.8481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9668,  0.7668, -2.9109, -1.3004,  2.7650,  0.4653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9899, -3.3712,  1.6247, -1.3750, -0.5355,  2.7324]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0462, -1.6003, -2.8842,  0.9205,  1.3914,  3.0654]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2594,  0.5647, -1.1806,  1.6449, -3.5578,  3.1512]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2942,  1.6424,  2.5065, -3.7123, -2.2540, -0.7549]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3376, -1.1126, -0.4345,  2.2757, -3.3393,  2.3185]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8694, -1.6109,  2.9877, -2.1876,  1.7781, -1.9863]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6020, -1.9760,  4.1541, -3.4124, -0.0348, -0.6126]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0743, -2.0600,  0.2190,  0.3149,  5.0281, -1.4644]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2744, -1.6604, -0.5151,  0.7438,  5.0830, -1.7739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0539, -1.0425,  0.8321, -0.9623, -3.4544,  3.4390]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6162, -0.3036, -2.2076, -1.1363, -1.5210,  4.6870]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2166, -1.4970, -2.4907,  4.0694, -0.2840,  2.5063]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1218, -0.8776, -2.3510, -0.5543, -1.1580,  4.3827]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3852, -0.9721,  1.3737,  1.7383, -0.4199, -1.5606]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4410, -0.4264, -2.1695,  2.1195,  0.3151,  1.1035]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0835, -0.7461, -1.4253,  0.7837, -2.2458,  3.5534]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4916,  5.1722, -2.0860, -2.2776, -1.4392, -0.1333]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6008,  5.1545, -2.2749, -2.0376, -1.6465,  0.0595]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8816,  3.0872,  0.5849, -4.1769,  0.0488, -1.5047]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9953,  3.8781, -0.7850, -4.0338, -1.2477, -0.4088]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3106,  2.7207, -4.5300, -0.0355,  0.2047,  0.3613]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4332, -0.7509, -0.5295,  3.1402, -2.9349,  1.9721]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5716,  0.8877,  1.3368, -2.4362, -2.7254,  0.0873]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7033,  1.0254, -4.2879,  1.9148, -0.7228,  2.8460]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5534,  1.5946, -2.7948, -0.3220, -0.7648,  1.7916]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3921, -0.7977,  2.2440, -2.8674,  0.4529, -1.4203]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6361, -2.7448,  1.8870, -0.8519,  3.4117, -1.9872]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1579,  0.3937, -1.4856,  0.6553,  1.0782,  0.9582]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3510, -2.4778,  2.2172, -3.0399,  1.0483,  1.2220]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1840, -1.0767, -1.8804,  1.5037, -1.9173,  4.3791]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2770, -1.5532, -1.3244,  5.4055, -1.1156,  0.2515]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0221, -1.3964, -1.6457,  3.4079, -1.9702,  3.0215]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9061, -1.0302, -3.5543,  0.8432,  1.8628,  3.3835]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4802,  5.0715, -1.7376, -2.7682, -1.4592, -0.0294]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5206,  3.8906,  0.0097, -4.2169, -1.1514, -0.6812]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3887,  0.7656,  3.4725, -3.4871, -0.2027, -2.2943]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4814,  4.3816, -3.4250, -1.1594, -1.6145,  1.1302]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9949,  0.2542,  3.7848, -2.6105, -1.7436, -1.1055]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7422,  2.8675,  1.7973, -3.7024, -0.8088, -1.8686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4078,  4.0917, -1.6913, -3.8719, -0.9362,  0.3521]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6170,  1.5729,  0.4183, -5.1053, -0.1641,  0.1864]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2065, -1.7541, -2.3678,  4.1437, -0.2593,  2.3821]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0362, -0.7210, -1.9418, -3.0964,  1.0243,  2.9630]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0853,  3.0407, -3.6347, -2.4224,  0.2001,  1.8973]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1007, -0.6965, -3.4289,  1.2818,  0.3786,  3.0491]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5933, -1.9661, -1.1602, -0.6628,  4.4630,  0.2337]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6307, -0.0070, -2.2415, -2.1014,  4.6924,  0.0104]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5641,  0.3624,  0.1531, -3.3189, -1.2431,  2.2842]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8028,  2.0670, -2.7318, -2.6526, -0.4246,  3.2822]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2461, -0.7557, -3.4325,  1.1015, -0.3359,  3.8757]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0013,  2.4572, -0.5430, -4.7920,  1.2150, -0.2958]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7566, -0.7065, -1.5757, -0.2454, -1.8443,  4.3437]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8643,  1.3327, -0.6380, -2.2434, -2.9915,  3.4988]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7977,  1.2152, -0.9186,  1.1181, -2.6656,  0.6244]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2946,  5.2222, -1.8713, -2.3702, -1.2650, -0.6142]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9480,  4.7499, -2.5162, -1.6980, -1.9715,  0.9970]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5355,  2.4005, -1.7927, -3.6513,  1.7266, -0.7309]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3086,  1.7212, -1.3927, -3.2399,  1.8999, -0.1843]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0424,  1.6545, -0.0344, -0.6940, -1.7584, -0.3475]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6650,  0.5814, -2.4935, -2.4801,  4.0932,  0.2566]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6412,  3.4315, -2.9704, -3.3840,  0.9467,  0.4103]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7586,  3.4848, -4.0108, -2.1873,  0.3208,  0.8153]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1094,  0.1787,  2.2614, -2.5201, -1.7119, -1.0111]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1327,  3.9708, -3.3797, -0.9687, -1.3278, -0.3269]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2222, -1.9228,  1.4948, -2.5928,  4.2484, -1.1641]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4887,  2.6547,  0.0672, -2.1825, -3.1376, -0.1887]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1350, -0.3115, -2.7457,  1.8541, -0.0316,  1.8813]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3444, -0.5608, -1.2136, -1.9425,  3.7285, -1.3848]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1882, -0.7555, -2.7942,  1.8248, -1.3657,  4.1276]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1310,  0.5056, -1.8496, -4.1160,  2.7253,  1.0662]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6650,  1.2435, -1.7317, -0.3620, -1.7902, -0.4243]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2193, -1.1102, -1.1679, -1.7004,  4.0721, -1.1686]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0881,  3.1978,  0.3232, -3.4253, -1.8289, -0.8586]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6815,  0.9099,  1.9092, -4.9571, -0.5697, -0.3259]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2307,  0.3730, -2.3896,  3.5718, -0.5596,  1.3624]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4346,  0.4345,  1.3854, -0.4857, -2.1273, -0.5188]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3581, -1.0888, -1.5399,  3.1167, -2.0322,  1.7363]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5214, -1.9287,  4.3104, -0.0415, -2.8001, -0.3064]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6292,  3.4403,  0.6106, -3.8025, -0.9510, -1.0233]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4257,  0.0779,  1.0775, -0.8079, -3.4437,  1.9957]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3570,  4.4756, -1.9346, -3.3788, -0.0511, -0.4434]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2760,  0.5437,  1.4557, -4.3916, -1.1863,  0.9156]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3043, -1.1445, -1.7920,  0.1671, -2.1074,  4.4177]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0060,  1.3249, -2.1357, -0.5683, -0.3428,  1.8237]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9164,  0.2659, -2.7886,  0.0210, -1.9651,  4.2645]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5046,  1.9608, -2.6082, -0.7642, -2.4191,  3.1044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2596, -1.2909, -3.3946,  0.9267, -0.1494,  3.6794]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0234, -0.4735, -3.9627,  1.2555,  2.4510,  1.9401]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9346,  0.5253, -2.8955,  1.8174, -2.0223,  3.2786]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0913,  4.3659, -2.5413, -3.2836,  0.4543,  0.1735]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4953, -0.7562, -2.2678,  5.4774, -0.5597,  0.1011]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0016, -2.1523,  1.8551, -3.5575,  2.4807, -0.2092]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5175, -0.1514, -0.4970, -1.3144,  1.6628, -0.3470]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1010, -2.1311,  2.2297, -1.3497,  1.8996, -1.6989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.2845, -1.6786,  1.3165, -3.7538,  1.2763, -0.9113]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3702,  2.7511, -2.0180,  0.2127, -2.8101,  1.6099]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5082, -1.5219, -1.8311,  3.0107, -1.5205,  2.9648]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8151,  0.2576, -0.7959, -3.1571, -1.1780,  2.9220]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7613,  0.8179, -3.4733, -1.8540,  1.2483,  2.4810]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2254,  0.9044, -1.6433, -3.6199,  3.4065, -0.0939]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1213,  0.5156,  0.2722, -1.7544, -3.5529,  2.9613]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1255, -3.0970,  0.5285, -0.8698,  0.3795,  3.5020]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7523,  5.1733, -2.2225, -1.8955, -1.6847,  0.1101]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0767,  5.0592, -1.7702, -2.7720, -1.3681, -0.4143]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2403,  3.7943, -3.3314, -2.2860, -0.4847,  0.8844]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3495, -1.6433,  0.2733, -2.9568,  4.3728, -0.4168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6406, -1.5322, -0.5190, -0.7798,  5.2523, -1.2271]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4728,  3.1560, -3.4903, -0.3679, -1.1190,  1.6558]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9790,  1.1709, -1.5652, -4.3180,  0.9618,  1.9017]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0260,  0.8658, -1.7592, -0.6990, -3.0480,  4.1446]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6081,  0.2957, -2.7052,  0.8335, -2.2648,  3.7949]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7014,  3.1340, -3.1288, -2.3392, -0.4022,  2.2904]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6653,  1.0712, -1.8534, -2.4274, -1.6994,  3.0270]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5575,  2.6625, -2.3562, -2.8660, -1.6194,  3.0090]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6030,  4.9810, -1.9056, -2.4125, -1.9133,  0.3240]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2741,  0.1790, -1.4041,  5.1936, -2.1717, -0.4644]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4187, -0.6862,  2.2543, -4.0706,  2.3001, -0.9800]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1886,  0.2513, -2.1797, -1.0398,  5.3165, -1.0084]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3081, -1.8854, -2.3714,  4.1015,  2.3686,  0.2391]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6518, -0.2122, -1.8711, -2.2489,  4.2175,  0.4303]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4193, -0.9115, -0.4879, -2.4559,  4.8763, -1.2404]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8352, -0.0756, -2.1027, -2.8671,  3.6650,  1.0279]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0991,  2.0973, -2.7065,  0.8560, -2.9292,  2.7699]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3539, -2.2168, -1.6421,  1.1147, -0.9811,  4.2836]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1330, -0.6456, -1.8174,  0.5018, -1.5517,  4.4724]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0130, -1.2254, -2.7193,  1.4791, -0.5994,  4.1474]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1342, -2.0602, -1.2998, -2.0670,  1.1803,  3.0909]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5762,  4.9368, -2.3390, -2.7825, -0.7262,  0.2321]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3821,  4.4736, -2.5306, -2.3760, -0.1435, -0.5733]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9913,  3.1809, -0.1178, -3.9644, -1.9389, -0.0327]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1724,  4.2270, -2.9151, -1.6430, -1.5765, -0.4308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1519, -3.3013,  1.8107,  1.9057, -0.5187,  0.0119]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6088,  2.7860, -2.4592, -3.1369,  1.0210,  0.6476]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0321, -1.3576,  3.7159, -3.7200, -1.1247, -0.4538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3050, -1.1442, -3.2612,  2.7929,  3.0576,  0.6747]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7958,  2.4908, -3.3208, -2.1410,  0.2329,  1.1882]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4863, -0.4480, -2.6544,  3.0870, -1.5487,  3.3204]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2191, -1.4903, -0.0390,  1.9523, -3.3439,  2.9450]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2776,  2.1344, -3.7575, -2.6711,  0.4733,  2.3321]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5371, -1.2955,  0.2776, -3.4032,  4.1673, -0.6791]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2657, -0.3323, -2.2239,  4.4418, -1.7359,  1.9077]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8419, -0.9523,  4.7737, -2.6410, -0.9479, -1.3578]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3377, -1.5312,  0.8877,  4.1116, -2.9929,  0.7219]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5957, -1.2294,  5.0277, -2.4368, -1.8535, -0.8393]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1499,  1.1118, -1.3810,  4.3028, -2.9611,  0.5481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4577,  2.6128, -1.9396, -3.8820, -0.0949,  1.4922]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7522, -3.2310,  3.5795,  1.5295, -1.5674, -0.4565]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9850, -2.2373, -0.5109,  4.6501, -1.2341, -0.3482]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4148,  1.5902, -3.1955, -2.7836,  2.9891, -0.1321]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6475,  1.3114,  2.3614, -4.1845, -1.6224, -0.9870]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1093,  1.9761, -3.0065, -3.3138,  2.1894,  0.8352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8836, -2.4118, -1.9757,  0.7462,  0.7628,  2.7295]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2221,  1.5019, -1.7582, -2.8897,  1.5333,  1.2628]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0385,  2.6396, -1.1276, -2.2355, -2.9609,  2.8586]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2815, -1.0431,  0.9485, -2.2040, -0.7261,  2.6252]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2414, -1.5526, -1.9191, -1.0174, -0.6604,  4.3602]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1927, -0.3580, -1.7066, -1.2277,  5.4748, -0.9050]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7220, -2.0139, -1.3401, -0.4319,  4.9213, -0.0893]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5199,  1.6479, -1.9130, -3.9250, -0.5739,  2.5285]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1069,  0.4790, -1.2254, -3.2875, -1.4268,  3.6098]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5805,  2.8640, -3.8053,  0.5704, -1.4924,  1.9694]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1596,  4.1401, -2.9386, -1.5336, -1.4499,  0.8981]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3359,  3.0144, -3.8718, -1.0742,  0.1649,  1.0753]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1394,  0.6123, -2.6842, -2.4596, -0.3204,  3.9687]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1557,  1.5113, -3.3951, -0.9580, -1.3192,  3.2734]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1480, -0.7614,  0.4966, -2.7667, -1.7964,  2.6723]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6775,  0.0319, -2.6485, -0.8678, -1.4622,  4.6200]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2426, -0.6113, -2.3518, -1.4494, -0.6545,  4.5966]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6742, -1.6234, -1.9927,  5.0207,  1.4418, -0.0660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4610,  5.1437, -2.5763, -2.1497, -1.0176, -0.0521]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1674,  5.0342, -1.9739, -2.5626, -0.6811, -1.0021]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4008,  0.7253, -2.1850,  0.8710,  2.4082, -0.4455]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9714, -0.9442,  0.1705, -1.2416,  2.6226, -2.8797]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4915, -0.9972, -2.5934,  2.2679,  3.9715, -0.9581]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0032,  2.1989, -3.0712, -2.0617,  3.4686, -1.0877]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1908, -1.4021, -1.3792,  4.9827, -0.7401, -0.0279]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1330, -0.0660, -2.2948,  3.1969, -2.5760,  2.8449]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4841, -0.9403, -2.1200,  4.7869, -1.3220,  1.9268]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4560,  3.7791, -0.7944, -4.2859, -1.1903,  0.3989]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2191,  2.9917, -1.4913, -4.1416,  0.0188,  0.0559]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6341,  2.0634, -3.5254, -2.1384,  0.0809,  3.1349]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1798,  5.1448, -1.8195, -2.5626, -1.3207, -0.5530]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3762,  5.1644, -2.0033, -2.5821, -0.8140, -0.4917]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2106, -1.2733,  1.3263, -0.8712, -1.0010,  0.0051]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3316, -0.9405, -1.8770,  4.1744, -1.6937,  1.1151]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2470,  3.4432, -0.7233, -2.3750, -2.4665, -0.4048]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.1620,  2.4577, -1.9972, -1.8791, -2.6546,  3.2690]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4411, -2.1106,  3.0343, -0.1272, -1.5525, -1.5666]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2144, -2.5018, -1.5265,  3.1109,  2.7428,  0.5251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4444,  1.6135, -1.2888, -3.2029, -2.0654,  3.3777]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8127,  3.6231, -1.6258, -1.6079, -3.3597,  1.8803]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0752,  2.6457, -2.3641,  0.9525, -3.1411,  1.4039]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-8.3184e-01,  1.4926e-03, -3.4384e+00,  1.4459e+00, -1.4340e+00,\n",
            "          3.9104e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8732,  2.7098,  0.0726, -2.3497, -2.3892,  0.0326]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7331,  1.2911, -0.7494, -0.5330, -1.4260,  0.8626]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2950,  1.0725, -3.3517, -2.3960,  3.0547,  0.4423]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2775, -2.9282,  1.0872,  1.1558,  1.7003, -1.8767]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0031, -0.6392, -0.4899,  2.8784, -3.1277,  2.6002]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9824, -0.7097, -1.9588,  5.4285, -1.1447,  0.7661]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7906,  1.2279, -2.2687,  2.5592, -3.2916,  2.2975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0133,  0.4522, -3.0346,  0.1480, -1.8029,  4.4168]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3420, -2.7155, -0.7486,  0.0872, -1.1597,  4.0865]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2617,  5.0872, -2.4440, -2.4064, -0.9727, -0.1704]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6929,  1.5090, -3.6972,  3.2089,  0.4548, -0.7940]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0610, -0.5222, -1.3105,  4.2780, -2.6535,  1.7876]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0185,  0.6045, -2.7587, -2.3612, -0.1210,  3.6071]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5821, -1.1403, -2.6352,  1.3193, -0.5879,  3.8437]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2898,  0.8083, -2.4835, -2.7945, -0.6004,  3.8834]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1806, -1.1761, -1.3615, -0.5572,  2.6063, -0.4909]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1922,  3.9076, -1.9430, -0.7555, -3.2121,  0.4149]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7453, -0.7320, -0.1683,  4.0007, -2.7886, -0.1659]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2736, -2.0069,  0.2480,  5.0428, -0.8074, -1.0178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5251,  1.7583, -2.0200, -1.4297, -2.2841,  3.1413]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0085,  5.0448, -1.6883, -2.8516, -1.3837, -0.5206]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1834,  0.5433,  3.8777, -0.7015, -2.4994, -1.6443]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8720,  3.3211, -2.0059, -1.2276, -3.2767,  2.3381]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3765,  1.5298, -4.3673, -0.8292,  2.3800,  1.1711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5080,  0.9362, -3.1311, -3.2943,  1.2463,  2.6501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3338,  4.7059, -1.8479, -1.7876, -2.7775,  0.4128]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8846,  3.6872, -0.7928, -0.9843, -3.7096,  1.1310]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8963, -1.0376, -1.0539,  4.7508, -2.7016,  1.5114]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.0419, -1.0539,  1.4721,  0.3518, -2.2473, -1.5766]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4851e+00, -1.3776e+00, -3.3888e-03,  2.2838e+00, -2.8886e+00,\n",
            "          3.5165e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2180, -0.2272, -2.7545, -2.1368,  0.1067,  4.0306]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1263, -0.2780, -0.0625, -4.1965,  0.3408,  2.2298]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6213,  0.5281,  0.4697, -3.4564, -0.6279, -1.4879]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0654,  0.0223, -3.1574,  0.6561, -0.8514,  2.1696]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2654,  3.8010, -1.1691, -1.7230, -2.1894,  0.4720]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2828, -2.1900, -1.6221,  4.7047, -0.6609,  1.2570]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4498,  0.2019, -1.8802, -1.5384, -2.4728,  3.8650]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8086, -2.3506,  1.2970, -1.3894,  4.3166, -1.0195]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8128,  1.6790, -2.5663, -0.9190, -1.4891,  1.0263]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1492, -1.2630,  0.1311,  3.7461, -3.5811,  1.3868]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0964,  3.6956,  0.0135, -3.9911, -1.7250, -0.8504]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8449,  0.6930,  1.0040, -0.6868, -3.4934, -0.1879]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9049,  2.0773, -3.0352, -1.4940,  1.9134, -1.0528]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5251,  1.4304, -0.7189, -3.6780,  3.2011, -1.5525]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2505, -1.6336, -1.0734,  3.3279, -1.8056,  3.0660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2290,  1.2145, -1.5704,  0.0455, -2.4783,  2.1318]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2346,  5.1785, -2.2094, -2.3060, -0.9837, -0.4608]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2271,  4.9339, -2.0960, -2.9220, -0.9072, -0.4467]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6270, -2.6258,  1.7745, -0.1425, -1.2234, -0.3420]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2111, -1.1818, -2.3015,  0.5574, -0.3799,  1.4264]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4312, -2.1171, -1.8091,  1.0995, -1.1133,  4.3648]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1404, -3.2101,  3.6349, -0.9818, -0.4744, -0.8709]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6291, -0.6182,  2.6458, -3.7551, -1.7162,  0.6122]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8411,  0.9709,  2.4920, -2.8345, -3.3262,  0.2347]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4055,  4.3462, -0.2097, -3.3741, -2.2539, -0.5888]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9576, -1.1892,  0.1731,  3.8439, -2.3413, -0.2591]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3155,  1.6578,  2.0572, -3.0315, -3.2993,  0.4520]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3200,  0.4063,  3.5326, -2.3480, -1.2959, -1.0510]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4646,  3.8886, -2.7444, -3.5113, -0.4702,  0.8392]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3269, -0.7033,  3.0015, -4.0857,  0.5925, -0.4938]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2208, -0.1579, -2.6545,  1.2019, -1.6046,  4.1805]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0896, -2.3517, -2.1013,  0.4621,  0.4094,  2.9342]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0018, -0.6747, -2.3816,  5.2442, -0.8444,  0.9141]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3288,  0.0164, -4.4784,  1.1186,  1.8423,  2.4354]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6705, -1.0905, -1.6198,  1.0608, -2.0423,  4.1205]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3192,  2.2912, -0.7352, -4.2263, -1.5012,  1.8160]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7317,  0.3328,  0.1083, -1.4802,  0.3625, -1.9509]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3708, -0.6523, -2.1445,  5.2562, -1.6387,  0.6158]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6683,  5.1030, -2.4364, -2.0419, -1.5051,  0.2628]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2604,  5.1459, -2.2290, -2.1816, -1.6248, -0.1812]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6549,  1.1601,  3.5039, -3.3992, -1.2674, -1.7054]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7088,  3.8218, -2.7630, -1.8952, -1.1736, -0.7706]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1591, -1.4610, -1.2625, -0.4215,  5.3905, -0.6203]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2643, -1.0900, -3.1661, -1.5136,  3.3273,  1.6609]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1903,  2.6160, -1.6261, -3.2224, -1.6129,  2.0360]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2992,  0.5542, -1.4617, -2.5584, -0.8071,  3.7114]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4260,  0.0652, -3.4430, -0.3301, -0.6490,  4.2792]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2346,  0.5892, -1.2901,  1.7881, -3.4104,  2.1307]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9018, -1.6437,  4.2212, -1.7832, -2.7122,  0.0267]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4957,  3.0445, -3.7225, -1.7535, -0.2205,  2.2250]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6379, -1.7344, -2.1795, -0.0607,  0.4605,  3.2480]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8101,  0.8559,  1.4739, -4.3897, -0.4548,  0.6469]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6952, -1.2228, -2.8994,  0.5878,  1.7623,  3.2481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6620, -1.0798, -1.8373,  5.0636, -1.8851,  1.3212]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9505,  0.1924, -2.9285, -0.5509, -1.3683,  4.5897]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1206,  4.8376, -1.4153, -3.0035, -1.9130, -0.2426]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3505,  4.8043, -1.7746, -3.2412, -0.9185, -0.5727]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2876,  2.6935, -0.4932, -4.6033,  0.7360, -0.6794]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5225,  4.4662, -3.6327, -1.6036, -0.4790,  0.9291]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.0228, -2.9409,  3.5477, -2.6652,  0.8999, -0.5092]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2296, -0.1613, -0.8761, -4.1501,  1.6188,  1.7950]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6440, -0.9408,  1.0358, -4.3210,  0.1074,  1.5538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3847,  1.9932, -3.9031, -1.1324,  2.8464,  0.3962]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5191,  1.6436, -1.9958, -3.0739, -2.0829,  3.0995]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8476,  2.7640, -3.4742,  0.4273, -1.6412,  0.6091]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5885,  2.6728, -0.3285, -3.7546, -1.1409, -0.4349]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6739,  5.2696, -2.0546, -2.0202, -1.4416, -0.3043]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4490,  3.8512, -3.5716, -2.4017, -0.0403,  1.5555]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1723,  4.6494, -3.2242, -2.3953, -0.1118,  0.2511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3906,  3.9740, -3.1537, -2.5403, -0.2582,  1.4934]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3346,  3.8905, -2.7221, -1.1275,  0.0430, -1.7200]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3217, -0.6821,  2.5671,  0.4117, -1.8560, -1.3212]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0377, -1.1902, -1.8781, -0.4395,  5.2866, -0.1763]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2552, -2.2362, -0.1321, -2.0896, -0.0300,  3.9097]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1777,  2.8850, -1.4945, -3.3737, -0.9784, -0.7006]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3336,  2.4411, -2.4700, -1.1532, -2.5420,  3.4041]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4218,  0.1664, -1.8215, -1.9485,  5.2457, -0.9298]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8338, -1.0657, -2.0276, -2.5706,  3.8523,  1.4269]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2745, -2.0140, -1.7987, -0.5246, -0.1068,  4.0458]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3388, -0.4716, -3.5659, -0.8854,  1.7236,  3.0361]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7319, -1.5643, -1.4324, -2.2265,  3.5184,  1.5653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2419,  2.7006, -2.4269, -2.7410,  2.0058,  0.2215]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2139, -2.7335,  2.9124,  0.2732, -2.0079,  2.0158]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1380,  3.4097, -3.7978, -2.2708,  1.2817,  0.8361]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1805, -0.2655, -2.3401, -1.5921, -0.1752,  3.9562]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2711,  0.2139, -2.5783, -1.6559, -1.5496,  4.1993]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-2.1763e-02,  2.2582e-03, -3.3869e+00, -5.8156e-01,  6.6180e-01,\n",
            "          3.1875e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6325,  5.1127, -1.9976, -2.3533, -1.5663,  0.0954]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3977,  4.8030, -2.6511, -2.6243, -1.1545,  0.6299]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2927,  5.1235, -2.2611, -2.4618, -1.3192, -0.0766]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1847,  5.1218, -1.8785, -2.6915, -1.0627, -0.5472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0574, -0.3967,  1.5294, -1.1767, -3.4570,  2.3828]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.2787, -2.8429,  0.8802, -0.8770,  1.7695, -0.2832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5515, -1.8425, -0.6084, -2.6989,  0.0461,  3.0325]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0795, -0.6529, -1.8869,  0.0707, -1.8569,  4.7119]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5895,  1.6114, -1.8295, -2.6915, -1.4459,  3.5921]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2980,  5.0526, -1.3067, -2.8128, -1.6455, -0.4489]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1866,  5.0365, -1.5674, -2.9309, -1.1199, -0.6080]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9950,  1.9042,  0.7125, -0.9719,  0.1997, -2.4779]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4882,  4.2226, -1.8188, -3.2196,  0.8585, -1.0206]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0124,  3.8539,  0.3257, -2.3866, -2.5013, -0.6654]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6480,  5.0642, -1.8433, -2.3323, -1.8601,  0.1262]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7122,  2.5786, -3.3014,  2.4695, -0.6780, -1.0882]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3761,  1.1285, -0.4015, -1.6393, -2.9842,  2.2553]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9011,  1.1265, -1.8352, -3.3128,  0.4680,  1.8830]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5910, -0.7248, -0.3651, -3.0285,  0.4217,  1.7137]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5090, -0.7272, -1.1801, -2.9239, -0.4808,  3.8127]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3929, -0.2552, -3.1333,  1.3552, -0.5529,  3.2750]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5543,  0.9266, -2.7765, -0.1469, -1.7696,  3.6162]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3193, -3.0614,  1.9578,  0.6784, -1.2412,  2.1037]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0637, -0.6182, -2.2615, -1.3735, -0.7192,  4.2552]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4632e+00,  2.7596e-01, -1.7014e+00,  4.2921e-03, -2.6970e+00,\n",
            "          4.4202e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0117, -0.5869,  0.1941,  4.2316, -1.6185, -0.6928]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9172, -2.1337,  2.3313, -1.2843, -2.5091,  2.0430]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4438,  5.1796, -1.8060, -2.4090, -1.5683, -0.2823]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2342,  4.9056, -1.2281, -3.1264, -0.9388, -1.0407]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8338,  2.7197,  0.9023, -3.1586, -2.8404, -0.3653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2619,  2.5310, -1.2878, -3.1867, -1.9342,  1.8909]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2138, -1.9354,  0.7089, -2.3954,  3.7704, -0.2745]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1667,  1.1177, -1.7265, -2.9264, -1.1661,  2.2356]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5883, -0.8165, -1.5117, -1.3732, -1.3747,  4.7241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5358, -1.8342, -0.1268,  1.7817,  0.9050, -1.9014]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8776,  0.4879, -3.1759, -2.0864,  2.1568,  0.7948]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7944, -0.9957, -1.8420,  4.6660, -1.6004,  1.5970]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3440,  5.1159, -1.8627, -2.6901, -1.2300, -0.2781]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7308,  0.4174, -1.2399,  2.6745,  0.5840, -2.6461]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9470, -2.9166,  3.5189, -0.3815, -0.7013,  0.2413]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2770, -0.5397, -1.3763, -1.1774,  5.5308, -1.1398]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3171, -0.7809, -1.1261, -1.8317, -1.2941,  4.4430]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8951,  4.9794, -2.4241, -1.9240, -1.7002,  0.6030]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1064,  4.4936, -2.7542, -3.1017, -0.0417,  0.2190]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1796,  4.3800, -1.2603, -3.1794, -1.3314, -0.1327]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6691,  0.1708, -0.5004,  0.6892, -2.2027,  0.6274]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5411,  2.6596, -2.7130, -0.9736, -1.0751,  0.2567]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.4442,  1.0264, -0.1914, -2.1079, -0.5958, -0.8643]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0081, -0.1322,  0.2180, -4.3008, -0.1032,  2.2056]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3725,  0.2359, -1.9010, -1.8609,  5.2486, -0.9504]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3602, -0.3366, -1.7119, -1.2719,  5.4659, -1.0351]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1767, -1.8168, -2.7865,  0.3236,  0.1220,  4.2693]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 3.6606, -0.5162,  0.4177, -3.4289,  0.2471, -1.2180]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4535,  1.6328, -0.0229, -4.3624, -1.9845,  1.2059]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3944,  3.1851, -1.4925, -3.7189, -1.4842,  0.3428]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7771,  5.0928, -2.1807, -2.0821, -1.7175,  0.2584]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9974,  3.9847, -1.7235, -3.8427,  0.0152, -0.7189]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7772,  3.6423, -3.9962, -0.2136, -1.3766,  1.8862]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6977, -0.6654,  1.2953, -3.1141,  3.6092, -1.9852]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8016,  0.3690,  0.4881, -3.9379,  3.1096, -1.7711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9185,  0.9276, -0.0830, -4.1106,  1.7671, -0.7448]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4352, -0.0297, -0.4697, -3.0851,  2.9651, -0.2759]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9011,  1.7006, -1.3363, -2.8193,  4.0994, -1.8975]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6213, -1.1334, -0.9629, -1.4946,  4.7279, -1.3251]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6727,  0.7890,  0.2528, -4.6494,  1.6832, -0.2886]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9752, -2.1605, -1.1033,  3.7858, -1.2858,  0.7425]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7554,  1.7726, -2.2191,  2.7139, -2.7646,  1.2800]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2676, -0.8953,  2.0019, -2.6584,  2.6498, -1.8356]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2089,  1.1744, -3.2928, -2.3798,  2.8319,  0.6079]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5261, -1.6287,  2.2068, -2.8678,  3.0049, -1.4982]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9087, -2.2069,  1.1627,  0.4440,  3.0022, -1.3159]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9214, -1.4343,  3.7999, -0.4895, -2.2443, -0.5782]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5402,  1.1514,  0.0738, -2.0538, -2.8080,  1.9183]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.7769,  0.4130, -1.5193, -4.2381,  1.8088,  0.8841]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5329,  1.1405, -0.4729, -1.8791, -2.2396,  1.8049]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4873, -0.7924, -1.5546,  5.1871, -1.2524,  0.3016]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2548,  2.3783, -3.0181, -2.5740, -1.4825,  1.9824]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1117,  1.3497, -0.2072, -0.7424, -1.2270, -1.5819]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0100, -3.4226,  0.5897,  1.3705,  1.3419,  0.5309]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1173, -2.6351,  3.5691, -3.1108,  0.2014, -0.1792]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5842, -0.5626, -2.4288,  1.3592, -1.0069,  3.4415]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6704, -2.7664,  3.6306, -2.6137, -1.1418,  0.8262]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1687, -1.5053, -0.3943,  4.8978, -2.0782,  0.4052]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5529,  1.5255, -3.8485,  1.5165, -1.6148,  2.6333]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6636,  5.0584, -1.7536, -2.4001, -1.8906,  0.1178]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6642,  0.0723, -0.4052,  4.1917, -2.7746, -0.9179]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6004, -1.3187,  1.2326, -0.3297, -0.9535,  0.3198]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2568, -0.6425, -1.7752, -0.6046,  5.4697, -0.9633]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5472,  4.1669, -1.0849, -2.0181, -2.7610,  0.6566]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2311, -2.1258, -1.7002,  2.4249,  4.1011, -0.2716]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5032,  2.8921, -1.4102, -1.4145, -3.5061,  1.2897]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9849,  3.4976, -1.4626, -3.6109, -0.8559,  0.1510]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6228,  0.2307,  2.2756, -4.1000, -2.1602,  1.3633]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1067, -0.6584, -1.5920, -1.7115, -1.5700,  4.4692]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6243,  4.9475, -2.0375, -2.6850, -1.5454,  0.3817]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1400,  4.7381, -1.4960, -3.3764, -1.3421, -0.3131]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3508,  4.1190, -0.2991, -3.7632, -1.8176, -0.3712]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6207,  3.8387, -0.0944, -3.9140, -2.1019, -0.2481]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0515,  3.2127, -1.0825,  0.4451, -2.5018, -1.3979]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3423, -0.8398,  1.6925, -3.7684, -1.2340,  1.7833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5697, -1.8792,  0.5075, -2.7456,  3.9133, -0.4538]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0929, -0.8140, -2.9351, -0.5211,  2.2109,  1.7323]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6241, -3.3458,  1.4698,  1.5214,  0.4079, -0.2861]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1614,  1.2863, -0.7175, -3.0499, -2.8583,  3.0304]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3932,  1.8757, -2.5268, -3.1293, -0.8536,  3.2608]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2092,  1.3845, -1.1034, -3.2061, -1.7571,  3.1610]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5293,  1.0744, -2.6646,  4.1149, -0.2648, -1.2643]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5465, -2.0861,  2.0609, -0.2302,  1.3085, -1.3970]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.4239e-01, -1.8913e-01, -3.1967e+00,  3.8181e+00,  3.1695e-03,\n",
            "          1.1735e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7407,  2.6733, -3.8188, -2.1917,  1.4601,  0.7793]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5732,  1.7970, -4.0435, -1.2133,  1.1662,  2.8483]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.3624,  0.0203, -2.3464,  4.5050, -1.5292,  1.7208]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3442, -1.1885,  0.0633, -1.3094, -2.6342,  4.3018]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7689,  4.9849, -1.9994, -2.4196, -1.7178,  0.4119]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1885,  4.9356, -2.2767, -2.7251, -1.0404, -0.0703]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1374,  4.7638, -1.9079, -3.2735, -1.1299,  0.0832]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6457,  1.1600, -1.3696,  2.3618, -1.7039, -0.2638]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7323,  3.8627, -1.6598, -4.0221,  0.2781, -0.2740]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0989,  2.5176, -4.3023, -1.9823,  0.2583,  1.4739]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8667,  1.6050, -2.2016, -1.5218, -0.8082,  1.6593]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4009, -3.9009,  2.5253,  1.5801, -0.2641,  0.9352]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2124, -1.3510, -1.9908, -0.3560,  4.5865, -0.6161]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7319,  0.6687, -1.4550, -2.3674, -2.1422,  4.0963]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2330, -1.8483, -2.6693,  2.1753,  3.0532,  1.3432]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3886e-02,  4.6336e+00, -1.3950e+00, -3.4835e+00, -1.5034e+00,\n",
            "          4.3630e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8006, -1.3636, -2.1192,  4.4145,  1.0060, -0.8513]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1025, -0.1945,  0.4003,  1.8092, -3.5399,  1.3634]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1682,  0.4063, -0.1539, -3.7226, -1.3324,  3.1924]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1177,  2.0815, -4.6964, -0.5271,  1.7603,  1.4034]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6768,  0.1237, -3.7623, -1.7498,  2.9296,  1.9102]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8500,  3.6295, -0.9406, -3.8092, -1.6610,  0.1454]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3524, -1.6914, -1.2810, -1.6731,  4.7840, -0.4445]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6933, -1.1137, -1.8312, -2.5035,  2.9298,  0.0742]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.5333e+00,  1.3134e-03,  1.1376e+00, -3.4810e+00,  1.0894e+00,\n",
            "         -1.3951e+00]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2624,  3.1657,  0.1785, -2.6902, -3.4267,  1.0424]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.6830, -3.0071,  2.5575, -1.8739,  1.0719, -1.0847]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5798,  0.9019, -3.5736, -1.8182,  1.7367,  1.9954]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7888, -1.3377, -1.0814,  4.3851, -1.6363,  1.5849]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3760,  1.9831, -4.3265, -0.9386, -0.0313,  2.3308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2693,  0.0349, -3.4882, -1.0034,  1.1138,  3.4771]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4556,  1.6290,  1.3112, -2.6698, -0.4748, -0.3833]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1434,  4.6138, -1.7662, -3.5041, -0.9791, -0.0515]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.2260,  0.8984, -0.3851, -4.5786, -0.6873,  1.8660]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.7614, -0.9491,  1.5760,  0.5703, -2.5413, -1.3804]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2214,  5.1344, -1.9068, -2.6681, -1.1762, -0.4900]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8419,  3.9925, -1.1629, -3.5049, -1.3812, -0.2745]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1560,  4.2499, -1.2885, -3.4534, -2.1328,  0.5477]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2167,  1.6036, -2.7249,  2.2654, -3.0165,  2.5808]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1839,  3.9410, -1.3264, -3.1584, -0.4112, -0.2533]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1613, -0.5608, -3.7715,  2.3330,  1.6774,  1.7368]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6395, -0.4686,  3.1226, -3.1870, -2.4689, -0.0310]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8929,  0.4261,  0.4968, -3.6450,  2.3227, -1.2565]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6118,  4.2961, -2.2368, -2.3447, -1.9492,  0.3090]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1242,  2.1977, -2.2985, -3.2482, -1.4468,  3.0929]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7931, -1.3681,  3.2520, -2.2664, -0.8765,  0.4241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1347,  0.0360, -1.4849,  3.8168, -1.8093,  0.4443]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6576,  5.1408, -1.3625, -1.9656, -2.1633, -0.3773]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5828,  4.5924, -0.8937, -3.3590, -0.7194, -1.3711]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5126,  4.1984, -1.6926, -3.7833, -0.7052, -0.0437]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3239,  4.5449, -1.8279, -3.4677, -0.6428, -0.3255]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.6563,  0.2607,  2.3716, -3.9302, -0.3103, -0.6870]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7541,  2.0389, -1.8359, -3.8401,  2.8281, -0.1247]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9903,  0.8738, -3.0743, -2.2531,  2.0517,  1.4377]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4407, -1.8166,  3.6396, -3.5381,  1.3970, -0.9573]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8607, -1.0136, -0.7826, -2.6412,  0.1966,  2.9272]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8774,  3.0783, -3.9037, -0.8187, -1.1936,  2.6596]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6445,  0.7154,  2.3008, -3.2712, -3.1767,  0.9214]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0686,  4.9032, -2.2743, -1.7577, -1.9335,  0.7239]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0664,  4.9947, -1.1425, -2.8523, -1.6881, -0.7035]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7202,  3.4261,  0.5052, -4.1974, -1.8324, -0.4668]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.8847, -1.0808, -0.9083, -3.0442,  3.8684, -0.1795]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3383, -3.4934, -1.2083,  1.8415,  0.7490,  2.7165]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0677,  4.3500, -2.6807, -1.0819, -2.7206,  0.5816]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8887,  1.0948,  1.6476, -2.0135, -3.8459,  0.8135]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1999, -1.4830,  3.5128, -3.2608, -1.0488,  0.3714]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0235,  1.7671,  0.8398, -3.0968, -1.2884,  0.5931]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4457,  0.6499, -1.7159, -2.3164, -2.0695,  3.4725]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6876, -0.3563, -1.3784, -0.4599, -2.4624,  4.4785]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0956, -0.1022, -2.7057,  4.2875, -0.9461,  0.8222]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5025,  0.7570, -1.6282, -2.2790, -2.1027,  4.1304]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8068,  5.0388, -2.2679, -2.0976, -1.6630,  0.4493]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.0955e-01, -9.6968e-01, -1.7179e+00,  5.4302e+00, -1.3589e+00,\n",
            "         -2.7515e-03]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8059,  2.7618,  1.0753, -4.2220, -2.0759, -0.1485]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5459, -3.7861,  0.0404,  0.9920,  2.3041,  0.4284]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6440,  2.1878, -1.3920, -4.1168, -1.1220,  1.9295]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1852, -0.4363, -2.5163, -1.6781,  0.0366,  4.1574]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2199, -0.1490, -2.1420,  3.8639, -2.1128,  1.4714]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4745, -1.5909, -1.5906,  4.9480,  0.4435, -0.7835]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7501, -0.4606, -2.5898, -1.6528,  4.7684,  0.2527]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5354, -0.9890, -1.9158, -2.2966,  4.2958,  1.1308]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1839, -0.3886, -2.0147, -3.0434,  1.4929,  2.3649]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6396,  2.3956, -2.6821,  0.5036, -2.2404,  2.1653]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.9178,  0.6060, -0.4491, -3.4843,  2.0978, -1.7875]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9336,  1.3155, -3.5802,  0.5555, -1.1052,  3.2082]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7737,  4.0238, -2.8201, -2.5044, -1.3206,  1.9096]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0592,  4.6276, -1.2358, -3.6405, -0.8815, -0.3241]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0170,  4.5209, -1.0397, -3.3772, -1.4358, -0.1878]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0646, -2.4985, -0.3156, -1.8225,  4.0794,  0.7157]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.6200, -1.2693, -0.8827, -0.7997,  5.4312, -1.3665]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7902, -0.1609,  0.7234, -4.1205, -0.7553,  2.3394]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4210,  4.9938, -1.5313, -2.9206, -1.5733, -0.0511]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1338,  5.1687, -1.8983, -2.5992, -0.9903, -0.7039]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0656,  4.6986, -1.5122, -3.1951, -1.3661, -0.1908]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9115, -0.5914, -2.8573, -0.4101,  0.0120,  4.4156]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1461,  2.2660, -2.2171, -3.3359, -1.2337,  2.8933]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6946, -1.5463, -3.3002,  2.1499,  0.8134,  3.2841]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5414, -0.5209, -3.5643,  1.3247,  0.8501,  2.9769]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4470, -1.1607, -2.0224,  2.0290,  3.0826, -1.5305]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1364, -1.1348, -2.1918, -1.3683, -0.3605,  4.5145]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5737,  5.0880, -2.0638, -2.4100, -1.5569,  0.0853]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1256,  5.1535, -1.9129, -2.5823, -1.0459, -0.7202]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.1656, -1.6950,  0.3607, -2.4064,  1.3218,  0.6858]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3612,  0.3725, -2.5669, -0.1938, -2.0535,  3.3260]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4018, -0.3877, -2.8521, -0.6547,  4.7197,  0.2065]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.5748,  0.2977, -2.3552, -3.0394, -0.1299,  3.3729]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7235, -1.2290, -0.0473, -3.2129, -0.6779,  3.4905]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3946,  5.1074, -1.9298, -1.7180, -2.2150, -0.2457]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2765,  4.4370, -2.6150, -2.9298,  0.7244, -0.5271]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8981, -0.0102, -1.7616,  1.7122, -2.8094,  3.4260]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-1.2710,  1.4244, -3.0534,  0.3467, -1.7823,  3.5844]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1620, -0.6386, -2.9374, -1.5418, -0.1678,  4.1675]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6250,  5.1369, -1.8504, -2.3237, -1.6987, -0.0176]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1078,  5.1514, -2.0921, -2.4687, -0.7653, -0.7610]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1114, -2.9347, -0.5956,  4.0156, -0.3171,  0.1306]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.4804, -0.2557, -0.8445,  0.2390, -3.1304,  2.0072]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9919, -0.1734, -3.2041,  3.6610, -1.3089,  2.6242]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3406,  4.7514, -2.2409, -3.1034, -0.6326, -0.4026]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.7717,  1.0359, -3.8705,  0.9696,  0.7487,  2.4611]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3414, -0.1957, -3.4835, -1.4948,  2.2336,  2.6407]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3504,  0.4378, -2.5258, -0.6204, -2.0042,  4.1491]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3771, -1.1467,  1.5318, -0.9566, -3.6422,  3.2706]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3924,  4.8469, -2.9716, -1.1024, -1.7410,  0.2861]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0242,  5.0291, -1.2221, -2.9359, -1.2854, -0.8794]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7939,  3.6787,  0.1495, -3.9895, -1.4501, -0.7996]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5191,  2.9792, -1.5891, -3.1630, -2.2651,  2.5075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.5913,  5.1448, -2.0456, -2.2788, -1.6198, -0.0141]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0062,  5.0918, -1.5727, -2.7522, -1.1858, -0.8536]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4186, -1.3026, -1.0706, -1.3776,  5.3418, -0.4501]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.8441, -0.6358, -3.8048,  2.1198,  0.3867,  3.3403]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.3621, -1.2365, -2.1433, -1.3350, -0.0297,  4.4848]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2304, -0.8853, -2.9670, -0.6446,  1.5644,  3.1060]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.0314,  2.0120, -2.3090, -3.3186,  3.2168, -0.5075]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.4192, -1.2630, -1.6882,  0.9444, -1.4043,  3.9220]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6110,  5.1161, -1.9303, -2.5142, -1.4246,  0.0059]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.4777,  4.8409, -2.3523, -2.5442, -0.9803, -0.7388]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.5263, -2.2623,  3.8039, -3.0038, -0.6274,  0.3472]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0340,  0.1072, -4.0926,  0.1865,  1.2278,  2.8173]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.1234,  4.9540, -1.3998, -2.9918, -1.2717, -0.7797]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6231,  5.0731, -2.2538, -1.9076, -1.9055,  0.1645]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.2976,  4.9244, -2.3377, -2.4249, -0.9606, -0.6374]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.8845, -0.3889, -0.0918, -2.3587,  4.9341, -1.6484]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.1244,  2.0719, -2.1239, -4.1465,  2.5217, -0.0888]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.3849, -1.2874, -3.2977,  2.1102,  1.8188,  1.4158]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.9146, -2.4064, -0.9073,  1.1723,  2.2418, -0.5405]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9464, -1.4593,  0.1426, -1.2359,  5.1052, -1.7604]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2597, -2.2471, -0.4625,  3.6356, -1.0388,  1.7292]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0172,  1.5867, -1.1931, -4.0276,  0.2554,  2.3983]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2316,  5.1194, -2.1068, -2.5842, -1.0108, -0.3334]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.0301,  4.9791, -2.1382, -2.8996, -0.6203, -0.5124]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 2.3535, -1.7245,  3.3986, -2.2399, -0.7912, -1.1223]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-3.3100e-03,  4.9929e+00, -2.1251e+00, -2.4766e+00, -1.2600e+00,\n",
            "         -2.6334e-01]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.1688,  5.0291, -1.9268, -2.6668, -1.4930, -0.1386]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7693,  3.9277, -0.1796, -3.9436, -0.8652, -1.1776]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0092, -2.4713, -0.6750,  4.8010, -1.0753,  0.7528]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.9541,  0.1568, -1.1102, -3.7576,  2.3249,  1.1890]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 0.7345,  0.5523, -2.2018, -3.6144,  2.1645,  1.8509]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6281,  1.5556, -2.7822, -1.5498, -1.3919,  3.5955]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.9200,  1.3245, -1.9984, -1.9538, -2.1970,  4.0108]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2635,  5.1101, -2.1063, -2.6049, -0.8681, -0.4044]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.2195,  5.0183, -1.7324, -2.8814, -1.4563, -0.2218]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[ 1.3014, -2.7311,  4.3352, -1.1377, -0.0277, -1.1855]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.6512, -0.7627, -3.0684, -0.5037,  0.1694,  4.4731]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "tensor([[-0.0078, -1.6565, -2.4487,  4.2014,  2.0883, -0.0774]],\n",
            "       device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "5iqKUYUFuHfB",
        "outputId": "21c269a8-d9a6-46f9-84ea-e9d71fed2243"
      },
      "source": [
        "tf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>xuhao</th>\n",
              "      <th>fenlei</th>\n",
              "      <th>leibie</th>\n",
              "      <th>title</th>\n",
              "      <th>juzi</th>\n",
              "      <th>label</th>\n",
              "      <th>pre</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>唐王冰注。</td>\n",
              "      <td>b</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>《汉书·艺文志》载《黄帝内经》十八篇，无《素问》之名。</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>後汉张机《伤寒论》引之，始称《素问》。</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>晋皇甫谧《甲乙经序》，称《针经》九卷，《素问》九卷，皆为《内经》，与《汉志》十八篇之数合，则...</td>\n",
              "      <td>d</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>医家类</td>\n",
              "      <td>●卷一百三·子部十三●医家类一</td>\n",
              "      <td>△《黄帝素问》·二十四卷（内府藏本）</td>\n",
              "      <td>故《隋书·经籍志》始著录也，然《隋志》所载只八卷，全元起所注已阙其第七。</td>\n",
              "      <td>b,d</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   xuhao fenlei  ... label pre\n",
              "0      0    医家类  ...     b   b\n",
              "1      1    医家类  ...     d   d\n",
              "2      2    医家类  ...     d   d\n",
              "3      3    医家类  ...     d   d\n",
              "4      4    医家类  ...   b,d   d\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVasZdHStMIq"
      },
      "source": [
        "tf.to_csv('miaomiao.csv',index=None,encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}