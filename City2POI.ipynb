{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "seq2seq_translation_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/MultiCity/blob/main/City2POI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqOI185olb9W"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0SU57-Vewmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e024e00f-91ed-4f75-e4df-c51b5755cb33"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxig8rKxe6eI"
      },
      "source": [
        "!cp /content/drive/MyDrive/language.csv /content"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoXcUg_YfQbZ"
      },
      "source": [
        "!cp /content/language.csv /content/data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNgus06dfWnu"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTRvCVQWfY6r"
      },
      "source": [
        "poi=pd.read_csv('/content/data/language.csv')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91_kdN7bfeZ5"
      },
      "source": [
        "sview=pd.read_csv('/content/streetview2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_L8y3jfjff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "b82cd4ba-014f-4d7a-d93f-08c95136af5b"
      },
      "source": [
        "poi.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>lat_gcj</th>\n",
              "      <th>lon_gcj</th>\n",
              "      <th>lat_wgs</th>\n",
              "      <th>lon_wgs</th>\n",
              "      <th>pov_exp</th>\n",
              "      <th>heading</th>\n",
              "      <th>POI</th>\n",
              "      <th>POI32</th>\n",
              "      <th>POI64</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>CATEGORY50</th>\n",
              "      <th>CATEGORY100</th>\n",
              "      <th>language2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10141003150306134427600</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.458431</td>\n",
              "      <td>114.307388</td>\n",
              "      <td>30.460880</td>\n",
              "      <td>114.301952</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>Tree Plant House Window Car Land Street Billbo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10141003150306134525400</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.461331</td>\n",
              "      <td>114.306847</td>\n",
              "      <td>30.463780</td>\n",
              "      <td>114.301411</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>Tree House Plant Window Footwear Land Human Wh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10141003150306134608900</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.463268</td>\n",
              "      <td>114.308234</td>\n",
              "      <td>30.465714</td>\n",
              "      <td>114.302797</td>\n",
              "      <td>2</td>\n",
              "      <td>228</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>Tree Window House Plant Car Building Palm Whee...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10141003150306134621500</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.463926</td>\n",
              "      <td>114.308983</td>\n",
              "      <td>30.466371</td>\n",
              "      <td>114.303544</td>\n",
              "      <td>2</td>\n",
              "      <td>225</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>Tree Window House Building Car Train Plant Whe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10141003150306134625100</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.464176</td>\n",
              "      <td>114.309251</td>\n",
              "      <td>30.466621</td>\n",
              "      <td>114.303812</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>Tree Window House Plant Car Wheel</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id  ...                                          language2\n",
              "0  10141003150306134427600  ...  Tree Plant House Window Car Land Street Billbo...\n",
              "1  10141003150306134525400  ...  Tree House Plant Window Footwear Land Human Wh...\n",
              "2  10141003150306134608900  ...  Tree Window House Plant Car Building Palm Whee...\n",
              "3  10141003150306134621500  ...  Tree Window House Building Car Train Plant Whe...\n",
              "4  10141003150306134625100  ...                  Tree Window House Plant Car Wheel\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTb3Oqjga5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c82fa3ac-ea8d-412d-bd21-d0a5af6d3ef6"
      },
      "source": [
        "test=poi['CATEGORY'].values.tolist()[0]\n",
        "test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅', '摩托车维修', '清真菜馆', '美容美发店', '美容美发店']\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNL52rurggOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6696898b-fd6a-477a-fcc9-51f8f507fbe2"
      },
      "source": [
        "eval(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['生活服务场所',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '生活服务场所',\n",
              " '美容美发店',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '建筑公司',\n",
              " '汽车维修',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '乡镇以下级政府及事业单位']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAwFIiH_ftJ4"
      },
      "source": [
        "# poi['language']=['CATEGORY']\n",
        "poi['language'] = poi.apply(lambda x: ' '.join(eval(x['CATEGORY'])), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjrEmHv9g7Iz"
      },
      "source": [
        "## 构建训练对"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kn8eKzgN3Zf"
      },
      "source": [
        "CATEGORY\tCATEGORY50\tCATEGORY100\tlanguage2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBIAJ4gVhyZ",
        "outputId": "9230b2a8-41d4-4eac-bcdc-659b677b289b"
      },
      "source": [
        "!pip install pypinyin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 23.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 12.7 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 92 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████                            | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 327 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 337 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 348 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 358 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 368 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 378 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 389 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 399 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 409 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 419 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 430 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 440 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 450 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 460 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 471 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 481 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 491 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 501 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 512 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 522 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 532 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 542 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 552 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 563 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 573 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 583 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 593 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 604 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 614 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 624 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 634 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 645 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 655 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 665 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 675 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 686 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 696 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 706 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 716 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 727 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 737 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 747 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 757 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 768 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 778 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 788 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 798 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 808 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 819 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 829 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 839 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 849 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 860 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 870 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 880 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 890 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 901 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 911 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 921 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 931 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 942 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 952 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 962 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 972 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 983 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 993 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.0 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.2 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zoo6bMfcVlav",
        "outputId": "f7b58a7a-19d0-4d2d-f68f-7ccce1cac9c3"
      },
      "source": [
        "from pypinyin import pinyin, lazy_pinyin, Style\n",
        "''.join(lazy_pinyin('中心'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'zhongxin'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxUSudSPN5iF"
      },
      "source": [
        "pairs=[]\n",
        "with open('/content/data/poi-sv.txt','w+',encoding='utf-8') as f:\n",
        "  for index, row in poi.iterrows():\n",
        "      # print(index) # 输出每行的索引值\n",
        "      tmp=eval(row['CATEGORY'])\n",
        "      # emp=[]\n",
        "      # for i in tmp:\n",
        "      #   emp.append(' '.join(i))\n",
        "      #   #lazy_pinyin(i)\n",
        "      # f.write(' '.join(emp))\n",
        "\n",
        "      f.write(' '.join(tmp))\n",
        "      f.write('\\t')\n",
        "      f.write(row['language2'])\n",
        "      f.write('\\n')\n",
        "      pairs.append(\n",
        "      [' '.join(tmp).strip(),row['language2']]\n",
        "      )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Mp1L8fujdyR",
        "outputId": "534a5069-eb7d-4164-b605-5b7560aefb6f"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店',\n",
              " 'Tree Plant House Window Car Land Street Billboard Tire']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip_MQcRXlb9b"
      },
      "source": [
        "\n",
        "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
        "*******************************************************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
        "\n",
        "This is the third and final tutorial on doing \"NLP From Scratch\", where we\n",
        "write our own classes and functions to preprocess the data to do our NLP\n",
        "modeling tasks. We hope after you complete this tutorial that you'll proceed to\n",
        "learn how `torchtext` can handle much of this preprocessing for you in the\n",
        "three tutorials immediately following this one.\n",
        "\n",
        "In this project we will be teaching a neural network to translate from\n",
        "French to English.\n",
        "\n",
        "::\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > il est en train de peindre un tableau .\n",
        "    = he is painting a picture .\n",
        "    < he is painting a picture .\n",
        "\n",
        "    > pourquoi ne pas essayer ce vin delicieux ?\n",
        "    = why not try that delicious wine ?\n",
        "    < why not try that delicious wine ?\n",
        "\n",
        "    > elle n est pas poete mais romanciere .\n",
        "    = she is not a poet but a novelist .\n",
        "    < she not not a poet but a novelist .\n",
        "\n",
        "    > vous etes trop maigre .\n",
        "    = you re too skinny .\n",
        "    < you re all alone .\n",
        "\n",
        "... to varying degrees of success.\n",
        "\n",
        "This is made possible by the simple but powerful idea of the `sequence\n",
        "to sequence network <https://arxiv.org/abs/1409.3215>`__, in which two\n",
        "recurrent neural networks work together to transform one sequence to\n",
        "another. An encoder network condenses an input sequence into a vector,\n",
        "and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "To improve upon this model we'll use an `attention\n",
        "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
        "learn to focus over a specific range of the input sequence.\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  https://pytorch.org/ For installation instructions\n",
        "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
        "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
        "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
        "\n",
        "\n",
        "It would also be useful to know about Sequence to Sequence networks and\n",
        "how they work:\n",
        "\n",
        "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
        "-  `Sequence to Sequence Learning with Neural\n",
        "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
        "-  `Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
        "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
        "\n",
        "You will also find the previous tutorials on\n",
        ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
        "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
        "helpful as those concepts are very similar to the Encoder and Decoder\n",
        "models, respectively.\n",
        "\n",
        "**Requirements**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIy1czP8lb9d"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZnTlENJGu21",
        "outputId": "1c94c254-9a77-4c84-ebfa-aaa192e98036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWJ_GhGglb9e"
      },
      "source": [
        "Loading data files\n",
        "==================\n",
        "\n",
        "The data for this project is a set of many thousands of English to\n",
        "French translation pairs.\n",
        "\n",
        "`This question on Open Data Stack\n",
        "Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n",
        "pointed me to the open translation site https://tatoeba.org/ which has\n",
        "downloads available at https://tatoeba.org/eng/downloads - and better\n",
        "yet, someone did the extra work of splitting language pairs into\n",
        "individual text files here: https://www.manythings.org/anki/\n",
        "\n",
        "The English to French pairs are too big to include in the repo, so\n",
        "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
        "separated list of translation pairs:\n",
        "\n",
        "::\n",
        "\n",
        "    I am cold.    J'ai froid.\n",
        "\n",
        ".. Note::\n",
        "   Download the data from\n",
        "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "   and extract it to the current directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaG9_ie5lb9f"
      },
      "source": [
        "Similar to the character encoding used in the character-level RNN\n",
        "tutorials, we will be representing each word in a language as a one-hot\n",
        "vector, or giant vector of zeros except for a single one (at the index\n",
        "of the word). Compared to the dozens of characters that might exist in a\n",
        "language, there are many many more words, so the encoding vector is much\n",
        "larger. We will however cheat a bit and trim the data to only use a few\n",
        "thousand words per language.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0EPrID4lb9g"
      },
      "source": [
        "We'll need a unique index per word to use as the inputs and targets of\n",
        "the networks later. To keep track of all this we will use a helper class\n",
        "called ``Lang`` which has word → index (``word2index``) and index → word\n",
        "(``index2word``) dictionaries, as well as a count of each word\n",
        "``word2count`` which will be used to replace rare words later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aAVNeMFSZLF"
      },
      "source": [
        "我们需要每个单词有一个唯一的索引，以便稍后用作网络的输入和目标。为了跟踪所有这些，我们将使用一个名为Lang的助手类，该类包含word→ 索引（word2index）和索引→ 单词（index2word）字典，以及每个单词的计数word2count，稍后将用于替换稀有单词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvufVOXVlb9h"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59vgGnxHlb9h"
      },
      "source": [
        "The files are all in Unicode, to simplify we will turn Unicode\n",
        "characters to ASCII, make everything lowercase, and trim most\n",
        "punctuation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYfE3Qllb9i"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    # s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    # s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQVMAJdLjVGT",
        "outputId": "6022cb48-67c4-4b22-d490-1b5d6a086a62"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店',\n",
              " 'Tree Plant House Window Car Land Street Billboard Tire']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT8mpEa2lb9i"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split\n",
        "lines into pairs. The files are all English → Other Language, so if we\n",
        "want to translate from Other Language → English I added the ``reverse``\n",
        "flag to reverse the pairs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "J5cN3BV0k_cO",
        "outputId": "64388ca1-f8c9-46a2-96d8-c3700cdd78b2"
      },
      "source": [
        "normalizeString('武汉大师兄 是多少')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'武汉大师兄 是多少'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DMdNOFPkznW"
      },
      "source": [
        "这里修改的时候pairs[1] 是空，其实是normalizeString错了"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uP5tQvBlb9j"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1lWhExSLHC"
      },
      "source": [
        "## 修改这个函数"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5W7e-pClb9j"
      },
      "source": [
        "Since there are a *lot* of example sentences and we want to train\n",
        "something quickly, we'll trim the data set to only relatively short and\n",
        "simple sentences. Here the maximum length is 10 words (that includes\n",
        "ending punctuation) and we're filtering to sentences that translate to\n",
        "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
        "earlier).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FluxrUxaXDrN"
      },
      "source": [
        "因为有很多例句，我们想快速地训练一些东西，所以我们将把数据集精简为相对简短的句子。这里的最大长度是10个单词（包括结尾标点符号），我们将过滤到翻译为“我是”或“他是”等形式的句子（考虑前面替换的撇号）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyKYOx12lU4B"
      },
      "source": [
        "我们修改好了，不需要"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkVqrvOVlb9k"
      },
      "source": [
        "MAX_LENGTH =11\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7CtW4KCl3WE",
        "outputId": "35f1f730-4fbe-4bd3-903b-b57800cae8de"
      },
      "source": [
        "input_lang, output_lang, pairs = readLangs('poi', 'sv', True)\n",
        "pairs[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rckZfxOnlyWt",
        "outputId": "c19e3477-64e7-4385-93e8-75da8dc76d47"
      },
      "source": [
        "filterPairs(pairs[0])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qsGEjIIDkQoo",
        "outputId": "62c752aa-6751-4651-81a7-89ebb8d0d9cb"
      },
      "source": [
        "pairs[0][1]"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店'"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d-kkDcLXhMK",
        "outputId": "1b963f3c-ffb7-45b2-d990-6f695a8ef9f8"
      },
      "source": [
        "len(pairs[0][1].split(' '))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH41FHouXZfp",
        "outputId": "1dc7fba9-1ef2-4890-8d4f-025e838fdfdc"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUD_lDvUVE4h",
        "outputId": "eeaebc02-3f45-4706-a183-8cf2f20256e5"
      },
      "source": [
        "filterPair([\"i am \", \"i m \"])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aevyO2utVB0K",
        "outputId": "983f017d-014e-4f15-d209-858e1807707e"
      },
      "source": [
        "filterPairs(pairs[0])"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74xSsR4lb9k"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "-  Read text file and split into lines, split lines into pairs\n",
        "-  Normalize text, filter by length and content\n",
        "-  Make word lists from sentences in pairs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGz7OhD_uOeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290a3be8-a67c-4d30-c102-daa192f76410"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/astorfi/sequence-to-sequence-from-scratch/master/data/eng-fra.txt"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-08-31 02:56:41--  https://raw.githubusercontent.com/astorfi/sequence-to-sequence-from-scratch/master/data/eng-fra.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9541158 (9.1M) [text/plain]\n",
            "Saving to: ‘eng-fra.txt.1’\n",
            "\n",
            "\reng-fra.txt.1         0%[                    ]       0  --.-KB/s               \reng-fra.txt.1       100%[===================>]   9.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-31 02:56:42 (93.2 MB/s) - ‘eng-fra.txt.1’ saved [9541158/9541158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnjTVWSlb9l"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    # pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNiPWFpnlnbK"
      },
      "source": [
        "# filterPairs(pairs)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-00Ci-hQvXni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a30776b2-6919-4c84-f0f2-a72fcc083162"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20790"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXhkqufRkize"
      },
      "source": [
        "文件修改"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbJag322vYqr"
      },
      "source": [
        "# texts=\"\"\n",
        "# for i in pairs:\n",
        "#   texts=texts+i[0]\n",
        "# len(set(texts.split(' '))\n",
        "# )"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBYp2jAUsgw",
        "outputId": "d196e906-77c9-43ec-a40b-5b7a4c2ca7e8"
      },
      "source": [
        "input_lang, output_lang, pairs = readLangs('poi', 'sv', True)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEw-KxnskofN",
        "outputId": "91fc5454-4943-4228-e5f8-c6c6b824f6c2"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pnvJP5nU1hr",
        "outputId": "e30b8673-7c47-4dfe-ee0c-b23de91319f0"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20790"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-eLofhHUwQy",
        "outputId": "25c01473-0447-4cb5-f245-65396e5742a8"
      },
      "source": [
        "type(input_lang)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Lang"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NqxR4sMunH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecb49ee9-f981-4e38-fd5f-2b5803229570"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('poi', 'sv', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading lines...\n",
            "Read 20790 sentence pairs\n",
            "Trimmed to 20790 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "sv 141\n",
            "poi 536\n",
            "['tree window bench building train plant car street flower land', '社会治安机构 楼栋号 住宅小区 临街院正门 驾校 诊所 楼栋号 诊所 临街院门 楼栋号']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9FAVCTzlb9l"
      },
      "source": [
        "The Seq2Seq Model\n",
        "=================\n",
        "\n",
        "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
        "sequence and uses its own output as input for subsequent steps.\n",
        "\n",
        "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
        "seq2seq network, or `Encoder Decoder\n",
        "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
        "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
        "an input sequence and outputs a single vector, and the decoder reads\n",
        "that vector to produce an output sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "Unlike sequence prediction with a single RNN, where every input\n",
        "corresponds to an output, the seq2seq model frees us from sequence\n",
        "length and order, which makes it ideal for translation between two\n",
        "languages.\n",
        "\n",
        "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
        "black cat\". Most of the words in the input sentence have a direct\n",
        "translation in the output sentence, but are in slightly different\n",
        "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
        "construction there is also one more word in the input sentence. It would\n",
        "be difficult to produce a correct translation directly from the sequence\n",
        "of input words.\n",
        "\n",
        "With a seq2seq model the encoder creates a single vector which, in the\n",
        "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
        "vector — a single point in some N dimensional space of sentences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHYjcrfAlb9m"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for\n",
        "every word from the input sentence. For every input word the encoder\n",
        "outputs a vector and a hidden state, and uses the hidden state for the\n",
        "next input word.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Ugirgilb9m"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk-ODgwslb9n"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "The decoder is another RNN that takes the encoder output vector(s) and\n",
        "outputs a sequence of words to create the translation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxJlejJ2lb9n"
      },
      "source": [
        "Simple Decoder\n",
        "^^^^^^^^^^^^^^\n",
        "\n",
        "In the simplest seq2seq decoder we use only last output of the encoder.\n",
        "This last output is sometimes called the *context vector* as it encodes\n",
        "context from the entire sequence. This context vector is used as the\n",
        "initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and\n",
        "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
        "token, and the first hidden state is the context vector (the encoder's\n",
        "last hidden state).\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajg3EWg_lb9o"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCcusKVFlb9p"
      },
      "source": [
        "I encourage you to train and observe the results of this model, but to\n",
        "save space we'll be going straight for the gold and introducing the\n",
        "Attention Mechanism.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwSnRRqolb9q"
      },
      "source": [
        "Attention Decoder\n",
        "^^^^^^^^^^^^^^^^^\n",
        "\n",
        "If only the context vector is passed between the encoder and decoder,\n",
        "that single vector carries the burden of encoding the entire sentence.\n",
        "\n",
        "Attention allows the decoder network to \"focus\" on a different part of\n",
        "the encoder's outputs for every step of the decoder's own outputs. First\n",
        "we calculate a set of *attention weights*. These will be multiplied by\n",
        "the encoder output vectors to create a weighted combination. The result\n",
        "(called ``attn_applied`` in the code) should contain information about\n",
        "that specific part of the input sequence, and thus help the decoder\n",
        "choose the right output words.\n",
        "\n",
        ".. figure:: https://i.imgur.com/1152PYf.png\n",
        "   :alt:\n",
        "\n",
        "Calculating the attention weights is done with another feed-forward\n",
        "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
        "Because there are sentences of all sizes in the training data, to\n",
        "actually create and train this layer we have to choose a maximum\n",
        "sentence length (input length, for encoder outputs) that it can apply\n",
        "to. Sentences of the maximum length will use all the attention weights,\n",
        "while shorter sentences will only use the first few.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC9ytHoFlb9q"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVaME_wrlb9q"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
        "  limitation by using a relative position approach. Read about \"local\n",
        "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
        "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
        "\n",
        "Training\n",
        "========\n",
        "\n",
        "Preparing Training Data\n",
        "-----------------------\n",
        "\n",
        "To train, for each pair we will need an input tensor (indexes of the\n",
        "words in the input sentence) and target tensor (indexes of the words in\n",
        "the target sentence). While creating these vectors we will append the\n",
        "EOS token to both sequences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYFLv3ilb9r"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSaW3zo6lb9r"
      },
      "source": [
        "Training the Model\n",
        "------------------\n",
        "\n",
        "To train we run the input sentence through the encoder, and keep track\n",
        "of every output and the latest hidden state. Then the decoder is given\n",
        "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
        "encoder as its first hidden state.\n",
        "\n",
        "\"Teacher forcing\" is the concept of using the real target outputs as\n",
        "each next input, instead of using the decoder's guess as the next input.\n",
        "Using teacher forcing causes it to converge faster but `when the trained\n",
        "network is exploited, it may exhibit\n",
        "instability <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with\n",
        "coherent grammar but wander far from the correct translation -\n",
        "intuitively it has learned to represent the output grammar and can \"pick\n",
        "up\" the meaning once the teacher tells it the first few words, but it\n",
        "has not properly learned how to create the sentence from the translation\n",
        "in the first place.\n",
        "\n",
        "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
        "choose to use teacher forcing or not with a simple if statement. Turn\n",
        "``teacher_forcing_ratio`` up to use more of it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3b8TbWzlb9s"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et8hCknylb9s"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time\n",
        "remaining given the current time and progress %.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngcd8gsslb9t"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_V5GHuWlb9t"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "-  Start a timer\n",
        "-  Initialize optimizers and criterion\n",
        "-  Create set of training pairs\n",
        "-  Start empty losses array for plotting\n",
        "\n",
        "Then we call ``train`` many times and occasionally print the progress (%\n",
        "of examples, time so far, estimated time) and average loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Jsu1n6wmtH_"
      },
      "source": [
        "整个训练过程看起来像这样。\n",
        "\n",
        "- 启动一个定时器\n",
        "- 初始化优化器和准则\n",
        "- 创建一组训练对\n",
        "- 启动空的损失数组以进行绘图\n",
        "\n",
        "然后我们多次调用``train``，并不时地打印进度（到目前为止的例子百分比\n",
        "的例子，到目前为止的时间，估计时间）和平均损失。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW9xHRUelb9u"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-rwK4X2lb9u"
      },
      "source": [
        "Plotting results\n",
        "----------------\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values\n",
        "``plot_losses`` saved while training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbBGUBxKlb9u"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.sans-serif']=['SimHei'] #用来正常显示中文标签\n",
        "plt.rcParams['axes.unicode_minus']=False #用来正常显示负号\n",
        "\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKoUgTi-lb9v"
      },
      "source": [
        "Evaluation\n",
        "==========\n",
        "\n",
        "Evaluation is mostly the same as training, but there are no targets so\n",
        "we simply feed the decoder's predictions back to itself for each step.\n",
        "Every time it predicts a word we add it to the output string, and if it\n",
        "predicts the EOS token we stop there. We also store the decoder's\n",
        "attention outputs for display later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fGZhv5xrRNj"
      },
      "source": [
        "能不能在这里找到encoder_hidden 或者嵌入向量？找i到单词嵌入？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoJ5MV3YXI8I",
        "outputId": "0dd7ef66-0ca3-41f4-bf17-0c25b0f01438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1, pairs[0][0], 11)[1].shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM8YmaprXh23",
        "outputId": "78eb9db1-9645-4d76-abb0-2cb622f06f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pairs[0][0]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tree plant house window car land street billboard tire'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzBvlP_uXdN7",
        "outputId": "8252775e-fe9c-410a-97cb-74ae4090758b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1, pairs[0][0], 11)[2].shape"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[ 0.0050,  0.9987, -0.0852,  ...,  0.9898,  0.9306, -0.1805],\n",
            "        [-0.0349,  0.9982, -0.1514,  ...,  0.9869, -0.9909, -0.1076],\n",
            "        [ 0.5328, -0.9968, -0.1231,  ...,  0.9869,  0.9844, -0.1183],\n",
            "        ...,\n",
            "        [-0.0992, -0.9906, -0.1164,  ...,  0.9796,  0.9732,  0.9416],\n",
            "        [-0.1001, -0.9898, -0.1171,  ...,  0.9797,  0.9342,  0.9261],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lq3NnzM-Z74F",
        "outputId": "aa200d11-5307-49b4-a425-f1c2b637fdc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pairs[0:10]"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['tree plant house window car land street billboard tire',\n",
              "  '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店'],\n",
              " ['tree house plant window footwear land human wheel car street',\n",
              "  '餐饮相关 中餐厅 餐饮相关 物流速递 其它农林牧渔基地 汽车维修 公司 公司 快餐厅 公司'],\n",
              " ['tree window house plant car building palm wheel land van',\n",
              "  '政府及社会团体相关 公司 公司 机械电子 公司 科教文化场所 餐饮相关 中餐厅 餐饮相关 政府及社会团体相关'],\n",
              " ['tree window house building car train plant wheel boat',\n",
              "  '机械电子 公司 政府及社会团体相关 公司 科教文化场所 政府及社会团体相关 住宅小区 公司 汽车综合维修 桥'],\n",
              " ['tree window house plant car wheel',\n",
              "  '机械电子 公司 科教文化场所 政府及社会团体相关 公司 政府及社会团体相关 住宅小区 汽车综合维修 桥 政府及社会团体相关'],\n",
              " ['tree window house plant car building person wheel land',\n",
              "  '公司 科教文化场所 机械电子 政府及社会团体相关 住宅小区 汽车综合维修 政府及社会团体相关 便民商店/便利店 建材五金市场 桥'],\n",
              " ['tree house window plant car wheel',\n",
              "  '政府及社会团体相关 汽车综合维修 政府及社会团体相关 建材五金市场 科教文化场所 便民商店/便利店 住宅小区 乡镇以下级政府及事业单位 乡镇以下级政府及事业单位 乡镇以下级政府及事业单位'],\n",
              " ['tree window house plant street car building wheel land palm',\n",
              "  '中餐厅 中餐厅 快餐厅 汽车配件销售 旅馆招待所 自动提款机 临街院门 生活服务场所 中餐厅 旅馆招待所'],\n",
              " ['tree window house plant car building palm skyscraper land wheel',\n",
              "  '临街院门 高等院校 生活服务场所 自动提款机 中餐厅 职业技术学校 诊所 高等院校 职业技术学校 培训机构'],\n",
              " ['tree window house wheel plant truck person clothing land tire',\n",
              "  '培训机构 汽车维修 临街院门 汽车综合维修 物流速递 汽车维修 临街院门 生活服务场所 中餐厅 生活服务场所']]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww-eL-jIZu-M",
        "outputId": "577a4d24-ff40-4e6e-f5a9-9297e07292a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1,'tree house window plant car wheel', 11)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[ 0.0050,  0.9987, -0.0852,  ...,  0.9898,  0.9306, -0.1805],\n",
            "        [ 0.3252, -0.9999,  0.4221,  ...,  0.9897,  0.9990, -0.2297],\n",
            "        [ 0.3524, -0.9745,  0.7969,  ...,  0.9895,  0.9980, -0.9228],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['临街院门',\n",
              "  '住宅小区',\n",
              "  '临街院门',\n",
              "  '临街院门',\n",
              "  '临街院门',\n",
              "  '临街院门',\n",
              "  '临街院门',\n",
              "  '临街院门',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '<EOS>'],\n",
              " tensor([[1.1605e-05, 2.3282e-05, 9.9980e-01, 5.0843e-07, 3.7539e-08, 6.7308e-06,\n",
              "          6.8762e-06, 5.0362e-05, 1.6756e-05, 4.8202e-06, 8.1925e-05],\n",
              "         [1.3764e-03, 7.1089e-04, 3.2003e-04, 1.9484e-04, 1.2371e-06, 9.6058e-01,\n",
              "          7.7739e-03, 2.3251e-03, 8.7646e-03, 1.7206e-02, 7.4312e-04],\n",
              "         [7.4651e-02, 5.5732e-04, 8.7867e-04, 1.2296e-03, 8.8658e-01, 4.0239e-03,\n",
              "          1.0302e-02, 1.9453e-02, 5.4129e-04, 1.2730e-03, 5.0963e-04],\n",
              "         [1.1019e-04, 2.3588e-02, 1.7183e-03, 5.1203e-03, 1.6542e-04, 9.0337e-01,\n",
              "          3.1668e-02, 1.1008e-02, 9.8336e-03, 8.6062e-03, 4.8089e-03],\n",
              "         [8.7327e-06, 4.6483e-03, 1.0945e-03, 7.2392e-03, 1.6048e-05, 9.7418e-01,\n",
              "          5.4948e-03, 2.9275e-03, 2.3506e-03, 1.5444e-03, 4.9996e-04],\n",
              "         [3.0531e-05, 4.6507e-03, 4.9169e-03, 1.3617e-02, 6.2447e-04, 9.5077e-01,\n",
              "          9.4990e-03, 3.9725e-03, 6.2745e-03, 5.1062e-03, 5.3717e-04],\n",
              "         [1.0533e-05, 4.5441e-03, 5.5196e-03, 1.6290e-02, 1.2028e-03, 9.4371e-01,\n",
              "          1.3645e-02, 1.0112e-03, 9.0846e-03, 4.6803e-03, 3.0263e-04],\n",
              "         [4.3416e-05, 1.3290e-03, 5.3349e-04, 9.6919e-04, 1.6540e-05, 9.8031e-01,\n",
              "          1.8005e-03, 5.7129e-04, 8.4008e-03, 5.7181e-03, 3.1172e-04],\n",
              "         [1.8485e-05, 1.6931e-03, 1.6238e-03, 2.5709e-02, 2.9918e-05, 9.3883e-01,\n",
              "          1.6228e-02, 5.0077e-04, 1.3085e-02, 1.8731e-03, 4.0855e-04],\n",
              "         [5.8864e-04, 1.2332e-05, 1.1079e-04, 1.0044e-03, 9.9650e-01, 1.4668e-04,\n",
              "          7.3059e-04, 8.3967e-04, 2.3999e-05, 3.3443e-05, 6.5379e-06],\n",
              "         [7.5753e-05, 2.7338e-05, 4.4156e-04, 4.8841e-03, 9.9148e-01, 2.2492e-04,\n",
              "          8.6667e-04, 1.9635e-03, 1.1971e-05, 1.8920e-05, 9.1723e-06]]),\n",
              " tensor([[ 0.0050,  0.9987, -0.0852,  ...,  0.9898,  0.9306, -0.1805],\n",
              "         [ 0.3252, -0.9999,  0.4221,  ...,  0.9897,  0.9990, -0.2297],\n",
              "         [ 0.3524, -0.9745,  0.7969,  ...,  0.9895,  0.9980, -0.9228],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5KbIKdzXmpD"
      },
      "source": [
        "## 试试 会不会变化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFEPl49aXsXa",
        "outputId": "6ec86630-0f96-4610-e7ee-d8696fac4e5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pairs[1][0]"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'tree house plant window footwear land human wheel car street'"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxEPStKTXpuw",
        "outputId": "90f995cf-81e5-4c57-9f5d-f9c1ac2d8c33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1, pairs[1][0], 11)[2].shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[ 0.0050,  0.9987, -0.0852,  ...,  0.9898,  0.9306, -0.1805],\n",
            "        [ 0.3252, -0.9999,  0.4221,  ...,  0.9897,  0.9990, -0.2297],\n",
            "        [ 0.1463, -0.9943,  0.4196,  ...,  0.9877, -0.9971, -0.2197],\n",
            "        ...,\n",
            "        [-0.1547, -0.8851,  0.3311,  ...,  0.9874,  0.1551,  0.9263],\n",
            "        [-0.9275, -0.8819,  0.1806,  ...,  0.9874, -0.0907,  0.9342],\n",
            "        [-0.9277, -0.8668,  0.1795,  ...,  0.9874, -0.0983,  0.9109]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SprH-Sehlb9v"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        # print(encoder_outputs)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        print('------')\n",
        "        print(encoder_outputs)\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1],encoder_outputs"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blhXZg8mlb9v"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the\n",
        "input, target, and output to make some subjective quality judgements:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdRQBmHlb9w"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4AyX_Tlb9w"
      },
      "source": [
        "Training and Evaluating\n",
        "=======================\n",
        "\n",
        "With all these helper functions in place (it looks like extra work, but\n",
        "it makes it easier to run multiple experiments) we can actually\n",
        "initialize a network and start training.\n",
        "\n",
        "Remember that the input sentences were heavily filtered. For this small\n",
        "dataset we can use relatively small networks of 256 hidden nodes and a\n",
        "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
        "reasonable results.\n",
        "\n",
        ".. Note::\n",
        "   If you run this notebook you can train, interrupt the kernel,\n",
        "   evaluate, and continue training later. Comment out the lines where the\n",
        "   encoder and decoder are initialized and run ``trainIters`` again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3JnedqDJDWy"
      },
      "source": [
        "有了所有这些辅助函数（看起来是额外的工作，但它使运行多个实验更容易），我们实际上可以初始化一个网络并开始训练。\n",
        "请记住，输入的句子经过了严格的过滤。对于这个小数据集，我们可以使用相对较小的网络，即256个隐藏节点和一个GRU层。在MacBook CPU上大约40分钟后，我们会得到一些合理的结果。\n",
        ".. 注意：：如果你运行这个笔记本，你可以训练，中断内核，评估，并在以后继续训练。注释掉初始化编码器和解码器的那几行，然后再次运行trainIters。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDRKomAXnDDz",
        "outputId": "d24ab859-20c2-4546-b3d1-586c5f0baaca"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Aug 31 02:56:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.57.02    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    59W / 149W |    553MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkPY-B1flb9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167246c7-498d-4766-9bbf-b7ce3ea119ed"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "#新建一个函数记录loss"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2m 56s (- 41m 13s) (5000 6%) 4.1979\n",
            "5m 44s (- 37m 22s) (10000 13%) 4.0424\n",
            "8m 35s (- 34m 22s) (15000 20%) 3.9788\n",
            "11m 26s (- 31m 26s) (20000 26%) 3.9525\n",
            "14m 13s (- 28m 26s) (25000 33%) 3.9029\n",
            "17m 1s (- 25m 32s) (30000 40%) 3.8711\n",
            "19m 52s (- 22m 42s) (35000 46%) 3.8624\n",
            "22m 45s (- 19m 54s) (40000 53%) 3.8340\n",
            "25m 30s (- 17m 0s) (45000 60%) 3.8389\n",
            "28m 14s (- 14m 7s) (50000 66%) 3.8135\n",
            "30m 58s (- 11m 15s) (55000 73%) 3.8137\n",
            "33m 45s (- 8m 26s) (60000 80%) 3.8223\n",
            "36m 33s (- 5m 37s) (65000 86%) 3.8177\n",
            "39m 20s (- 2m 48s) (70000 93%) 3.7893\n",
            "42m 5s (- 0m 0s) (75000 100%) 3.7983\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "findfont: Font family ['sans-serif'] not found. Falling back to DejaVu Sans.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSi4NcEefI_6"
      },
      "source": [
        "### 增加词袋token ID 的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfyXa6cXX5gz",
        "outputId": "dc84b027-1b99-431f-a4c3-d174f51c058a"
      },
      "source": [
        "input_lang.n_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "998"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cef8JIVUYXyt",
        "outputId": "eca62644-378e-41a7-924c-02eda1012ae4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1, 'car door plant bicycle tire building', 11)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[-0.1290,  0.0234, -0.0509,  ...,  0.0665,  0.0011,  0.0251],\n",
            "        [ 0.6783,  0.0590, -0.5378,  ...,  0.0638, -0.2623, -0.0951],\n",
            "        [ 0.6648,  0.0593, -0.5385,  ...,  0.0650, -0.9909, -0.0889],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['临街院门',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '住宅小区',\n",
              "  '<EOS>'],\n",
              " tensor([[1.4122e-06, 7.1781e-06, 9.9995e-01, 1.9679e-06, 7.4606e-08, 2.4124e-06,\n",
              "          1.3372e-05, 4.6912e-06, 1.0843e-05, 8.5951e-07, 1.1151e-05],\n",
              "         [5.0838e-04, 2.2239e-03, 5.4248e-04, 1.0634e-03, 1.5943e-05, 9.5561e-01,\n",
              "          6.2073e-03, 1.5947e-03, 2.0496e-02, 1.0746e-02, 9.8985e-04],\n",
              "         [2.4503e-02, 2.9898e-04, 5.0930e-03, 8.4598e-04, 9.5191e-01, 1.9726e-03,\n",
              "          7.9692e-03, 6.1061e-03, 4.4820e-04, 6.3672e-04, 2.1176e-04],\n",
              "         [7.4740e-04, 2.2808e-04, 1.0615e-04, 7.7988e-04, 9.9617e-01, 1.4206e-04,\n",
              "          4.9997e-04, 1.1991e-03, 3.3320e-05, 5.0476e-05, 4.3247e-05],\n",
              "         [1.1871e-04, 1.2530e-05, 1.6649e-04, 3.2380e-04, 9.9894e-01, 3.1084e-05,\n",
              "          3.7201e-05, 3.3795e-04, 6.3165e-06, 9.8722e-06, 1.2194e-05],\n",
              "         [4.2315e-05, 1.1323e-06, 6.5206e-05, 4.2494e-05, 9.9953e-01, 4.3673e-05,\n",
              "          1.6001e-05, 2.3873e-04, 3.7112e-06, 1.0492e-05, 7.1179e-06],\n",
              "         [3.1851e-04, 2.0985e-06, 4.8116e-05, 7.4959e-04, 9.9862e-01, 4.1191e-05,\n",
              "          3.3486e-05, 1.1187e-04, 2.5684e-05, 4.2802e-05, 1.1585e-05],\n",
              "         [2.8022e-05, 1.3059e-06, 7.4903e-05, 1.6550e-04, 9.9953e-01, 9.1862e-05,\n",
              "          1.0808e-05, 8.2756e-05, 5.4794e-06, 6.0132e-06, 1.7694e-06],\n",
              "         [4.6881e-04, 7.4489e-06, 1.4551e-04, 9.5218e-04, 9.9679e-01, 3.9119e-04,\n",
              "          2.8552e-04, 7.8491e-04, 1.0587e-04, 5.3800e-05, 1.5604e-05],\n",
              "         [7.5348e-05, 1.6369e-05, 8.1769e-04, 2.4635e-04, 9.9755e-01, 3.1358e-04,\n",
              "          6.0299e-04, 3.0621e-04, 3.4479e-05, 2.3757e-05, 1.5761e-05],\n",
              "         [2.5426e-05, 2.1031e-05, 2.8379e-04, 1.3629e-03, 9.9716e-01, 8.7312e-05,\n",
              "          4.1048e-04, 5.7797e-04, 3.0931e-05, 1.9434e-05, 2.0703e-05]]),\n",
              " tensor([[-0.1290,  0.0234, -0.0509,  ...,  0.0665,  0.0011,  0.0251],\n",
              "         [ 0.6783,  0.0590, -0.5378,  ...,  0.0638, -0.2623, -0.0951],\n",
              "         [ 0.6648,  0.0593, -0.5385,  ...,  0.0650, -0.9909, -0.0889],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWZaoQHOYkIe",
        "outputId": "4e319a0b-9d77-49f0-fe82-4d1284a41efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "mat=evaluate(encoder1, attn_decoder1, 'car door plant bicycle tire building', 11)[1].numpy()\n",
        "plt.matshow(mat, cmap=plt.cm.Blues)\n",
        "plt.show()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[-0.1290,  0.0234, -0.0509,  ...,  0.0665,  0.0011,  0.0251],\n",
            "        [ 0.6783,  0.0590, -0.5378,  ...,  0.0638, -0.2623, -0.0951],\n",
            "        [ 0.6648,  0.0593, -0.5385,  ...,  0.0650, -0.9909, -0.0889],\n",
            "        ...,\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
            "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7rs35EkZUeM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psf15AAsYEK7",
        "outputId": "23a3310d-0fdb-4307-e512-cfa626b5dff1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluate(encoder1, attn_decoder1, 'window tree house plant building bicycle wheel footwear chair person', 11)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "tensor([[ 0.0790,  0.0236,  0.8653,  ...,  0.0053,  0.8894, -0.8973],\n",
            "        [ 0.0685,  0.9930,  0.8529,  ...,  0.8694,  0.9790, -0.8895],\n",
            "        [ 0.2357, -0.9999,  0.8798,  ...,  0.8694,  0.9998, -0.8848],\n",
            "        ...,\n",
            "        [-0.0557, -0.9592, -0.3965,  ..., -0.9988, -0.9985,  0.9242],\n",
            "        [ 0.1211, -0.9602, -0.3565,  ..., -0.9966, -0.9889,  0.9945],\n",
            "        [ 0.1798, -0.8808, -0.3669,  ..., -0.9962, -0.9889,  0.9877]],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['临街院门', '宿舍', '宿舍', '宿舍', '宿舍', '宿舍', '宿舍', '宿舍', '住宅小区', '住宅小区', '<EOS>'],\n",
              " tensor([[2.2393e-06, 3.2467e-06, 9.9996e-01, 4.8955e-07, 4.6633e-09, 9.6390e-07,\n",
              "          1.6922e-06, 3.1064e-06, 2.7785e-06, 4.2962e-07, 2.5152e-05],\n",
              "         [3.0125e-04, 4.2988e-03, 1.3938e-02, 4.1878e-04, 7.6659e-05, 9.2005e-01,\n",
              "          2.6907e-02, 2.6920e-03, 2.1858e-02, 8.6405e-03, 8.1602e-04],\n",
              "         [1.1196e-06, 9.7818e-01, 3.4284e-03, 3.8725e-05, 7.9162e-05, 6.0511e-03,\n",
              "          4.3512e-03, 5.0000e-03, 1.7401e-03, 8.3514e-04, 2.9310e-04],\n",
              "         [4.9101e-08, 9.8860e-01, 1.0897e-03, 3.1485e-04, 1.0150e-03, 2.0957e-03,\n",
              "          9.9162e-04, 4.7885e-03, 5.5231e-04, 3.9840e-04, 1.5851e-04],\n",
              "         [1.0063e-07, 9.8104e-01, 4.0160e-03, 1.5332e-04, 8.6301e-03, 1.6908e-03,\n",
              "          5.5749e-04, 2.8607e-03, 3.9706e-04, 4.2866e-04, 2.2431e-04],\n",
              "         [1.5419e-07, 9.6955e-01, 1.1856e-02, 1.7590e-03, 7.3301e-03, 6.2769e-03,\n",
              "          2.1016e-04, 2.0344e-03, 4.2108e-04, 4.3242e-04, 1.3028e-04],\n",
              "         [1.9377e-07, 9.1414e-01, 1.4247e-02, 2.0318e-03, 5.9225e-02, 3.7796e-03,\n",
              "          5.2554e-04, 3.9248e-03, 1.0190e-03, 8.3101e-04, 2.7822e-04],\n",
              "         [9.8040e-07, 8.5935e-01, 2.6005e-02, 9.1147e-04, 9.2816e-02, 5.4364e-03,\n",
              "          6.1430e-04, 1.1063e-02, 2.7384e-03, 7.7809e-04, 2.8457e-04],\n",
              "         [2.4451e-06, 9.4225e-01, 2.7160e-02, 5.5512e-04, 4.3714e-03, 1.2836e-02,\n",
              "          1.7056e-03, 5.8280e-03, 3.5758e-03, 1.0231e-03, 6.8862e-04],\n",
              "         [9.9721e-06, 8.0005e-06, 1.6391e-04, 1.9456e-04, 9.9894e-01, 1.6816e-04,\n",
              "          2.8684e-04, 1.6174e-04, 2.1438e-05, 4.1983e-05, 5.1846e-06],\n",
              "         [3.2073e-05, 2.0307e-05, 6.3980e-05, 5.1619e-05, 9.9798e-01, 7.3045e-05,\n",
              "          1.2549e-03, 4.8002e-04, 1.8528e-05, 1.3574e-05, 1.2456e-05]]),\n",
              " tensor([[ 0.0790,  0.0236,  0.8653,  ...,  0.0053,  0.8894, -0.8973],\n",
              "         [ 0.0685,  0.9930,  0.8529,  ...,  0.8694,  0.9790, -0.8895],\n",
              "         [ 0.2357, -0.9999,  0.8798,  ...,  0.8694,  0.9998, -0.8848],\n",
              "         ...,\n",
              "         [-0.0557, -0.9592, -0.3965,  ..., -0.9988, -0.9985,  0.9242],\n",
              "         [ 0.1211, -0.9602, -0.3565,  ..., -0.9966, -0.9889,  0.9945],\n",
              "         [ 0.1798, -0.8808, -0.3669,  ..., -0.9962, -0.9889,  0.9877]],\n",
              "        device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cApMGg_Wlb9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab3024c8-f916-46b0-9694-36d23fc15acb"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> window tree house plant building bicycle wheel footwear chair person\n",
            "= 宿舍 建筑物门 宿舍 建筑物门 建筑物门 建筑物门 建筑物门 宿舍 中国银行atm 中国工商银行atm\n",
            "< 临街院门 宿舍 宿舍 宿舍 宿舍 宿舍 宿舍 宿舍 住宅小区 住宅小区 <EOS>\n",
            "\n",
            "> tree car wheel street flower bus footwear train person man\n",
            "= 公共厕所 公交车站相关 美容美发店 摄影冲印 展览馆 风景名胜 风景名胜 风景名胜 风景名胜 住宅小区\n",
            "< 公共停车场 公共停车场 公共停车场 公共停车场 风景名胜 风景名胜 风景名胜 风景名胜 风景名胜 风景名胜 <EOS>\n",
            "\n",
            "> tree house window wheel car door plant bicycle tire building\n",
            "= 临街院门 临街院门 临街院门 汽车养护 汽车维修 公司 物流速递 车辆管理机构 工厂 生活服务场所\n",
            "< 临街院门 风景名胜 生活服务场所 临街院门 临街院门 生活服务场所 生活服务场所 住宅小区 住宅小区 住宅小区 <EOS>\n",
            "\n",
            "> tree window plant skyscraper billboard building house\n",
            "= 住宅小区 停车场出入口 住宅小区 专用停车场 专用停车场 停车场入口 汽车服务相关 汽车养护 汽车服务相关 美容美发店\n",
            "< 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 <EOS>\n",
            "\n",
            "> tree window car building wheel person boat skyscraper land house\n",
            "= 银行 自动提款机 中餐厅 生活服务场所 物流速递 生活服务场所 中餐厅 餐饮相关 咖啡厅 临街院门\n",
            "< 临街院门 临街院门 美容美发店 临街院门 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 <EOS>\n",
            "\n",
            "> tree window car building wheel train boat house vehicle tire\n",
            "= 生活服务场所 中学 培训机构 公共停车场 临街院门 美容美发店 培训机构 农村商业银行atm 农村商业银行 生活服务场所\n",
            "< 临街院门 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 生活服务场所 <EOS>\n",
            "\n",
            "> tree window house plant car building wheel person motorcycle\n",
            "= 公交车站相关 临街院正门 小学 小学 科教文化场所 公交车站相关 临街院正门 中学 快餐厅 健身中心\n",
            "< 临街院门 住宅小区 住宅小区 临街院门 临街院门 临街院门 住宅小区 住宅小区 住宅小区 住宅小区 <EOS>\n",
            "\n",
            "> tree street wheel car truck land window vehicle van tire\n",
            "= 立交桥 休闲场所 风景名胜 商务住宅相关 公共停车场 汽车服务相关 洗浴推拿场所 驾校 洗浴推拿场所 驾校\n",
            "< 交通服务相关 交通服务相关 交通服务相关 风景名胜 风景名胜 风景名胜 风景名胜 风景名胜 住宅小区 住宅小区 <EOS>\n",
            "\n",
            "> tree window building car skyscraper wheel house street person footwear\n",
            "= 公安警察 停车场出口 交通服务相关 公共停车场 糕饼店 ktv 药房 中餐厅 洗浴推拿场所 汽车养护\n",
            "< 临街院门 临街院门 临街院门 临街院门 临街院门 美容美发店 美容美发店 生活服务场所 生活服务场所 中餐厅 <EOS>\n",
            "\n",
            "> window tree plant car house wheel building skyscraper vehicle\n",
            "= 幼儿园 楼栋号 住宅小区 公共停车场 住宅小区 生活服务场所 住宅小区 生活服务场所 物流速递 公共停车场\n",
            "< 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 住宅小区 <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26eQXeUflb9x"
      },
      "source": [
        "Visualizing Attention\n",
        "---------------------\n",
        "\n",
        "A useful property of the attention mechanism is its highly interpretable\n",
        "outputs. Because it is used to weight specific encoder outputs of the\n",
        "input sequence, we can imagine looking where the network is focused most\n",
        "at each time step.\n",
        "\n",
        "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
        "displayed as a matrix, with the columns being input steps and rows being\n",
        "output steps:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVZLqBJA1U_8"
      },
      "source": [
        "torch.save(encoder1, '/content/drive/MyDrive/encoder1')\n",
        "torch.save(attn_decoder1, '/content/drive/MyDrive/attn_decoder1')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0F9iNebuP8c"
      },
      "source": [
        "明天测试 输出中间结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GB-xgAk1j3z"
      },
      "source": [
        "encoder1 = torch.load('/content/encoder1')\n",
        "attn_decoder1 = torch.load('/content/attn_decoder1')\n",
        "# model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbRVAmonmGvx",
        "outputId": "74323cc4-508c-4545-c1ea-a51c5ae58ee3"
      },
      "source": [
        "len(output_words)\n",
        "output_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['linjieyuanmen',\n",
              " 'linjieyuanmen',\n",
              " 'linjieyuanmen',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " '<EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIMJxSeFWG4q",
        "outputId": "ee198af0-325f-4b1a-add4-b7980f4f3266",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tree plant house window car land street billboard tire',\n",
              " '公交车站相关 美容美发店 快餐厅 工厂 维修站点 中餐厅 摩托车维修 清真菜馆 美容美发店 美容美发店']"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9RIw6f4lb9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "a995d0ed-e732-4378-aaf7-fa6521a71936"
      },
      "source": [
        "%matplotlib inline\n",
        "MAX_LENGTH=10\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1,pairs[0][0])\n",
        "\n",
        "plt.matshow(attentions.numpy())\n",
        "# plt.show()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f0f8eef15d0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWTSrqQikk3l",
        "outputId": "e3c3ba7e-78cb-4d54-c4a6-9f1ad942c88d"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree',\n",
              " 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw8gOHsqlb9y"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes\n",
        "and labels:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alLDfnQHlYti"
      },
      "source": [
        "# attentions.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3nejK_blb9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 932
        },
        "outputId": "7957e3d0-f7f0-418b-c937-09ed7b383a60"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "    print(attentions.shape)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(pairs[0][0])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = tree plant house window car land street billboard tire\n",
            "output = 临街院门 住宅小区 临街院门 临街院门 临街院门 临街院门 住宅小区 住宅小区 住宅小区 住宅小区 <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20020 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 34903 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38498 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20303 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23429 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21306 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20020 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 34903 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38498 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20303 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23429 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21306 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "et0fsLa5lKQn",
        "outputId": "b5dd1fa4-a3ac-4d5b-9479-de260e811b99"
      },
      "source": [
        "evaluateAndShowAttention('car tree tree car tree land vehicle truck house')\n"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input = car tree tree car tree land vehicle truck house\n",
            "output = 公交车站相关 公交车站相关 公交车站相关 临街院门 临街院门 临街院门 临街院门 临街院门 住宅小区 住宅小区 <EOS>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20844 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 36710 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 31449 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 30456 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20851 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20020 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 34903 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38498 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 38376 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 20303 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23429 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 21306 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20844 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20132 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 36710 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 31449 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 30456 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20851 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20020 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 34903 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38498 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 38376 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 20303 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23429 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 23567 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 21306 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEXCAYAAADRBe2iAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAY70lEQVR4nO3de7RkZX3m8e9zuhu5tSA2jpFGRAMZYSQiLU6CGdSAqzVcnDAqiFGM2saoKxevycwiSmKMRpNRF0xAglGHhKBjtLNCAkMQWShqnxZFu5WEgSiNjNCAKAzSl/PMH3sX7FN9zqnbrqpdp57PWrWovWvX77y7Of3r97bfV7aJiIhHzYy7ABERTZPEGBHRJokxIqJNEmNERJskxoiINkmMERFtkhgjItokMUZEtElijIhok8QYE0/SPpJ+btzlGBUVPifp6eMuy3KVxBgTTdKpwDeAfyqPnylp43hLNXQvBJ4NvG7cBVmukhhj0r0bOB74EYDtbwCHj7NAI/BaiqR4qqSV4y7McpTEGJNup+37284t25VRJK0Bjrb9j8DVwEvGXKRlKYkxJt0WSa8AVkg6QtJHgS+Pu1BD9GvA35TvP06a00ORxBiT7i3A0cDDFAnjx8Bvj7VEw/XrFAkR25uAn5F06HiLtPwo6zFGDI8kAWcDT7V9nqQnA0+0/bU+Yh0IvNz2hZVzJwPbbd9YW6EjiTEmk6S/Z4m+RNunjbA4i5L0P4A54AW2ny7pccBVtp895qLFEjKiFZPqg+MuQJeeY/tZkm4EsH2fpL16DSLp9cC1tv+1rIVeApwB/Bvw6tQY65XEGBPJ9hcBJO0HPGR7rjxeATxmnGVrs7MskwEkHUxRg+zVbwF/Vb4/CziGYlrSscBHgF8auKTxiAy+xKT7Z2DfyvE+FNNYeiZpj/mPkgZt8n4E+DvgCZLeC1wP/HEfcXbZ3lm+PwX4pO17bF8N7DdgGaNNEmNMur1tP9A6KN/vu8T1S/lfkg5pHUg6kaLJ2jfblwLvAN4H3Am8xPan+wg1J+lnJO0N/DLzk/8+g5Qx9pTEGJPuQUnPah1IOg54qM9YbwA+J+mJkl5MUdt78SCFk/Q04Dbb5wPfBk4uR5d7dS4wS9GnuNH2ljL+icCtg5Qx9pRR6ZhoZVP3MuAHgIAnUkxp2dxnvF8ALgR+CvyK7bsHLN83gHXAU4B/ADZSPLnSc8ItH/9bbfu+yrn9KP4eP7D4N6NXSYwx8SStAlqr69xc6Yvr9vvtU3+Oomj23geDTf2R9PVyVPodFINEH5V0o+1j+4j1BOBNFBPaAbYAF9j+Yb/li4VlVDpGRtK3WHru4TE9xHqB7Wsk/WrbR0dKwvZneyjaMKf+7JR0FvAq4NTy3Kpeg0g6AfhripHpT5anjwO+Kuls21+qoaxRSmLsk6TnAkfY/ng5BWN/27c1JV6daizbKeV/31T+91Plf8/uI9aJwDU8mmyqDHSdGCtTfw4H7rT90/J4H+Df9VG2qtcAvwG81/Zt5c/4VIfvLORDFAM31fmKGyX9HUXT/zkDljMq0pTug6Q/oOg3+jnbR0p6EvBp2yc0IV6dhlG2hZqSrSbngMUdiKRZ4Bdt7yiP9wK+1ISnVCRttX1Ur59Ff1Jj7M9/pphY+3UA2z+QtLpB8eo0jLJJ0gmt5p+kX6TPGRKSHkPxBMhTqPw+2z6vj3ArW0mxjLGjn6dU2sp3Gwt0H9h+au+h9LjqwEt58iAyu6R2SYz92WHbklpPMww6wbbueHUaRtleC1wi6QCKkeT7KFaN6cfngfuBzRQr7Azibkmn2d4IIOl0YPuAMddV3u8NvBQ4qI84fw5cJeltlP9IUfQxvr/8LOpke1m/gBXApTXHfBtFv86twOuBG4C3NCFe3fdb9722xT4AOGDAGN+u8V6fBnwF+D5wO8W6jj9b5+9O+XM29/m9U4DrgHsoEvZ1wKl1ly8vT0cfo6TrKVY32dHx4u5jnkyx94aAK23/76bEq/t+h3CvtTV/JV0EfNT2twYpU1vM/cvyDDw3sDr5nKLJuw54o+2fHzR2DM+0NKVvBb5UbpL0YOuk7T8bIOa/FCF8taR9Ja22/ZOGxKv7fuu+14Gbv5WpPyuB10i6tYylsqxdT/2pxDy37Rjou7+y5UOV97sonlx5WR9lu9z2y8r377f9zspnV9l+4QBljDbTkhj/T/maAQYe1CiXgNpA0Vf0NOAQ4C8onmEdezxqvN8hlA1gre31g5SLR6f+1OnByvu9y5/xnUEC2n7+QCV61BGV9ycD76wcH1zTz4jSVCRG2++pOeSbKHam+2oZ/1/LpxIaEa/m+637XgG+LOkZgzR/bX+v9X6heZZ9xqzW7pD0QeDKfstYxjgA+APgP5Wnvgic5z038OpYvD4/iz5MRWIs/7K8g+JRqr1b522/oM+QD7uYytGKv5LBfjlrjVfz/dZ9rwDPBc4pp7IM2vx9ZJ4lxV4oq4D/CdQxB3RfYO2AMS6hWDyi1Xz+NYpytj+x07Esko6laAXsU75X+crqOjWbisQIXAr8LUXT6DeAVwODLA7wRUm/T/ELejLwm8DfNyhenfdbd9kAXjTg96tqm2fZ9sjiCoom6iD9iwBPs31G5fg95cISvboTaPUR/9/K+9Zx1GhaRqU32z5O0k2tWomkTe7ziQYV1afXURmpBS52n3+YQ4hX2/3WXba22E9gfo32+33E+Jrt4/XoYg37ATf0Wfs8rHK4C/ih7V29xmmLeQPwdtvXl8cnAB+0/QuDxI3hmpYaY2u1lTsl/QrFElX9TLJtLZ2/xfa/Bz42aMHqjleq5X6HVDYknUYxWvsk4C7gMIpBjqOX+t4iLpd0IXBgOVD06/2UtbzXK8t7rdMbgU+UfY1QTGZ/dT+Byme3j7T9zcq5JwO7bd8xcEnjEdOSGP+o/MV8K/BR4LH0ufew7d2Sbpb05H5qOMOOV6rlfodUNoA/BP4jcLXtYyU9H3hln7FMsV3Aj4EjgXP7mWc5xHv9DvABihH9AymmKb0EuKmPWLuAz0o6xnZrBP1i4PeBJMYaTUtifClwve1vA88vny/9IP33lT0O2CLpa8yfJ9jvun11x6vzfusuG8BO2/dImpE0Y/sLkv57n7H2p6gl3kvRr9pPwmkZxr1+HvgRRR/oQMnL9k4Vq+m8DPh4WVs82PbsIHFjT9OSGI+x/aPWge17y1G9frXmuLWI4pnVpsSr837rLhvAj8qnS64DLpV0F/PnEHatnJr0HknHAC+nGCzaZvukPsIN417rmLNZdTFwEcXI9qvK/0bNpiUxzqiyMklZgxrk3le6XMOvpez/aUq8Ou+37rIBnE6xdcDvUKzFeACDj/7eRTE6ew/Q7zzLYdzrwHM2q2x/V4UjgTPJtqlDMS2J8UPADZJau7O9FHhvr0EkvZFiuspTJVWbbKuBnldQrjtexcD3O8SyUekfA/jEILEk/SZF0/Jg4NPA621v7TFG7feqITyyWPGXFDXHb7ltGbKox1RM1wGQdBTQmuB8Ta9/ecoYB1D0Q70PeFflo5/Yvnfc8dpiD3S/wyibpJ+w8OTwVrJ4bB8x3wf8re1+5ga2YgzjXg9b6vPqkzt9xN6XYl7jGS72lY6aTU1ijIjoVlb+jYhok8QYEdFmKhOjpA1NjdfksjU9XpPLNo3xJtlUJkaK9QWbGq/JZWt6vCaXbRrjTaxpTYwREYtaVqPSKneya6rjjjuu4zV33303Bx/ceUHmzZs311GkiJ7Z1iDfX79+vbdv727zxc2bN19Z85NDXZmWCd6NMDtb3yOt0kC/mxFjs337djZt2tTVtTMzM2uGXJwFJTFGxMjNNbylmsQYESNloOldeEmMETFixg3fvyuJMSJGy7B7LokxIuIRJn2MERF7mPg+Rknvptifo7Vb2krgK4ucY5jnbb+78y1FRNNNfGIsndlaKl/SgRQbKy10brFr6zwfERPMdprSw1Y++J5nPCMmyHKpMTaW7YsoNgdq/COBEVEMvuxOYoyImC81xoiINuljjIioslNjjIioWi7PSt8FfFLSXHk8A/zTIucYwfmImHC75+Y6XzRGWah2hOr8s856jDEugy5U+/PHPtNXXHNNV9euPejxm22vG+Tn9SNN6YgYKRsavobEckyMza1J1VnLu/eBB2qLBXDQ/qtrjbdq1V61xtu58+Fa48V4Nb2lugwTY0Q0XRJjRERFlh2LiGhnN35UOokxIkYuTemIiApD9nyJiGiX6ToREW0mvimdrQ0iom4TnxhL2dogImrhjEpHROxpudQYGyt7vkRMlkzwHoHs+RIxeTJdJyKiTabrRERU2GYugy8REfMthz7GbG0QEbWa+FFp2xcAFyzw0ULnRnE+IibcxCfGiIg62V4WTemIiFplus7INfsPvC4H7LtvzRHr/XPLHi2xGAO7a5yvI2k98GFgBXCx7T9p+/zJwCeAA8tr3mX7iqViztRWuoiILtnu6tWJpBXA+cCLgKOAsyQd1XbZfwMut30scCZdjF8kMUbEyM2V/YydXl04HrjF9q22dwCXAae3XWPgseX7A4AfdAq6DJvSEdFoXdYGu3QIcHvleBvwnLZr3g1cJektwH7ASZ2CpsYYESNlempKr5E0W3n1s2DMWcBf2V4LvBj4lKQlc19qjBExcj1M19lue90Sn98BHFo5Xlueq3otsB7A9g2S9gbWUDy8sqDUGCNi5GrsY9wEHCHpcEl7UQyubGy75vvALwNIejqwN3D3UkFTY4yIkapzPUbbuyS9GbiSYirOJba3SDoPmLW9EXgr8DFJv1P++HPcoZMze75ExGjVO/hCOSfxirZz51bebwVO6CVm9nyJiJHLI4FDlq0NIiZLa1S6ySY+MWZrg4jJk10CIyLmcRaRiIiosotXkyUxRsTIZfAlIqLNchh8yZ4vEVGbOid4D0v2fImI0cr2qRERC5j0GmM004w07iJE9M01bm0wDEmMETFyDa8wJjFGxGgV8xibnRmTGCNi5JIYIyLmMXO7MyodEfGINKUjIhaQxBgR0S6JMSJivobnxfoT4zD3iMmeLxHLgKd38GWYe8RExATL1gYjkD1fIiZPEuOQZc+XiMmTxBgRUWVDFpGIiJgvNcaIiAoDc6kxRkRUTOkjgcPeIyYiJtzULVQ7gj1iImKieSprjBERS0pinGh176tS3y+DNFNbrGG478EHa4130P6ra41Xt3r/otedNOr8PR68bFl2LCJiAd6dxBgRMU9qjBERVc7gS0TEHpqeGJvdgx8Ry05r2bFuXt2QtF7SzZJukfSuRa55maStkrZI+utOMVNjjIjRMrimhWolrQDOB04GtgGbJG20vbVyzRHA7wEn2L5P0hM6xU2NMSJGrLvaYpc1xuOBW2zfansHcBlwets1rwfOt30fgO27OgVNYoyIkSvmMnZ+deEQ4PbK8bbyXNWRwJGSviTpK5LWdwqaPV8iYuR6GHxZI2m2cnxRuTh1L1YCRwDPA9YC10l6RmvrlMW+MAzZ8yUiFmT3tIjEdtvrlvj8DuDQyvHa8lzVNuCrtncCt0n6F4pEuWmxoBPflJa0QdJs278qEdFgNfYxbgKOkHS4pL2AM4GNbdd8jqK2iKQ1FE3rW5cKOvGj0tnzJWLSmLm5ekalbe+S9GbgSmAFcIntLZLOA2Ztbyw/e6GkrcBu4O2271kq7sQnxoiYMDUvImH7CuCKtnPnVt4b+N3y1ZUkxogYvWlbqDYiYinFky/jLsXSkhgjYuSa/qx09nyJiNGymavpkcBhyZ4vETFy01hjjIhYVGt1nSZLYpxQUr370dT9i/rTnTtrjVe3uu935cpVtcXavXtX54t60LgkNAGjL0mMETFiWcE7ImIPbvbYSxJjRIyYqe2RwGFJYoyIkcrgS0TEApIYIyLmcS/rMY5FEmNEjFbNq+sMQ7Y2iIjRm7bEWMrWBhGxIANzaUpHRFT0tufLWEx8YpS0Adgw7nJERLfy5MvQZc+XiMmTxBgR0SaJMSKiwgZP20K1ERGdNLzCmK0NImLUpnDwJVsbREQnU5cYIyKWNI2PBEZELMVkgveEq/d/njRTW6xVq/aqLRbAjh0/rTXeitr3pGn2KGad+7Q0/V4HZ5yFaiMiKtKUjojYU8PzYhJjRIxe+hgjIiqy50tERLv0MUZEtHO2T42IaDd1fYzZ8yUillR0MtYWTtJ64MPACuBi23+yyHVnAJ8Bnm17dqmY2fMlIkaqzrwoaQVwPnAysA3YJGmj7a1t160Gfgv4ajdx63sUY0wkbZA0K2nJfwEiojlsd/XqwvHALbZvtb0DuAw4fYHr/hB4P9DVI14TnxhtX2R7ne114y5LRHTBZm73XFevLhwC3F453laee4SkZwGH2v6HbouYwZeIGLkepuusaWsNXlTu89QVFQsU/BlwTvelS2KMiBHrcYL39g6twTuAQyvHa8tzLauB/wBcq2JhkycCGyWdttQATBJjRIxcjRO8NwFHSDqcIiGeCbyi8nPuB9a0jiVdC7yt06j0xPcxRsSkcbkjVhevTpHsXcCbgSuB7wCX294i6TxJp/Vbwuz5EhGjZahzyUnbVwBXtJ07d5Frn9dNzOz5EhEjl0cCIyIqsrpORES7rK4TVXXu5VH3Hi11O2j//cddhJFa/vu01MnTt4hERERHqTFGRMznmnfgrFsSY0SMlG3m5naPuxhLSmKMiJHL4EtERJskxoiINkmMEREVxSK0zZ7elD1fImLkpi4xlrLnS0QsKk3pIZO0Adgw7nJERPeSGIesXOb8IgBJzf7TjghgCvsYIyKW4iwiERGxpyTGiIh5jLNQbUTEfGb6EmP2fImIJU1dUzp7vkTEUjL4EhGxBycxRkS0y3qMMSSqOV69/4Lv2LWr80U9afb91lu+Ztem6pAaY0REVdHJOO5SLCmJMSJGymTPl4iIPeRZ6YiIeTIqHRGxh7k8EhgR8ahi7CWJMSKiYgqb0tnzJSI6mrbEWMqeLxGxqEzXGbLs+RIxeaauKT1q2fMlYrLYbvyz0jPjLkBETB/bXb26IWm9pJsl3SLpXQt8/ruStkq6SdI/SzqsU8wkxogYuboSo6QVwPnAi4CjgLMkHdV22Y3AOtvHAJ8BPtApbhJjRIxcjTXG44FbbN9qewdwGXB628/6gu3/Vx5+BVjbKWgSY0SMmMFz3b06OwS4vXK8rTy3mNcC/9gpaPZ8iYiRsmGu+ydf1kiarRxfVA649kzSK4F1wImdrs2eLxExcj1M19lue90Sn98BHFo5Xluem0fSScB/BU60/XCnHzrx03UiYtK4zmelNwFHSDqcIiGeCbyieoGkY4ELgfW27+omaBLjxKp3yubumlc7WTEzbd3XmULbi7omeNveJenNwJXACuAS21sknQfM2t4I/CmwP/BpSQDft33aUnGTGCNi5Op88sX2FcAVbefOrbw/qdeYSYwRMVLZVzoiYg/GbvYjgUmMETFyqTFGRLRJYoyImGcKV/COiFhK9nyJiFjA1NUYs+dLRCzNeEq3T82eLxGxqOz5MmTZ8yVi8qSPcciy50vEZMmTLxERe8h0nYiIPcxN6eBLRMSi0scYEVFVdDKOuxRLyp4vETFSpvnTddT0TtBeZFS6f1nBO7plW4N8f9Wqx/jxj39SV9f+8If/trnDni9DkaZ0RIxc+hgjIuZxRqUjIqoywTsiYgFJjBER8xjSxxgRMV/Tp+skMUbEyKUpHRFRYZu5uWZvnzrwLFxJ10q6WdI3ytdnKp9tkPTd8vU1Sc+tfHaKpBslfVPSVklvGLQsETEZbHf1Gpe+aoyS9gJW2X6wPHW27dm2a04B3gA81/Z2Sc8CPifpeOAeijUUj7e9TdJjgKeU33uc7fv6u52ImARNb0r3VGOU9HRJHwJuBo7scPk7gbfb3g5g++vAJ4A3AaspkvI95WcP2765/N7LJX1b0lslHdxL+SJiMjS9xtgxMUraT9JrJF0PfAzYChxj+8bKZZdWmtJ/Wp47GtjcFm4WONr2vcBG4HuS/kbS2ZJmAGz/BfAiYF/gOkmfkbS+9fkC5dsgaVbS7EKfR0QDtVbY6fQak46LSEj6MXAT8Drb313g82uBty3QlL4XONz2/ZVzpwOvtv2r5fEzgJOAVwHftH1OWwxRJMmLgVnbp3Uoa7Pr5w2WRSSiW4MuIjEzs8J7771vV9c+9NADY1lEopvf3v8C3AF8VtK5kg7rMvZW4Li2c8cBW1oHtr9l+8+Bk4EzqheWfZEXAB8BLgd+r8ufGxENN/FNadtX2X458EvA/cDnJV0t6SkdvvoB4P2SHg8g6ZnAOcAFkvaX9LzKtc8Evlde90JJNwF/BHwBOMr2b9veQkQsC01PjF2PStu+B/gw8OGyNlediHSppIfK99ttn2R7o6RDgC+XTdyfAK+0faek1cA7JF0IPAQ8SJE0oRiQOdX29wa6s4hoqOZvhpWFagNIH2N0b/A+xhmvXLlXV9fu3PlwFqqNiOUvy45FROzBWcE7IqJdEmNERJs0pUdrO+W0nw7WlNfWpc54YylbD4Ml+bOb7njdzmNeypW213R5bZ3317VlNSrdLUmzdY501RmvyWVrerwml20a402yzKmIiGiTxBgR0WZaE+NFDY7X5LI1PV6TyzaN8SbWVPYxRkQsZVprjBERi0pijIhok8QYEdEmiTEiok0SY0REm/8P4r4W9MKtuyIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_7QOcvlb9y"
      },
      "source": [
        "Exercises\n",
        "=========\n",
        "\n",
        "-  Try with a different dataset\n",
        "\n",
        "   -  Another language pair\n",
        "   -  Human → Machine (e.g. IOT commands)\n",
        "   -  Chat → Response\n",
        "   -  Question → Answer\n",
        "\n",
        "-  Replace the embeddings with pre-trained word embeddings such as word2vec or\n",
        "   GloVe\n",
        "-  Try with more layers, more hidden units, and more sentences. Compare\n",
        "   the training time and results.\n",
        "-  If you use a translation file where pairs have two of the same phrase\n",
        "   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n",
        "   this:\n",
        "\n",
        "   -  Train as an autoencoder\n",
        "   -  Save only the Encoder network\n",
        "   -  Train a new Decoder for translation from there\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtVB34UC1Exk"
      },
      "source": [
        "尝试使用其他数据集\n",
        "另一对语言\n",
        "人类→ 机器（如物联网命令）\n",
        "聊天→ 回应\n",
        "问题:→ 答复\n",
        "用预先训练过的单词嵌入替换嵌入，如word2vec或GloVe\n",
        "尝试使用更多的层次、更多的隐藏单位和更多的句子。比较训练时间和结果。\n",
        "如果使用一个翻译文件，其中对具有两个相同短语（I am test\\t I am test），则可以将其用作自动编码器。试试这个：\n",
        "作为自动编码器训练\n",
        "仅保存编码器网络\n",
        "从那里训练一个新的译码器进行翻译"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scADqDy2fiT5"
      },
      "source": [
        "最后一部分我们来进行精度验证 基于rouge的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5s6KhzCfwJG"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import keras \n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "text = [' '.join(catetypes)]\n",
        "tokenizer.fit_on_texts(text)\n",
        "\n",
        "keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([\"下 雨 我 加班\"]), maxlen=2,padding='post',truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uGlJQMqti5N"
      },
      "source": [
        "types=['中国人民银行',\n",
        " '加油站',\n",
        " '教堂',\n",
        " '奇瑞维修',\n",
        " '洗浴推拿场所',\n",
        " '商业贸易',\n",
        " '加水站',\n",
        " '赛马场',\n",
        " '殡仪馆',\n",
        " '现代维修',\n",
        " '中国移动营业厅',\n",
        " '旧货市场',\n",
        " '兴业银行ATM',\n",
        " '湖泊',\n",
        " '住宅区',\n",
        " '玛莎拉蒂维修',\n",
        " '消费者协会',\n",
        " '德国菜',\n",
        " '特色/地方风味餐厅',\n",
        " '认证事务所',\n",
        " '大家乐',\n",
        " '出租车',\n",
        " '国家级机关及事业单位',\n",
        " '特殊买卖场所',\n",
        " '普通商场',\n",
        " '东风标致维修',\n",
        " '一汽大众销售',\n",
        " '汽车俱乐部',\n",
        " '证券公司',\n",
        " '福建菜',\n",
        " '卫生院',\n",
        " '东风悦达起亚维修',\n",
        " '麦德龙',\n",
        " '广告装饰',\n",
        " '吉利销售',\n",
        " '英菲尼迪销售',\n",
        " '地税机关',\n",
        " '进口现代维修',\n",
        " '苏宁',\n",
        " '城市广场',\n",
        " '福田卡车维修',\n",
        " '出入口',\n",
        " '邮政速递',\n",
        " '社区中心',\n",
        " '国美',\n",
        " '林肯维修',\n",
        " '兽医站',\n",
        " '临街院门',\n",
        " '中国建设银行',\n",
        " '桥',\n",
        " '公园广场',\n",
        " '妇科医院',\n",
        " '阿迪达斯专卖店',\n",
        " '一汽丰田销售',\n",
        " '传染病医院',\n",
        " '吉利维修',\n",
        " '迪厅',\n",
        " '本田讴歌维修',\n",
        " '游泳馆',\n",
        " '糕饼店',\n",
        " '屈臣氏',\n",
        " '湖北菜(鄂菜)',\n",
        " '溜冰场',\n",
        " '公安警察',\n",
        " '宠物诊所',\n",
        " '山',\n",
        " '中国农业银行ATM',\n",
        " '一汽大众奥迪销售',\n",
        " '牛扒店(扒房)',\n",
        " '进口大众维修',\n",
        " '其它个人用品店',\n",
        " '交通车辆管理相关',\n",
        " '中国银行ATM',\n",
        " '台球厅',\n",
        " '家电电子卖场',\n",
        " '华夏银行ATM',\n",
        " '候车室',\n",
        " '广汽本田维修',\n",
        " '渔场',\n",
        " '马术俱乐部',\n",
        " '农副产品市场',\n",
        " '河流',\n",
        " '科研机构',\n",
        " '律师事务所',\n",
        " '乡镇以下级政府及事业单位',\n",
        " '广汽本田销售',\n",
        " '建筑物正门',\n",
        " '产业园区',\n",
        " '福田卡车销售',\n",
        " '中国工商银行ATM',\n",
        " '巴西菜',\n",
        " '沃尔沃维修',\n",
        " '站台',\n",
        " '公交车站相关',\n",
        " '充电站',\n",
        " '雷诺销售',\n",
        " '图书馆',\n",
        " '汽车销售',\n",
        " '候机室',\n",
        " '宝马维修',\n",
        " '公检法机关',\n",
        " '东风雪铁龙维修',\n",
        " '出站口',\n",
        " '羽毛球场',\n",
        " '档案馆',\n",
        " '三级甲等医院',\n",
        " '专科医院',\n",
        " '休闲场所',\n",
        " '综合市场',\n",
        " '中国电信营业厅',\n",
        " '新华人寿保险公司',\n",
        " '运动场所',\n",
        " '街道级地名',\n",
        " '货车销售',\n",
        " '广汽丰田销售',\n",
        " '文化用品店',\n",
        " '渣打银行ATM',\n",
        " '公共厕所',\n",
        " '品牌皮具店',\n",
        " '中信银行',\n",
        " '快餐厅',\n",
        " '郑州日产销售',\n",
        " '会计师事务所',\n",
        " '泰国/越南菜品餐厅',\n",
        " '天文馆',\n",
        " '一汽-大众奥迪销售',\n",
        " '东风本田维修',\n",
        " '家具建材综合市场',\n",
        " '体育休闲服务场所',\n",
        " '高等院校',\n",
        " '电视台',\n",
        " '地市级地名',\n",
        " '江淮维修',\n",
        " '城市快速路出口',\n",
        " '花鸟鱼虫市场',\n",
        " '彩票彩券销售点',\n",
        " '泰康人寿保险公司',\n",
        " '人渡口',\n",
        " '商务住宅',\n",
        " '东风销售',\n",
        " '公墓',\n",
        " '中国光大银行',\n",
        " '精神病医院',\n",
        " '甜品店',\n",
        " '道路附属设施',\n",
        " '交通管理机构',\n",
        " '维修站点',\n",
        " '报刊亭',\n",
        " '采摘园',\n",
        " '花卉市场',\n",
        " '学校',\n",
        " '工业大厦建筑物',\n",
        " '呷哺呷哺',\n",
        " '梅赛德斯-奔驰销售',\n",
        " '户外用品',\n",
        " '高速加油站服务区',\n",
        " '雪铁龙销售',\n",
        " '露营地',\n",
        " '一汽解放销售',\n",
        " '马自达维修',\n",
        " '上海大众销售',\n",
        " '凯迪拉克维修',\n",
        " '生活服务',\n",
        " '肯德基',\n",
        " '林场',\n",
        " '外地政府办',\n",
        " '外国机构相关',\n",
        " '网络科技',\n",
        " '摩托车销售',\n",
        " '科技馆',\n",
        " '药房',\n",
        " '招商银行ATM',\n",
        " 'DS维修',\n",
        " '沃尔沃销售',\n",
        " '小学',\n",
        " '名爵销售',\n",
        " '医药保健相关',\n",
        " '杂志社',\n",
        " '公用电话',\n",
        " '中国进出口银行',\n",
        " '法国兴业银行',\n",
        " '马自达销售',\n",
        " '华夏银行',\n",
        " '日本料理',\n",
        " '陵园',\n",
        " '吉普维修',\n",
        " '综合体育馆',\n",
        " '专用停车场',\n",
        " '火车站',\n",
        " '疾病预防',\n",
        " '岛屿',\n",
        " '综合家电商场',\n",
        " '公交卡/月票代售点',\n",
        " '中国邮政储蓄银行ATM',\n",
        " '保龄球馆',\n",
        " '长途汽车票代售点',\n",
        " '雷克萨斯销售',\n",
        " '外国使领馆',\n",
        " '货运火车站',\n",
        " '传媒机构',\n",
        " '中介机构',\n",
        " '体育休闲服务',\n",
        " '麦当劳',\n",
        " '学校内部设施',\n",
        " '上海浦东发展银行ATM',\n",
        " '云贵菜',\n",
        " '妇联',\n",
        " '雪佛兰销售',\n",
        " '停车场出入口',\n",
        " '雷诺维修',\n",
        " '雷克萨斯维修',\n",
        " '医疗保健服务',\n",
        " '进口大众销售',\n",
        " '收费站',\n",
        " '电力营业厅',\n",
        " '机场相关',\n",
        " '果品市场',\n",
        " '楼宇相关',\n",
        " '中式素菜馆',\n",
        " '福特维修',\n",
        " '观致销售',\n",
        " '保险公司',\n",
        " '道路名',\n",
        " '中国人民保险公司',\n",
        " '违章停车',\n",
        " '珠宝首饰工艺品',\n",
        " '海鲜酒楼',\n",
        " '中国农业银行',\n",
        " '博物馆',\n",
        " '壁球场',\n",
        " '法拉利维修',\n",
        " '住宿服务',\n",
        " '宝马销售',\n",
        " '中国太平洋保险',\n",
        " '动物园',\n",
        " '礼品饰品店',\n",
        " '斯巴鲁维修',\n",
        " '别克维修',\n",
        " '诊所',\n",
        " '慈善机构',\n",
        " '斯巴鲁销售',\n",
        " '酒吧',\n",
        " '青年旅舍',\n",
        " '小商品市场',\n",
        " '工商部门',\n",
        " '退票',\n",
        " '国家级景点',\n",
        " '停车场入口',\n",
        " '棋牌室',\n",
        " '耳鼻喉医院',\n",
        " '眼镜店',\n",
        " '购物服务',\n",
        " '交通银行',\n",
        " '女洗手间',\n",
        " '宝马MINI维修',\n",
        " '植物园',\n",
        " '星巴克咖啡',\n",
        " '江苏菜',\n",
        " '寺庙道观',\n",
        " '便民商店/便利店',\n",
        " '肿瘤医院',\n",
        " '典当行',\n",
        " '水族馆',\n",
        " '综合医院',\n",
        " '职业技术学校',\n",
        " '上岛咖啡',\n",
        " '中国邮政储蓄银行',\n",
        " '摩托车维修',\n",
        " '证券营业厅',\n",
        " '兰博基尼维修',\n",
        " '停车场相关',\n",
        " '成人教育',\n",
        " '社会治安机构',\n",
        " '上海银行ATM',\n",
        " '东风标致销售',\n",
        " '汇丰银行ATM',\n",
        " '一汽-大众维修',\n",
        " '劳斯莱斯维修',\n",
        " '东风货车销售',\n",
        " '乒乓球馆',\n",
        " '胸科医院',\n",
        " '票务相关',\n",
        " '高速路出口',\n",
        " '北奔重汽销售',\n",
        " '幼儿园',\n",
        " '荣威销售',\n",
        " '郑州日产维修',\n",
        " '游乐场',\n",
        " '冷饮店',\n",
        " '停车场出口',\n",
        " '旅馆招待所',\n",
        " '山东菜(鲁菜)',\n",
        " '公司',\n",
        " '美式风味',\n",
        " '加气站',\n",
        " '四川菜(川菜)',\n",
        " '购物中心',\n",
        " '人才市场',\n",
        " '中国联通营业厅',\n",
        " '医疗保健用品',\n",
        " '影剧院相关',\n",
        " '游戏厅',\n",
        " '道达尔',\n",
        " '中国民生银行',\n",
        " '立交桥',\n",
        " '农村商业银行',\n",
        " '婴儿游泳馆',\n",
        " '拍卖行',\n",
        " '汽车租赁还车',\n",
        " '旅游景点',\n",
        " '家禽养殖基地',\n",
        " '广汽三菱销售',\n",
        " '眼科医院',\n",
        " '台湾菜',\n",
        " '村庄级地名',\n",
        " '旅行社',\n",
        " '公园景点售票处',\n",
        " '中国光大银行ATM',\n",
        " '残联',\n",
        " '东亚银行',\n",
        " '男洗手间',\n",
        " '楼栋号',\n",
        " '手机销售',\n",
        " '电台',\n",
        " '中信银行(国际)ATM',\n",
        " '江淮货车销售',\n",
        " '经济型连锁酒店',\n",
        " '信息咨询中心',\n",
        " '婴儿服务场所',\n",
        " '培训机构',\n",
        " '特色商业街',\n",
        " '改签',\n",
        " '商场',\n",
        " '车辆通行证办理处',\n",
        " '室内设施',\n",
        " '中国人寿保险公司',\n",
        " '西餐厅(综合风味)',\n",
        " '观致维修',\n",
        " 'Pacific Coffee Company',\n",
        " '音乐厅',\n",
        " '美术馆',\n",
        " '中国银行',\n",
        " '脑科医院',\n",
        " '度假村',\n",
        " '英菲尼迪维修',\n",
        " '平安银行',\n",
        " '清真菜馆',\n",
        " '服装鞋帽皮具店',\n",
        " '矿产公司',\n",
        " '海滨浴场',\n",
        " '民主党派',\n",
        " '汽车维修',\n",
        " '工厂',\n",
        " '车渡口',\n",
        " '交通银行ATM',\n",
        " '菲亚特销售',\n",
        " '平安银行ATM',\n",
        " '公共设施',\n",
        " '船票代售点',\n",
        " '消防机关',\n",
        " '口腔医院',\n",
        " '茶艺馆',\n",
        " '法国兴业银行ATM',\n",
        " '客运港',\n",
        " '花卉苗圃基地',\n",
        " '金融保险机构',\n",
        " '公司企业',\n",
        " '售票',\n",
        " '城市快速路入口',\n",
        " '政府机构及社会团体',\n",
        " '服务中心',\n",
        " '浙江菜',\n",
        " '足球场',\n",
        " '银行相关',\n",
        " '上海菜',\n",
        " '捷豹销售',\n",
        " '港口码头',\n",
        " '克莱斯勒销售',\n",
        " '知名企业',\n",
        " '垂钓园',\n",
        " '地名地址信息',\n",
        " '夜总会',\n",
        " '安徽菜(徽菜)',\n",
        " '地中海风格菜品',\n",
        " '搬家公司',\n",
        " '宝马MINI销售',\n",
        " '建材五金市场',\n",
        " '蔬菜市场',\n",
        " '货车维修',\n",
        " '行业协会',\n",
        " '三星级宾馆',\n",
        " '地市级政府及事业单位',\n",
        " '中国平安保险公司',\n",
        " '国家开发银行',\n",
        " '长途汽车站',\n",
        " '东风雪铁龙销售',\n",
        " '美容美发店',\n",
        " '兴业银行',\n",
        " '印度风味',\n",
        " '政府及社会团体相关',\n",
        " '热点地名',\n",
        " '摩托车服务相关',\n",
        " '高尔夫相关',\n",
        " '飞机场',\n",
        " '区县级地名',\n",
        " '五星级宾馆',\n",
        " '汽车服务',\n",
        " '休闲餐饮场所',\n",
        " '李宁专卖店',\n",
        " '自行车专卖店',\n",
        " '回教寺',\n",
        " '陕西重汽维修',\n",
        " '一汽-大众销售',\n",
        " '隧道',\n",
        " '汽车服务相关',\n",
        " '电讯营业厅',\n",
        " '三菱销售',\n",
        " '进口起亚维修',\n",
        " '售票处',\n",
        " '中国石油',\n",
        " '度假疗养场所',\n",
        " '住宅小区',\n",
        " '专营店',\n",
        " '省级景点',\n",
        " '其它农林牧渔基地',\n",
        " '电影院',\n",
        " '家具城',\n",
        " '华泰财产保险股份有限公司',\n",
        " '餐饮服务',\n",
        " '轮渡站',\n",
        " '上海浦东发展银行',\n",
        " '中餐厅',\n",
        " '东亚银行ATM',\n",
        " '林肯销售',\n",
        " '中国石化',\n",
        " '医药公司',\n",
        " '评估事务所',\n",
        " '别克销售',\n",
        " '保时捷销售',\n",
        " '健身中心',\n",
        " '路口名',\n",
        " '整形美容',\n",
        " '摄影冲印',\n",
        " '北京华联',\n",
        " '法式菜品餐厅',\n",
        " '上海大众维修',\n",
        " '邮局',\n",
        " '交通设施服务',\n",
        " '四星级宾馆',\n",
        " '生活服务场所',\n",
        " '公证鉴定机构',\n",
        " '北京现代维修',\n",
        " '法拉利销售',\n",
        " '路边停车场',\n",
        " '陕西重汽销售',\n",
        " '丧葬设施',\n",
        " '机场货运处',\n",
        " '机场出发/到达',\n",
        " '科教文化服务',\n",
        " '车辆管理机构',\n",
        " '农场',\n",
        " '起亚销售',\n",
        " '耐克专卖店',\n",
        " '洗车场',\n",
        " '农村商业银行ATM',\n",
        " '广发银行',\n",
        " '购物相关场所',\n",
        " '中国建设银行ATM',\n",
        " '纪念馆',\n",
        " '综合酒楼',\n",
        " '商住两用楼宇',\n",
        " '汽车综合维修',\n",
        " '风景名胜',\n",
        " '高尔夫球场',\n",
        " '高速服务区',\n",
        " '一汽丰田维修',\n",
        " '宠物市场',\n",
        " '体育用品店',\n",
        " '汽车救援',\n",
        " '中国铁通营业厅',\n",
        " '意式菜品餐厅',\n",
        " '乐天玛特',\n",
        " '别墅',\n",
        " '北京菜',\n",
        " '建筑公司',\n",
        " 'DS销售',\n",
        " '冶金化工',\n",
        " '永和豆浆',\n",
        " '巴克莱银行ATM',\n",
        " '潮州菜',\n",
        " '老字号',\n",
        " '跆拳道场馆',\n",
        " '火车票代售点',\n",
        " '步行街',\n",
        " '汽车养护',\n",
        " '布艺市场',\n",
        " '验车场',\n",
        " '其它亚洲菜',\n",
        " '教会',\n",
        " '古玩字画店',\n",
        " '乡镇级政府及事业单位',\n",
        " '中国工商银行',\n",
        " '汇丰银行',\n",
        " '东风货车维修',\n",
        " '路虎销售',\n",
        " '少先队',\n",
        " '宿舍',\n",
        " '文艺团体',\n",
        " '六星级及以上宾馆',\n",
        " '电信公司',\n",
        " '驾校',\n",
        " '进口起亚销售',\n",
        " '红十字会',\n",
        " '社会团体相关',\n",
        " '广汽丰田维修',\n",
        " '外国餐厅',\n",
        " '品牌服装店',\n",
        " '现代销售',\n",
        " '东风悦达起亚销售',\n",
        " '土特产专卖店',\n",
        " '韩国料理',\n",
        " '家居建材市场',\n",
        " '检察院',\n",
        " '保时捷维修',\n",
        " '世界遗产',\n",
        " '数码电子',\n",
        " '骨科医院',\n",
        " '高速路入口',\n",
        " '北京现代销售',\n",
        " '自来水营业厅',\n",
        " '乡镇级地名',\n",
        " '通行设施',\n",
        " '临街院正门',\n",
        " '名爵维修',\n",
        " '玛莎拉蒂销售',\n",
        " '户外健身场所',\n",
        " '公园',\n",
        " '自动提款机',\n",
        " '东风日产销售',\n",
        " '商务写字楼',\n",
        " '国税机关',\n",
        " '三菱维修',\n",
        " '奇瑞销售',\n",
        " '货运港口码头',\n",
        " '江淮销售',\n",
        " '中国民生银行ATM',\n",
        " '物流速递',\n",
        " '凯迪拉克销售',\n",
        " '网吧',\n",
        " '剧场',\n",
        " '公共停车场',\n",
        " '洗衣店',\n",
        " '餐饮相关',\n",
        " '动物医疗场所',\n",
        " '摩托车服务',\n",
        " '银行',\n",
        " '沃尔玛',\n",
        " '儿童用品店',\n",
        " '高速停车区',\n",
        " '东风维修',\n",
        " '梅赛德斯-奔驰维修',\n",
        " '中信银行ATM',\n",
        " '地铁站',\n",
        " '宾馆酒店',\n",
        " '科教文化场所',\n",
        " '高尔夫练习场',\n",
        " '钟表店',\n",
        " '政府机关相关',\n",
        " '飞机票代售点',\n",
        " '火锅店',\n",
        " '西北菜',\n",
        " '一汽-大众奥迪维修',\n",
        " '广发银行ATM',\n",
        " '省直辖市级政府及事业单位',\n",
        " '品牌鞋店',\n",
        " '二手车交易',\n",
        " '财务公司',\n",
        " '法院',\n",
        " '卜蜂莲花',\n",
        " '厨卫市场',\n",
        " '广东菜(粤菜)',\n",
        " '水产海鲜市场',\n",
        " '专利事务所',\n",
        " '红旗维修',\n",
        " '网球场',\n",
        " '自然地名',\n",
        " '共青团',\n",
        " '斯柯达维修',\n",
        " '招商银行',\n",
        " 'KTV',\n",
        " '茶餐厅',\n",
        " '书店',\n",
        " '娱乐场所',\n",
        " '会展中心',\n",
        " '工商税务机构',\n",
        " '区县级政府及事业单位',\n",
        " '文化宫',\n",
        " '展览馆',\n",
        " '宠物用品店',\n",
        " '金融保险服务',\n",
        " '斯柯达销售',\n",
        " '交通执法站',\n",
        " '进站口/检票口',\n",
        " '交通服务相关',\n",
        " '水果基地',\n",
        " '渣打银行',\n",
        " '摄影器材店',\n",
        " '华润',\n",
        " '滑雪场',\n",
        " '中学',\n",
        " '音像店',\n",
        " '紧急避难场所',\n",
        " '机械电子',\n",
        " '报社',\n",
        " '商务住宅相关',\n",
        " '雪佛兰维修',\n",
        " '大众销售',\n",
        " '篮球场馆',\n",
        " '必胜客',\n",
        " '东风本田销售',\n",
        " '东北菜',\n",
        " '住宿服务相关',\n",
        " '事务所',\n",
        " '行李查询/行李问询',\n",
        " '疗养院',\n",
        " '吉普销售',\n",
        " '其它能源站',\n",
        " '进口现代销售',\n",
        " '物流仓储场地',\n",
        " '普通地名',\n",
        " '咖啡厅',\n",
        " '灯具瓷器市场',\n",
        " '超市',\n",
        " '宾利销售',\n",
        " '福特销售',\n",
        " '建筑物门',\n",
        " '急救中心',\n",
        " '汽车配件销售',\n",
        " '出版社',\n",
        " '劳斯莱斯销售',\n",
        " '湖南菜(湘菜)',\n",
        " '汽车租赁',\n",
        " '门牌信息',\n",
        " '东风日产维修',\n",
        " '水上活动中心',\n",
        " '医疗保健服务场所',\n",
        " '烟酒专卖店']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}