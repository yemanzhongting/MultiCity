{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "seq2seq_translation_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yemanzhongting/MultiCity/blob/main/City2POI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqOI185olb9W"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0SU57-Vewmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1e707e0-fee0-4a39-b0d7-c9421ff57f5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxig8rKxe6eI"
      },
      "source": [
        "!cp /content/drive/MyDrive/wuhandaxue.csv /content"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoXcUg_YfQbZ"
      },
      "source": [
        "!cp /content/drive/MyDrive/streetview2.csv /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNgus06dfWnu"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTRvCVQWfY6r"
      },
      "source": [
        "poi=pd.read_csv('wuhandaxue.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91_kdN7bfeZ5"
      },
      "source": [
        "sview=pd.read_csv('/content/streetview2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bk_L8y3jfjff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "a2f05ca6-1064-4c2a-b6e0-23ba0aa97c76"
      },
      "source": [
        "poi.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "      <th>tags</th>\n",
              "      <th>lat_gcj</th>\n",
              "      <th>lon_gcj</th>\n",
              "      <th>lat_wgs</th>\n",
              "      <th>lon_wgs</th>\n",
              "      <th>pov_exp</th>\n",
              "      <th>heading</th>\n",
              "      <th>POI</th>\n",
              "      <th>POI32</th>\n",
              "      <th>POI64</th>\n",
              "      <th>CATEGORY</th>\n",
              "      <th>CATEGORY50</th>\n",
              "      <th>CATEGORY100</th>\n",
              "      <th>language2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10141003150306134427600</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.458431</td>\n",
              "      <td>114.307388</td>\n",
              "      <td>30.460880</td>\n",
              "      <td>114.301952</td>\n",
              "      <td>2</td>\n",
              "      <td>153</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>[  4154 395493 208493  19057 395492 216694 332...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅'...</td>\n",
              "      <td>Car Tree Tree Car TreeCar Tree Tree Tree TreeC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10141003150306134525400</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.461331</td>\n",
              "      <td>114.306847</td>\n",
              "      <td>30.463780</td>\n",
              "      <td>114.301411</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>[216628 221539 218523 395495  32257 127973  32...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>['餐饮相关', '中餐厅', '餐饮相关', '物流速递', '其它农林牧渔基地', '汽...</td>\n",
              "      <td>Tree House Tree Tree LandCar Tree Tree Tree Tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10141003150306134608900</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.463268</td>\n",
              "      <td>114.308234</td>\n",
              "      <td>30.465714</td>\n",
              "      <td>114.302797</td>\n",
              "      <td>2</td>\n",
              "      <td>228</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>[342477  32463  32451  32219  32015 446011 216...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>['政府及社会团体相关', '公司', '公司', '机械电子', '公司', '科教文化场...</td>\n",
              "      <td>Tree Tree House Car TreeTree Tree Tree Tree Ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10141003150306134621500</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.463926</td>\n",
              "      <td>114.308983</td>\n",
              "      <td>30.466371</td>\n",
              "      <td>114.303544</td>\n",
              "      <td>2</td>\n",
              "      <td>225</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>[ 32219  32015 342477  32463 446011 120814 307...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>['机械电子', '公司', '政府及社会团体相关', '公司', '科教文化场所', '政...</td>\n",
              "      <td>Tree Tree Tree Tree TreeTree Tree House Tree T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10141003150306134625100</td>\n",
              "      <td>Ｓ１１３</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>30.464176</td>\n",
              "      <td>114.309251</td>\n",
              "      <td>30.466621</td>\n",
              "      <td>114.303812</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>[ 32219  32015 446011 342477  32463 120814 307...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>['机械电子', '公司', '科教文化场所', '政府及社会团体相关', '公司', '政...</td>\n",
              "      <td>Tree Tree House Tree TreeTree Car House Tree T...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        id  ...                                          language2\n",
              "0  10141003150306134427600  ...  Car Tree Tree Car TreeCar Tree Tree Tree TreeC...\n",
              "1  10141003150306134525400  ...  Tree House Tree Tree LandCar Tree Tree Tree Tr...\n",
              "2  10141003150306134608900  ...  Tree Tree House Car TreeTree Tree Tree Tree Ho...\n",
              "3  10141003150306134621500  ...  Tree Tree Tree Tree TreeTree Tree House Tree T...\n",
              "4  10141003150306134625100  ...  Tree Tree House Tree TreeTree Car House Tree T...\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPTb3Oqjga5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c82fa3ac-ea8d-412d-bd21-d0a5af6d3ef6"
      },
      "source": [
        "test=poi['CATEGORY'].values.tolist()[0]\n",
        "test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"['公交车站相关', '美容美发店', '快餐厅', '工厂', '维修站点', '中餐厅', '摩托车维修', '清真菜馆', '美容美发店', '美容美发店']\""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNL52rurggOv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6696898b-fd6a-477a-fcc9-51f8f507fbe2"
      },
      "source": [
        "eval(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['生活服务场所',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '生活服务场所',\n",
              " '美容美发店',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '建筑公司',\n",
              " '汽车维修',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '乡镇以下级政府及事业单位',\n",
              " '乡镇以下级政府及事业单位']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAwFIiH_ftJ4"
      },
      "source": [
        "# poi['language']=['CATEGORY']\n",
        "poi['language'] = poi.apply(lambda x: ' '.join(eval(x['CATEGORY'])), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR2XsoktflBM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "8027bd7c-0361-4bc4-9914-9abae68da3e2"
      },
      "source": [
        "sview.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhotoName</th>\n",
              "      <th>PhotoID</th>\n",
              "      <th>OneType</th>\n",
              "      <th>TwoType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10141003150306134357300_back_349.jpg</td>\n",
              "      <td>10141003150306134357300</td>\n",
              "      <td>House Car Tree Tree Land vehicle Car Tree Tree...</td>\n",
              "      <td>House Car Tree Tree Land vehicle Car Tree Tree...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10141003150306134357300_front_169.jpg</td>\n",
              "      <td>10141003150306134357300</td>\n",
              "      <td>Car Person Person Person Car Car Building Car ...</td>\n",
              "      <td>Car Person Person Person Car Car Building Car ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10141003150306134357300_left_79.jpg</td>\n",
              "      <td>10141003150306134357300</td>\n",
              "      <td>Van Person Land vehicle Truck Wheel Car Wheel ...</td>\n",
              "      <td>Van Person Land vehicle Truck Wheel Car Wheel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10141003150306134357300_right_259.jpg</td>\n",
              "      <td>10141003150306134357300</td>\n",
              "      <td>Building Person Window Window Window Building ...</td>\n",
              "      <td>Building Person Window Window Window Building ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10141003150306134407700_back_158.jpg</td>\n",
              "      <td>10141003150306134407700</td>\n",
              "      <td>Car Car Car Car Window Window House Car Car Wi...</td>\n",
              "      <td>Car Car Car Car Window Window House Car Car Wi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               PhotoName  ...                                            TwoType\n",
              "0   10141003150306134357300_back_349.jpg  ...  House Car Tree Tree Land vehicle Car Tree Tree...\n",
              "1  10141003150306134357300_front_169.jpg  ...  Car Person Person Person Car Car Building Car ...\n",
              "2    10141003150306134357300_left_79.jpg  ...  Van Person Land vehicle Truck Wheel Car Wheel ...\n",
              "3  10141003150306134357300_right_259.jpg  ...  Building Person Window Window Window Building ...\n",
              "4   10141003150306134407700_back_158.jpg  ...  Car Car Car Car Window Window House Car Car Wi...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kENnh02cmqd1"
      },
      "source": [
        "sview['Five']=sview.apply(lambda x: ' '.join((x['TwoType']).split(' ')[0:5]), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6euAVG6CiIsD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ea5bac7-28ee-4a71-81b6-ce7ef9587480"
      },
      "source": [
        "sview[sview['PhotoID']=='10141003150306134357300']['TwoType'].values.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['House Car Tree Tree Land vehicle Car Tree Tree House House Car Tree Tree House Tree Car Tree Tree Tree House Tree Tree Tree Tree Tree',\n",
              " 'Car Person Person Person Car Car Building Car House Car Person Window Car Person Window Car Car Window Person Window Car Person Street light Window Window',\n",
              " 'Van Person Land vehicle Truck Wheel Car Wheel Footwear Footwear Footwear Building Van Wheel Boat Wheel Footwear Wheel Tree Van Van Wheel Window Window Tree Wheel',\n",
              " 'Building Person Window Window Window Building Building Window Window Window Window Window Window Car Window Window Window Window Window Window Window Window Window Window Window']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxo54VKGh8ty"
      },
      "source": [
        "def get_five(id):\n",
        "  texts=\"\"\n",
        "  tmp=sview[sview['PhotoID']==id]['TwoType'].values.tolist()\n",
        "  for i in tmp:\n",
        "    texts=texts+' '.join(list(set(i.split(' '))))\n",
        "  return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA7Uaq0BpGzR"
      },
      "source": [
        "def get_five(id):\n",
        "  texts=\"\"\n",
        "  tmp=sview[sview['PhotoID']==id]['Five'].values.tolist()\n",
        "  for i in tmp:\n",
        "    texts=texts+' '.join(i.split(' '))\n",
        "  return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ugwdwn2kpVbe"
      },
      "source": [
        "def get_five(id):\n",
        "  texts=\"\"\n",
        "  tmp=sview[sview['PhotoID']==id]['TwoType'].values.tolist()\n",
        "  for i in tmp:\n",
        "    texts=texts+i\n",
        "  return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irWZ-vQ1kyLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "7e809a15-3cac-40ca-e3b9-3a5bdf842635"
      },
      "source": [
        "get_five('10141003150306134357300')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'House Car Tree Tree Land vehicle Car Tree Tree House House Car Tree Tree House Tree Car Tree Tree Tree House Tree Tree Tree Tree TreeCar Person Person Person Car Car Building Car House Car Person Window Car Person Window Car Car Window Person Window Car Person Street light Window WindowVan Person Land vehicle Truck Wheel Car Wheel Footwear Footwear Footwear Building Van Wheel Boat Wheel Footwear Wheel Tree Van Van Wheel Window Window Tree WheelBuilding Person Window Window Window Building Building Window Window Window Window Window Window Car Window Window Window Window Window Window Window Window Window Window Window'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KiTHDU2Lq1NC"
      },
      "source": [
        "分割数据"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAg-bgkRqsTx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da7ZXu1vqsWo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8YkBzfHk39e"
      },
      "source": [
        "# sview['']=\n",
        "poi['language2'] = poi.apply(lambda x:get_five(x['id']), axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F_A-reMpsJZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjrEmHv9g7Iz"
      },
      "source": [
        "## 构建训练对"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kn8eKzgN3Zf"
      },
      "source": [
        "CATEGORY\tCATEGORY50\tCATEGORY100\tlanguage2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcy0XOtQTs-H",
        "outputId": "a064f2e6-2ee3-4a31-addc-497c874bac90"
      },
      "source": [
        "eval('[1,2]')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCBIAJ4gVhyZ",
        "outputId": "ee07fd2b-88b5-4454-f51f-b6c828e4fbfb"
      },
      "source": [
        "!pip install pypinyin"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pypinyin\n",
            "  Downloading pypinyin-0.42.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: pypinyin\n",
            "Successfully installed pypinyin-0.42.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDoN92OoV0mL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INTUV4iCV3H0"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zoo6bMfcVlav",
        "outputId": "f7b58a7a-19d0-4d2d-f68f-7ccce1cac9c3"
      },
      "source": [
        "from pypinyin import pinyin, lazy_pinyin, Style\n",
        "''.join(lazy_pinyin('中心'))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'zhongxin'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxUSudSPN5iF"
      },
      "source": [
        "pairs=[]\n",
        "with open('/content/data/poi-sv.txt','w+',encoding='utf-8') as f:\n",
        "  for index, row in poi.iterrows():\n",
        "      # print(index) # 输出每行的索引值\n",
        "      tmp=eval(row['CATEGORY'])\n",
        "      emp=[]\n",
        "      for i in tmp:\n",
        "        emp.append(''.join(lazy_pinyin(i)))\n",
        "\n",
        "      f.write(' '.join(emp))\n",
        "      f.write('\\t')\n",
        "      f.write(row['language2'])\n",
        "      f.write('\\n')\n",
        "      pairs.append(\n",
        "      [row['CATEGORY'],row['language2']]\n",
        "      )"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVYIjV4NnyIu"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld8GzdIlOJZZ",
        "outputId": "b7d6cb1d-e20f-4211-abc1-22b8c0230358"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20790"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBK1OJrJn1Uu"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BJyzf-Nn5ho"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0bgdBMqn5k2"
      },
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFAyrNYKn5nU"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXiFjlwQn5p4"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG-wi87En5sa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcdc0ed2-484a-4166-9a72-e6222937245d"
      },
      "source": [
        "print(random.choice(pairs))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"['临街院门', '住宅小区', '洗浴推拿场所', '公共停车场', '生活服务场所', '中餐厅', '美容美发店', '美容美发店', '生活服务场所', '公司企业']\", 'Car Car Wheel Tree TreeCar Car Car Car CarTree Car Tree Tree TreeCar Skyscraper Tree Wheel Tree']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyymIQien5u1"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCInTwsioZL0"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5XclHBwoZOH"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbv9aYJIodfk"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsWz6UbgodiR"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4soTbsxodlB"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAt6-vG1odnf"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yInTL6Fhokll"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVkAQ1JsokoA"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by4XzfqYokqm"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GSkbegxOhsF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpbkQctxoktI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "49dba61f-35e8-47e8-d396-0ad5df04e9fb"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "#新建一个函数记录loss"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-e589675958b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_lang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_lang' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMz07PDhoq0i"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fokb04ZXo6TR"
      },
      "source": [
        "'生活服务场所', '乡镇以下级政府及事业单位', '生活服务场所', '美容美发店', '乡镇以下级政府及事业单位', '建筑公司', '汽车维修', '乡镇以下级政府及事业单位', '乡镇以下级政府及事业单位', '乡镇以下级政府及事业单位'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge26xldzoq3L"
      },
      "source": [
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1, \"je suis trop froid .\")\n",
        "plt.matshow(attentions.numpy())\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhqk2dR9oq5r"
      },
      "source": [
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention(\"elle a cinq ans de moins que moi .\")\n",
        "\n",
        "evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsjAoCY_oq8p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RppfTFj6orBk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ip_MQcRXlb9b"
      },
      "source": [
        "\n",
        "NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n",
        "*******************************************************************************\n",
        "**Author**: `Sean Robertson <https://github.com/spro/practical-pytorch>`_\n",
        "\n",
        "This is the third and final tutorial on doing \"NLP From Scratch\", where we\n",
        "write our own classes and functions to preprocess the data to do our NLP\n",
        "modeling tasks. We hope after you complete this tutorial that you'll proceed to\n",
        "learn how `torchtext` can handle much of this preprocessing for you in the\n",
        "three tutorials immediately following this one.\n",
        "\n",
        "In this project we will be teaching a neural network to translate from\n",
        "French to English.\n",
        "\n",
        "::\n",
        "\n",
        "    [KEY: > input, = target, < output]\n",
        "\n",
        "    > il est en train de peindre un tableau .\n",
        "    = he is painting a picture .\n",
        "    < he is painting a picture .\n",
        "\n",
        "    > pourquoi ne pas essayer ce vin delicieux ?\n",
        "    = why not try that delicious wine ?\n",
        "    < why not try that delicious wine ?\n",
        "\n",
        "    > elle n est pas poete mais romanciere .\n",
        "    = she is not a poet but a novelist .\n",
        "    < she not not a poet but a novelist .\n",
        "\n",
        "    > vous etes trop maigre .\n",
        "    = you re too skinny .\n",
        "    < you re all alone .\n",
        "\n",
        "... to varying degrees of success.\n",
        "\n",
        "This is made possible by the simple but powerful idea of the `sequence\n",
        "to sequence network <https://arxiv.org/abs/1409.3215>`__, in which two\n",
        "recurrent neural networks work together to transform one sequence to\n",
        "another. An encoder network condenses an input sequence into a vector,\n",
        "and a decoder network unfolds that vector into a new sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "To improve upon this model we'll use an `attention\n",
        "mechanism <https://arxiv.org/abs/1409.0473>`__, which lets the decoder\n",
        "learn to focus over a specific range of the input sequence.\n",
        "\n",
        "**Recommended Reading:**\n",
        "\n",
        "I assume you have at least installed PyTorch, know Python, and\n",
        "understand Tensors:\n",
        "\n",
        "-  https://pytorch.org/ For installation instructions\n",
        "-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n",
        "-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n",
        "-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n",
        "\n",
        "\n",
        "It would also be useful to know about Sequence to Sequence networks and\n",
        "how they work:\n",
        "\n",
        "-  `Learning Phrase Representations using RNN Encoder-Decoder for\n",
        "   Statistical Machine Translation <https://arxiv.org/abs/1406.1078>`__\n",
        "-  `Sequence to Sequence Learning with Neural\n",
        "   Networks <https://arxiv.org/abs/1409.3215>`__\n",
        "-  `Neural Machine Translation by Jointly Learning to Align and\n",
        "   Translate <https://arxiv.org/abs/1409.0473>`__\n",
        "-  `A Neural Conversational Model <https://arxiv.org/abs/1506.05869>`__\n",
        "\n",
        "You will also find the previous tutorials on\n",
        ":doc:`/intermediate/char_rnn_classification_tutorial`\n",
        "and :doc:`/intermediate/char_rnn_generation_tutorial`\n",
        "helpful as those concepts are very similar to the Encoder and Decoder\n",
        "models, respectively.\n",
        "\n",
        "**Requirements**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYB8UiK0opwt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHjUoIuOopzb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP9sgls4op2F"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56PpPQhPop4u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHQYilGzfPR7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIy1czP8lb9d"
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWJ_GhGglb9e"
      },
      "source": [
        "Loading data files\n",
        "==================\n",
        "\n",
        "The data for this project is a set of many thousands of English to\n",
        "French translation pairs.\n",
        "\n",
        "`This question on Open Data Stack\n",
        "Exchange <https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages>`__\n",
        "pointed me to the open translation site https://tatoeba.org/ which has\n",
        "downloads available at https://tatoeba.org/eng/downloads - and better\n",
        "yet, someone did the extra work of splitting language pairs into\n",
        "individual text files here: https://www.manythings.org/anki/\n",
        "\n",
        "The English to French pairs are too big to include in the repo, so\n",
        "download to ``data/eng-fra.txt`` before continuing. The file is a tab\n",
        "separated list of translation pairs:\n",
        "\n",
        "::\n",
        "\n",
        "    I am cold.    J'ai froid.\n",
        "\n",
        ".. Note::\n",
        "   Download the data from\n",
        "   `here <https://download.pytorch.org/tutorial/data.zip>`_\n",
        "   and extract it to the current directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaG9_ie5lb9f"
      },
      "source": [
        "Similar to the character encoding used in the character-level RNN\n",
        "tutorials, we will be representing each word in a language as a one-hot\n",
        "vector, or giant vector of zeros except for a single one (at the index\n",
        "of the word). Compared to the dozens of characters that might exist in a\n",
        "language, there are many many more words, so the encoding vector is much\n",
        "larger. We will however cheat a bit and trim the data to only use a few\n",
        "thousand words per language.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/word-encoding.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0EPrID4lb9g"
      },
      "source": [
        "We'll need a unique index per word to use as the inputs and targets of\n",
        "the networks later. To keep track of all this we will use a helper class\n",
        "called ``Lang`` which has word → index (``word2index``) and index → word\n",
        "(``index2word``) dictionaries, as well as a count of each word\n",
        "``word2count`` which will be used to replace rare words later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aAVNeMFSZLF"
      },
      "source": [
        "我们需要每个单词有一个唯一的索引，以便稍后用作网络的输入和目标。为了跟踪所有这些，我们将使用一个名为Lang的助手类，该类包含word→ 索引（word2index）和索引→ 单词（index2word）字典，以及每个单词的计数word2count，稍后将用于替换稀有单词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvufVOXVlb9h"
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59vgGnxHlb9h"
      },
      "source": [
        "The files are all in Unicode, to simplify we will turn Unicode\n",
        "characters to ASCII, make everything lowercase, and trim most\n",
        "punctuation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAYfE3Qllb9i"
      },
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "\n",
        "\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    return s"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OT8mpEa2lb9i"
      },
      "source": [
        "To read the data file we will split the file into lines, and then split\n",
        "lines into pairs. The files are all English → Other Language, so if we\n",
        "want to translate from Other Language → English I added the ``reverse``\n",
        "flag to reverse the pairs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uP5tQvBlb9j"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1lWhExSLHC"
      },
      "source": [
        "## 修改这个函数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4sYlLH0SJyu"
      },
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    # Read the file and split into lines\n",
        "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
        "        read().strip().split('\\n')\n",
        "\n",
        "    # Split every line into pairs and normalize\n",
        "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
        "\n",
        "    # Reverse pairs, make Lang instances\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLf7HCXsSjnv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5W7e-pClb9j"
      },
      "source": [
        "Since there are a *lot* of example sentences and we want to train\n",
        "something quickly, we'll trim the data set to only relatively short and\n",
        "simple sentences. Here the maximum length is 10 words (that includes\n",
        "ending punctuation) and we're filtering to sentences that translate to\n",
        "the form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\n",
        "earlier).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FluxrUxaXDrN"
      },
      "source": [
        "因为有很多例句，我们想快速地训练一些东西，所以我们将把数据集精简为相对简短的句子。这里的最大长度是10个单词（包括结尾标点符号），我们将过滤到翻译为“我是”或“他是”等形式的句子（考虑前面替换的撇号）。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkVqrvOVlb9k"
      },
      "source": [
        "MAX_LENGTH =50\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH #and \\\n",
        "        # p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d-kkDcLXhMK",
        "outputId": "79bec7be-0957-4d4b-a1a2-3f9a59bf2c48"
      },
      "source": [
        "len(pairs[0][1].split(' '))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sH41FHouXZfp",
        "outputId": "253525d6-102d-4359-ce54-4c1210c3b034"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree',\n",
              " 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUD_lDvUVE4h",
        "outputId": "c562028f-243d-4ac6-d716-f2358bd0cf76"
      },
      "source": [
        "filterPair([\"i am \", \"i m \"])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aevyO2utVB0K",
        "outputId": "d12b8a91-1194-4522-fdb1-d551c3fc57dd"
      },
      "source": [
        "filterPairs(pairs[0])"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree',\n",
              " 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian']"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K74xSsR4lb9k"
      },
      "source": [
        "The full process for preparing the data is:\n",
        "\n",
        "-  Read text file and split into lines, split lines into pairs\n",
        "-  Normalize text, filter by length and content\n",
        "-  Make word lists from sentences in pairs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGz7OhD_uOeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133c1bca-aef8-4e01-ed68-50dd1955c7de"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/astorfi/sequence-to-sequence-from-scratch/master/data/eng-fra.txt"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-29 14:17:07--  https://raw.githubusercontent.com/astorfi/sequence-to-sequence-from-scratch/master/data/eng-fra.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9541158 (9.1M) [text/plain]\n",
            "Saving to: ‘eng-fra.txt’\n",
            "\n",
            "eng-fra.txt         100%[===================>]   9.10M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-29 14:17:08 (85.5 MB/s) - ‘eng-fra.txt’ saved [9541158/9541158]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRnjTVWSlb9l"
      },
      "source": [
        "def prepareData(lang1, lang2, reverse=False):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = filterPairs(pairs)\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        input_lang.addSentence(pair[0])\n",
        "        output_lang.addSentence(pair[1])\n",
        "    print(\"Counted words:\")\n",
        "    print(input_lang.name, input_lang.n_words)\n",
        "    print(output_lang.name, output_lang.n_words)\n",
        "    return input_lang, output_lang, pairs"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-00Ci-hQvXni",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8def60b9-b306-471f-d795-ceef437d03b0"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10599"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbJag322vYqr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f74f442b-780c-4726-e52a-b86dd4d51578"
      },
      "source": [
        "texts=\"\"\n",
        "for i in pairs:\n",
        "  texts=texts+i[0]\n",
        "len(set(texts.split(' '))\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4430"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJBYp2jAUsgw",
        "outputId": "64bbbd0c-19ea-4432-bea7-ea6964972263"
      },
      "source": [
        "input_lang, output_lang, pairs = readLangs('poi', 'sv', True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F-6I2UUW3Vt",
        "outputId": "5280d04a-eb02-4251-be5f-a324df864168"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree',\n",
              " 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pnvJP5nU1hr",
        "outputId": "b4dc9197-95b4-4f0f-f0ef-22070d14b895"
      },
      "source": [
        "len(pairs)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20790"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-eLofhHUwQy",
        "outputId": "d1224a68-3ab2-49e7-e90f-763a28c90651"
      },
      "source": [
        "type(input_lang)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.Lang"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NqxR4sMunH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "065054da-639e-4b2a-87ee-2b48ac039a81"
      },
      "source": [
        "input_lang, output_lang, pairs = prepareData('poi', 'sv', True)\n",
        "print(random.choice(pairs))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading lines...\n",
            "Read 20790 sentence pairs\n",
            "Trimmed to 20790 sentence pairs\n",
            "Counting words...\n",
            "Counted words:\n",
            "sv 998\n",
            "poi 551\n",
            "['tree house house tree treewindow building window window windowcar wheel wheel wheel treetree tree tree tree tree', 'jiaxiao linjieyuanzhengmen jiaxiao gongsi qichexiaoshou peixunjigou zhiyejishuxuexiao zhiyejishuxuexiao hangyexiehui binguanjiudian']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9FAVCTzlb9l"
      },
      "source": [
        "The Seq2Seq Model\n",
        "=================\n",
        "\n",
        "A Recurrent Neural Network, or RNN, is a network that operates on a\n",
        "sequence and uses its own output as input for subsequent steps.\n",
        "\n",
        "A `Sequence to Sequence network <https://arxiv.org/abs/1409.3215>`__, or\n",
        "seq2seq network, or `Encoder Decoder\n",
        "network <https://arxiv.org/pdf/1406.1078v3.pdf>`__, is a model\n",
        "consisting of two RNNs called the encoder and decoder. The encoder reads\n",
        "an input sequence and outputs a single vector, and the decoder reads\n",
        "that vector to produce an output sequence.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/seq2seq.png\n",
        "   :alt:\n",
        "\n",
        "Unlike sequence prediction with a single RNN, where every input\n",
        "corresponds to an output, the seq2seq model frees us from sequence\n",
        "length and order, which makes it ideal for translation between two\n",
        "languages.\n",
        "\n",
        "Consider the sentence \"Je ne suis pas le chat noir\" → \"I am not the\n",
        "black cat\". Most of the words in the input sentence have a direct\n",
        "translation in the output sentence, but are in slightly different\n",
        "orders, e.g. \"chat noir\" and \"black cat\". Because of the \"ne/pas\"\n",
        "construction there is also one more word in the input sentence. It would\n",
        "be difficult to produce a correct translation directly from the sequence\n",
        "of input words.\n",
        "\n",
        "With a seq2seq model the encoder creates a single vector which, in the\n",
        "ideal case, encodes the \"meaning\" of the input sequence into a single\n",
        "vector — a single point in some N dimensional space of sentences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHYjcrfAlb9m"
      },
      "source": [
        "The Encoder\n",
        "-----------\n",
        "\n",
        "The encoder of a seq2seq network is a RNN that outputs some value for\n",
        "every word from the input sentence. For every input word the encoder\n",
        "outputs a vector and a hidden state, and uses the hidden state for the\n",
        "next input word.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/encoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9Ugirgilb9m"
      },
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output = embedded\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hk-ODgwslb9n"
      },
      "source": [
        "The Decoder\n",
        "-----------\n",
        "\n",
        "The decoder is another RNN that takes the encoder output vector(s) and\n",
        "outputs a sequence of words to create the translation.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxJlejJ2lb9n"
      },
      "source": [
        "Simple Decoder\n",
        "^^^^^^^^^^^^^^\n",
        "\n",
        "In the simplest seq2seq decoder we use only last output of the encoder.\n",
        "This last output is sometimes called the *context vector* as it encodes\n",
        "context from the entire sequence. This context vector is used as the\n",
        "initial hidden state of the decoder.\n",
        "\n",
        "At every step of decoding, the decoder is given an input token and\n",
        "hidden state. The initial input token is the start-of-string ``<SOS>``\n",
        "token, and the first hidden state is the context vector (the encoder's\n",
        "last hidden state).\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajg3EWg_lb9o"
      },
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input).view(1, 1, -1)\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCcusKVFlb9p"
      },
      "source": [
        "I encourage you to train and observe the results of this model, but to\n",
        "save space we'll be going straight for the gold and introducing the\n",
        "Attention Mechanism.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwSnRRqolb9q"
      },
      "source": [
        "Attention Decoder\n",
        "^^^^^^^^^^^^^^^^^\n",
        "\n",
        "If only the context vector is passed between the encoder and decoder,\n",
        "that single vector carries the burden of encoding the entire sentence.\n",
        "\n",
        "Attention allows the decoder network to \"focus\" on a different part of\n",
        "the encoder's outputs for every step of the decoder's own outputs. First\n",
        "we calculate a set of *attention weights*. These will be multiplied by\n",
        "the encoder output vectors to create a weighted combination. The result\n",
        "(called ``attn_applied`` in the code) should contain information about\n",
        "that specific part of the input sequence, and thus help the decoder\n",
        "choose the right output words.\n",
        "\n",
        ".. figure:: https://i.imgur.com/1152PYf.png\n",
        "   :alt:\n",
        "\n",
        "Calculating the attention weights is done with another feed-forward\n",
        "layer ``attn``, using the decoder's input and hidden state as inputs.\n",
        "Because there are sentences of all sizes in the training data, to\n",
        "actually create and train this layer we have to choose a maximum\n",
        "sentence length (input length, for encoder outputs) that it can apply\n",
        "to. Sentences of the maximum length will use all the attention weights,\n",
        "while shorter sentences will only use the first few.\n",
        "\n",
        ".. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n",
        "   :alt:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC9ytHoFlb9q"
      },
      "source": [
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.dropout_p = dropout_p\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
        "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
        "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
        "        self.dropout = nn.Dropout(self.dropout_p)\n",
        "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attn_weights = F.softmax(\n",
        "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
        "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
        "                                 encoder_outputs.unsqueeze(0))\n",
        "\n",
        "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
        "        output = self.attn_combine(output).unsqueeze(0)\n",
        "\n",
        "        output = F.relu(output)\n",
        "        output, hidden = self.gru(output, hidden)\n",
        "\n",
        "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
        "        return output, hidden, attn_weights\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVaME_wrlb9q"
      },
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n",
        "  limitation by using a relative position approach. Read about \"local\n",
        "  attention\" in `Effective Approaches to Attention-based Neural Machine\n",
        "  Translation <https://arxiv.org/abs/1508.04025>`__.</p></div>\n",
        "\n",
        "Training\n",
        "========\n",
        "\n",
        "Preparing Training Data\n",
        "-----------------------\n",
        "\n",
        "To train, for each pair we will need an input tensor (indexes of the\n",
        "words in the input sentence) and target tensor (indexes of the words in\n",
        "the target sentence). While creating these vectors we will append the\n",
        "EOS token to both sequences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQYFLv3ilb9r"
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "    indexes = indexesFromSentence(lang, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "\n",
        "def tensorsFromPair(pair):\n",
        "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
        "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
        "    return (input_tensor, target_tensor)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSaW3zo6lb9r"
      },
      "source": [
        "Training the Model\n",
        "------------------\n",
        "\n",
        "To train we run the input sentence through the encoder, and keep track\n",
        "of every output and the latest hidden state. Then the decoder is given\n",
        "the ``<SOS>`` token as its first input, and the last hidden state of the\n",
        "encoder as its first hidden state.\n",
        "\n",
        "\"Teacher forcing\" is the concept of using the real target outputs as\n",
        "each next input, instead of using the decoder's guess as the next input.\n",
        "Using teacher forcing causes it to converge faster but `when the trained\n",
        "network is exploited, it may exhibit\n",
        "instability <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf>`__.\n",
        "\n",
        "You can observe outputs of teacher-forced networks that read with\n",
        "coherent grammar but wander far from the correct translation -\n",
        "intuitively it has learned to represent the output grammar and can \"pick\n",
        "up\" the meaning once the teacher tells it the first few words, but it\n",
        "has not properly learned how to create the sentence from the translation\n",
        "in the first place.\n",
        "\n",
        "Because of the freedom PyTorch's autograd gives us, we can randomly\n",
        "choose to use teacher forcing or not with a simple if statement. Turn\n",
        "``teacher_forcing_ratio`` up to use more of it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3b8TbWzlb9s"
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for ei in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(\n",
        "            input_tensor[ei], encoder_hidden)\n",
        "        encoder_outputs[ei] = encoder_output[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        # Teacher forcing: Feed the target as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            decoder_input = target_tensor[di]  # Teacher forcing\n",
        "\n",
        "    else:\n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        for di in range(target_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
        "\n",
        "            loss += criterion(decoder_output, target_tensor[di])\n",
        "            if decoder_input.item() == EOS_token:\n",
        "                break\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et8hCknylb9s"
      },
      "source": [
        "This is a helper function to print time elapsed and estimated time\n",
        "remaining given the current time and progress %.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ngcd8gsslb9t"
      },
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_V5GHuWlb9t"
      },
      "source": [
        "The whole training process looks like this:\n",
        "\n",
        "-  Start a timer\n",
        "-  Initialize optimizers and criterion\n",
        "-  Create set of training pairs\n",
        "-  Start empty losses array for plotting\n",
        "\n",
        "Then we call ``train`` many times and occasionally print the progress (%\n",
        "of examples, time so far, estimated time) and average loss.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JW9xHRUelb9u"
      },
      "source": [
        "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
        "                      for i in range(n_iters)]\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for iter in range(1, n_iters + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        loss = train(input_tensor, target_tensor, encoder,\n",
        "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if iter % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
        "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
        "\n",
        "        if iter % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-rwK4X2lb9u"
      },
      "source": [
        "Plotting results\n",
        "----------------\n",
        "\n",
        "Plotting is done with matplotlib, using the array of loss values\n",
        "``plot_losses`` saved while training.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbBGUBxKlb9u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKoUgTi-lb9v"
      },
      "source": [
        "Evaluation\n",
        "==========\n",
        "\n",
        "Evaluation is mostly the same as training, but there are no targets so\n",
        "we simply feed the decoder's predictions back to itself for each step.\n",
        "Every time it predicts a word we add it to the output string, and if it\n",
        "predicts the EOS token we stop there. We also store the decoder's\n",
        "attention outputs for display later.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SprH-Sehlb9v"
      },
      "source": [
        "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n",
        "                                                     encoder_hidden)\n",
        "            encoder_outputs[ei] += encoder_output[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "        decoder_attentions = torch.zeros(max_length, max_length)\n",
        "\n",
        "        for di in range(max_length):\n",
        "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
        "                decoder_input, decoder_hidden, encoder_outputs)\n",
        "            decoder_attentions[di] = decoder_attention.data\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words, decoder_attentions[:di + 1]"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blhXZg8mlb9v"
      },
      "source": [
        "We can evaluate random sentences from the training set and print out the\n",
        "input, target, and output to make some subjective quality judgements:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLdRQBmHlb9w"
      },
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX4AyX_Tlb9w"
      },
      "source": [
        "Training and Evaluating\n",
        "=======================\n",
        "\n",
        "With all these helper functions in place (it looks like extra work, but\n",
        "it makes it easier to run multiple experiments) we can actually\n",
        "initialize a network and start training.\n",
        "\n",
        "Remember that the input sentences were heavily filtered. For this small\n",
        "dataset we can use relatively small networks of 256 hidden nodes and a\n",
        "single GRU layer. After about 40 minutes on a MacBook CPU we'll get some\n",
        "reasonable results.\n",
        "\n",
        ".. Note::\n",
        "   If you run this notebook you can train, interrupt the kernel,\n",
        "   evaluate, and continue training later. Comment out the lines where the\n",
        "   encoder and decoder are initialized and run ``trainIters`` again.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkPY-B1flb9w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f2a83df-6b26-40fc-a346-1821308e79dd"
      },
      "source": [
        "hidden_size = 256\n",
        "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
        "\n",
        "trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n",
        "#新建一个函数记录loss"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3m 28s (- 48m 45s) (5000 6%) 4.1855\n",
            "6m 46s (- 44m 3s) (10000 13%) 4.0713\n",
            "10m 8s (- 40m 32s) (15000 20%) 4.0037\n",
            "13m 27s (- 37m 1s) (20000 26%) 3.9657\n",
            "16m 48s (- 33m 37s) (25000 33%) 3.9306\n",
            "20m 8s (- 30m 13s) (30000 40%) 3.9119\n",
            "23m 28s (- 26m 50s) (35000 46%) 3.8832\n",
            "26m 47s (- 23m 26s) (40000 53%) 3.8755\n",
            "30m 4s (- 20m 3s) (45000 60%) 3.8622\n",
            "33m 23s (- 16m 41s) (50000 66%) 3.8460\n",
            "36m 43s (- 13m 21s) (55000 73%) 3.8371\n",
            "40m 2s (- 10m 0s) (60000 80%) 3.8379\n",
            "43m 24s (- 6m 40s) (65000 86%) 3.8224\n",
            "46m 46s (- 3m 20s) (70000 93%) 3.7978\n",
            "50m 6s (- 0m 0s) (75000 100%) 3.7913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSi4NcEefI_6"
      },
      "source": [
        "### 增加词袋token ID 的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPpUOFgYff86"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfyXa6cXX5gz",
        "outputId": "dc84b027-1b99-431f-a4c3-d174f51c058a"
      },
      "source": [
        "input_lang.n_words"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "998"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smWgR-okX5nv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mUmmSdkxY8d"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cApMGg_Wlb9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6647cb3-d0ed-489d-b1ab-0abd6b786c01"
      },
      "source": [
        "evaluateRandomly(encoder1, attn_decoder1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "> je suis desolee de vous avoir blesse .\n",
            "= i m sorry i hurt you .\n",
            "< i m sorry i hurt you . <EOS>\n",
            "\n",
            "> je ne suis pas ton ennemi .\n",
            "= i am not your enemy .\n",
            "< i m not your enemy . <EOS>\n",
            "\n",
            "> vous etes merveilleuses .\n",
            "= you re wonderful .\n",
            "< you re fascinating . <EOS>\n",
            "\n",
            "> c est un garcon intelligent .\n",
            "= he is an intelligent boy .\n",
            "< he is an intelligent boy . <EOS>\n",
            "\n",
            "> je vis mon reve .\n",
            "= i m living my dream .\n",
            "< i m making my . <EOS>\n",
            "\n",
            "> nous sommes desoles pour le derangement .\n",
            "= we are sorry for the inconvenience .\n",
            "< we are sorry for the inconvenience . <EOS>\n",
            "\n",
            "> je suis pret pour partir .\n",
            "= i m ready to go .\n",
            "< i m ready to go . <EOS>\n",
            "\n",
            "> vous etes tres habiles .\n",
            "= you re very clever .\n",
            "< you re very clever . <EOS>\n",
            "\n",
            "> tu es une opportuniste .\n",
            "= you re opportunistic .\n",
            "< you re opportunistic . <EOS>\n",
            "\n",
            "> je vais en amerique en avion .\n",
            "= i am going to america by plane .\n",
            "< i am going to america by . <EOS>\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26eQXeUflb9x"
      },
      "source": [
        "Visualizing Attention\n",
        "---------------------\n",
        "\n",
        "A useful property of the attention mechanism is its highly interpretable\n",
        "outputs. Because it is used to weight specific encoder outputs of the\n",
        "input sequence, we can imagine looking where the network is focused most\n",
        "at each time step.\n",
        "\n",
        "You could simply run ``plt.matshow(attentions)`` to see attention output\n",
        "displayed as a matrix, with the columns being input steps and rows being\n",
        "output steps:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVZLqBJA1U_8"
      },
      "source": [
        "torch.save(encoder1, '/content/encoder1')\n",
        "torch.save(attn_decoder1, '/content/attn_decoder1')"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GB-xgAk1j3z"
      },
      "source": [
        "encoder1 = torch.load('/content/encoder1')\n",
        "attn_decoder1 = torch.load('/content/attn_decoder1')\n",
        "# model.eval()"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbRVAmonmGvx",
        "outputId": "74323cc4-508c-4545-c1ea-a51c5ae58ee3"
      },
      "source": [
        "len(output_words)\n",
        "output_words"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['linjieyuanmen',\n",
              " 'linjieyuanmen',\n",
              " 'linjieyuanmen',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " 'shenghuofuwuchangsuo',\n",
              " '<EOS>']"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9RIw6f4lb9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "9bd8dd7a-0ca1-4d3b-8a08-e718e259c26e"
      },
      "source": [
        "a=\"qichezongheweixiu peixunjigou shangyemaoyi qicheweixiu linjieyuanmen qichezongheweixiu linjieyuanmen jiaxiao gongsi ditiezhan\t\"\n",
        "b=\"Train Car Wheel Car TrainCar Car Tree Car TreeTree Tree Tree Tree TreeTree Tree Tree Window Tree\"\n",
        "MAX_LENGTH=10\n",
        "output_words, attentions = evaluate(\n",
        "    encoder1, attn_decoder1,'car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree')\n",
        "\n",
        "plt.matshow(attentions.numpy())\n",
        "# plt.show()"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f32ce67b510>"
            ]
          },
          "metadata": {},
          "execution_count": 124
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x253.44 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWTSrqQikk3l",
        "outputId": "e3c3ba7e-78cb-4d54-c4a6-9f1ad942c88d"
      },
      "source": [
        "pairs[0]"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree',\n",
              " 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian']"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sw8gOHsqlb9y"
      },
      "source": [
        "For a better viewing experience we will do the extra work of adding axes\n",
        "and labels:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alLDfnQHlYti"
      },
      "source": [
        "# attentions.numpy()"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3nejK_blb9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "9d0c056b-5eb5-406d-8182-3647d4daefc9"
      },
      "source": [
        "%matplotlib inline\n",
        "def showAttention(input_sentence, output_words, attentions):\n",
        "    # Set up figure with colorbar\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Set up axes\n",
        "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
        "                       ['<EOS>'], rotation=90)\n",
        "    ax.set_yticklabels([''] + output_words)\n",
        "\n",
        "    # Show label at every tick\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def evaluateAndShowAttention(input_sentence):\n",
        "    output_words, attentions = evaluate(\n",
        "        encoder1, attn_decoder1, input_sentence)\n",
        "    print('input =', input_sentence)\n",
        "    print('output =', ' '.join(output_words))\n",
        "    showAttention(input_sentence, output_words, attentions)\n",
        "\n",
        "    print(attentions.shape)\n",
        "\n",
        "\n",
        "evaluateAndShowAttention('car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree')\n",
        "\n",
        "# evaluateAndShowAttention(\"elle est trop petit .\")\n",
        "\n",
        "# evaluateAndShowAttention(\"je ne crains pas de mourir .\")\n",
        "\n",
        "# evaluateAndShowAttention(\"c est un jeune directeur plein de talent .\")\n",
        "\n",
        "# 'gongjiaochezhanxiangguan meirongmeifadian kuaicanting gongchang weixiuzhandian zhongcanting motuocheweixiu qingzhencaiguan meirongmeifadian meirongmeifadian'\n",
        "# linjieyuanmen linjieyuanmen linjieyuanmen shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = car tree tree car treecar tree tree tree treecar tree tree tree treetree tree tree tree tree\n",
            "output = linjieyuanmen linjieyuanmen linjieyuanmen shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([11, 50])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "et0fsLa5lKQn",
        "outputId": "b2d1fbd1-6e5b-4d82-b10e-cbe839e949fb"
      },
      "source": [
        "evaluateAndShowAttention('car tree tree car tree land vehicle truck house')\n"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input = car tree tree car tree land vehicle truck house\n",
            "output = shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo shenghuofuwuchangsuo <EOS>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc0AAADnCAYAAAB8BQ35AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZwdVZn/8c83GwkJixjcCAIiiEH2AL40DCioESW4jRhxBCSiOLiMK44O+gNGhkUdFVSWAUTjAowwYVEQEZBFIawhYZFNVpWAuLFkuc/vj3NuunL73r51u2/3rU6+b171St/qOlXVRZInp85znqOIwMzMzNob0+sbMDMzGy0cNM3MzEpy0DQzMyvJQdPMzKwkB00zM7OSxvX6BszMzOpmzZoVS5YsKXXsjTfeeElEzBrmW1qFg6aZmVXGkiVLWLBgQaljJU0d5tvpx0HTzMwqpcr1Axw0zcysMgJYUav1+jZactA0M7MKCQL3NM3MzNoLqFU3ZjpomplZtXhM08zMrIQAag6aZmZm5binaWZmVkJEOHvWzMysLPc0zczMSvKUEzMzsxJSIlCv76I1B00zM6sUv541MzMrw4lAZmZm5QTuaZqZmZXm4gZmZmYluadpZmZWilc5MTMzKyW8yomZmVl5NWfPmpmZtedVTszMzDrgRCAzM7MyItzTNDMzK8s9TTMzsxICWOGgaWZmVo57mmZmZiU5aJqZmZUQTgQyMzMrzz1NMzOzkhw0zczMSkjZs9Utozem1zdgZmZWVItyWzuSZkm6S9I9kg5v8v2XSvqVpJsl3SZp73bndNA0M7PqiCBKbgORNBY4CXgzMB2YI2l6w2FfBM6OiB2A9wDfbnd7DppmZlYZAV0JmsAuwD0RcV9ELAV+DOzb5HLr5q/XAx5td1KPaZqZWaV0acrJRsBDhc8PA7s2HPNl4FJJHwUmA3u1O6l7mmZmVikd9DSnSlpQ2A7p8FJzgDMjYhqwN/B9SQPGRfc0zcysMiKCFeUXoV4SETNafO8RYOPC52l5X9HBwKx83eskTQSmAn9qdUH3NM3MrFKi5H9t3ABsIWkzSRNIiT7zG455ENgTQNIrgYnA4wOd1EHTKk3SJEmvGOI5JOn8/IfCzCquG1NOImI5cBhwCXAHKUt2kaQjJc3Oh30K+KCkW4EfAQdGmwwjv561ypK0D3ACMAHYTNL2wJERMXvglv28EdgZmEv6Q2JmFVXPnu3KuSIuBi5u2HdE4evFwGs7Oad7mlZlXyaljT8FEBG3AJsN4jwHkwLmPpL8D0WziuvSlJNh4aBpVbYsIv7SsK+jPymSpgJbR8TPgMuAt3Xr5sxsGOREoDJbLzhoWpUtkvReYKykLSR9C7i2w3P8C2msAuAMUo/TzCqqi8UNhoWDplXZR4GtgedIge+vwCc6PMcHSMGSiLgBeLGkjQduYma9VMtrarbbesHjO1ZZEfE08IW8tSVJwP7AyyLiSEmvAi6MiOLcrE+T5mE91OwcZtZ7JaaT9IyDplWOpAsYYOxygOzZbwM14PXAkaSJzHsBny+0/UX37tTMhkOFl9N00LRKOmGQ7XaNiB3zMj8fBK4AJuQe6OnAO4EHgAMi4uau3KmZdVXQtdqzw8JB0yonIq4EkDQZeCYirUibl/pZa4Cmy/IxAXwcuJDU85wDbEuarrID8E1gt2H7Acxs8DorozfinAhkVfZLYO3C50nAZZL6zdWUtDMpGJ4HvIA0bnkF8BXgrcBZEfFERFxGWs3AzCrI2bNmgzcxIv5e/5C/Xhv4X0kb1fdL2h04PSLmAZ8FjgGWkaaXXECqLXlZ4byTRuDezWyQqhw0/XrWquwfknaMiJsAJO0EPAN8DDg/l9nbkRQk95a0OXB/RJwkaV1SwHwOmB8Ri/I5dgfu68HPYmYleUzTbHA+AZwj6VFAwIuA/SLiRkkfAy4FngX2iojHJd0CzJD0cuBA4DRg24j4YOGcC4D9RvKHMLNOlFrBpGccNK2yIuIGSVsB9VVO/gv4UkqGBdKr2r8A/5P31SJiuaR3ACcCPwFulXRuPn4R8O2I+ONI/Qxm1pkITzkxG5Ckhaw6L3My8A9g3fz5k/nX3+Rff93iVMdJmgO8n1Ts/QZgLHBW/v5OwG8l7R8R13Tn7s2s26qcPeugaYMiaSawRUScIWlDYAqwUeO+iLi/XXtSkJsM1IsWrEMqVDAvf96n0DTy/sci4tl8rknAC4GDgA8D/0mq/PMR4FURUV94dr6k84CTgV2H+gzMrPs8T9NWO5K+BMwgvTY9AxgPXAnc2rDvBzRZq65J+z8C5wBrR8QOhUO3lXRTRBzU0H4B8JrCrhXAORGxMylJCEn/EREXARcV20bELZLWGeSPbmYjoFeZsWU4aNpgvJ1UJOAmgIh4NPcsZzfsaxWcmrVfB6hJem391WnOdN1A0r+z6u/VcRGxtP4hIpZKmiDpfvpe806T9ABpnPNl9WMlbYCnWplVVw+nk5ThoGmDsTQiQlLAyso90WRfJ+0hLRZ9uqT1SNmyzwOuA5aTpo7UPS5pdv21q6R9gSWkmrMUznUYcGUheO8EHAt8fbA/uJmNAAdNG41ySbqzImL/hm+dLelkYP1c4/UDwCVN9p0maV7J9qdGxI3AdjloAlwTEW9qcl/nA/MknUgKrg8B74+IJwqHHSdpMWlJsbeSeqCLgaMj4oLBPhMzG361FQ6aNgpFxApJm0ia0PA69ARJbyCtb/kK4IiI+EWLfVd30H4tUlH1TUm/N5+VdGJEHNZwX/cCr5Y0JX/+O4CkHQuHjQGmAfdFxHbdfTJmNlzSlBMHTRu97gOukTSfNA2k7n9Jr2Qvk7R2fgV6d5N9nbQ/hzTv8p9IPcMxwKE5wD5H6lUGcG7hPBTmbb6usPuVpIpA75Z0bER8rnD8pRHxxqE8FDMbPg6aNprdm7cxpKkgkErXzQE2ADYnTTWZD/y9Yd93gatKtv8u8MKImCVpkzb39K7C1xNJr1/viIiVQVPSzfVKQDnofq7QZsOSP7uZjTgnAtkoFhH/r3FfLle3C/DbfMzvJG0KrNew7wUdtH8BcK2kbSJiYeHYfvNBI+KrDec7gTSmuh7wJVJPdUtJXyUtRt3vx+rwMZjZCIpadf+IOmjagHKg+iywNalXB7BZnuZRP2Yc6VVrv32dtAdmAgfmqSPPkQoWTAL+wMBzP9cmjV+eDtwOvBv4Rd5/HjBJ0g6k17vCq5yYVZbHNG20m0eq4fpWUrWdA4DJee7kpPzq8yOkGq+N+y7ooP0FwCkN174Y2Bs4H/rmczaU3RtLet16JDA3It4JIOlBYCtSEYUFwNcK5/1DNx6MmQ2PcBk9G8WeHxH/I+njEXElad7jDcDjwELgQ6Tgdhpp/crGfQvKto/8z8v8qnYiaU3MyFtxPudbC/e3HPhjLtS+v6SZEXF1RLxO0muBE4pjnWZWfRXuaDpoWlvL8q+PSXoLqZe2XUScCpwKK+dz3hERW9X31Ulq275w7Gzgq8BLgD8BmwC3AE8V534Cl+RrNToU+F5hnudTwNEN13gpsCIiHunsMZjZiIjwmKaNakfnIPQp4FuklUdukvTSiHgQVs7nvKu4r5P2BUcBrwYui4gdJH0bmE5arWRL+uZz7tmi/R3AcaSM3PWBvwGnSPpZRNSnu5wG/DvgoGlWUR7TtNHsn4GrI+J24HW5dutiYJGk6+mbe/naJvsA/lyyPcCyiHhC0hhJY0iF3D9AGrf8CXBbPu55LdpPIPUub6IvKN5GSgw6I/cyN4yIBUN8JmY2TAIHTRvdto2Ip+ofIuLJXIhg78IxItV9fUvDvmOBjUu2P5b0GnYKaW7nPNIr2puAfwX2I42HPkzf3MzG9pMjYlbx5iVdREowqi9BdkbHT8DMRpSDpo1mYyQ9LyL+DH2rhOSknpUkjW2ybxJp2kmZ9pNIgfdZ4N+A/UnzPo8kTTX5A/AE8AJgeYv2/eZ5RsSdSrYE3gPsNsTnYWbDKYJY4exZG72+Clwn6RzSKiGvB5BUf1W6ASmQjSnsg1T95xrg0jbtVx5bGHeElNDzEVK5vQ1JJfYuA94BvKKh/Vak17TjgIMk3ceqZfe+RhrLXFgP3mZWXe5p2qgVEWcpLfr8euByUgA6GDg8H7IOaczx8MI+gL9FxJOwctHoVu0hFSSYLemvDZdfizTOOSWfZz3S69VjGtqvR6pZ28rjwDdoXh3IzCqmwjHTQdPai4jFpOSdusuaHDZnCO1bLVbdeJ6/kIJjy2sNYL32h5hZrzkRyMzMrCyX0TMzMysrqFU4EWhMr2/ARg9Jh5TZ18mxQ20/ktda09uPpnvtdfvRdK/D1X4oIqLU1gsOmtaJZn84Wv2BKXvsUNuP5LXW9PYjea3R3n4kr1XV9oNSX+WkG0FT0qxcreweSYe3OObdkhZLWiTph+3OOaigKekBSVMH07aDa5wp6V3tjyx1rt3yA7klz+cbESPxnMzMVjspcrbfBqBUE/sk4M2kcpxzJE1vOGYL4PPAayNia+AT7W5tTRnT3B84JiJ+0OsbGW0kxUCfW+3r26+GfWNCq+5izJgxAf0H/zu/Vvl907fZZuW+F2+0EVtvu20sXriw6bHDcf3R2n403Wuv24+me+1i+yURsWGzc3UiujOkuQtwT0TcByDpx8C+rJrJ/0HgpPr87Yj4U7uTtu1pSpos6SJJt0q6XdJ++VsflXSTpIWStioce7qk6yXdLGnfvP9AST+V9HNJv5N0XOH8B0u6O7c5VdKJhcv/k6RrJd1X73VK2kPShYX2J0o6MH+9Z77uwnwfa0maS6o9epSkea3aS9pZ0k/zvn0lPSNpgqSJSpPlkXSFpBn566mSHshfj5V0Qn4+t0n6aOFnaPacdpF0Xb7XayW9YrDPSdI/5+veKumqwnlOLLS9UNIe+es5+V5ul3Rsu///QzVu3PjCNoFx48YzfvxaK7cJEyau/Foa028bM2Zs063ZsaxcY7q4NfeTiy9auV36m+v4ycUXdfRzNb++2Rrv9904SQevZ6dKWlDYiq+KNwIeKnx+OO8r2hLYUtI1kn4jaRZtlOlpzgIejYi3AChNMD+W9C+KHZWqtnyatJbiF4DLI+IDktYHrpdUn5O3PbADqVLLXZK+BawA/gPYkbQixeXArYVrvxiYSar4Mh84t9VNSpoInAnsGRF3SzoLODQi/lvSTODCiDi3HjyauDnfI6RSa7cDO+dn9Ns2z+gQYFNg+7yu4waF7zV7TncCu+Vj9wK+ArwzH9/pczoCeFNEPJKfeUuSXkL6f7cTqZD6pZLeFhHnNxx3CF0epzAzKyWCWvlFqJdExIwhXG0csAWwBzANuEqpFOdTrRqU+efxQuANko6VtFueYA7w0/zrjaSAAfBG4HBJtwBXkAprvzR/75cR8ZeIeJbUPd6E1H2+MiKejIhlpFJpRedHRC1Pjn9hm/t8BXB/RNydP38P+KcSPx8AEbEcuFfSK/N9fS233w34dZvmewEn53NQr4STNXtO6wHnSLod+DqwdeH4Tp/TNcCZSutNjm1znzsDV0TE4/le59HkGUXEKRExY4i/Gc3MOlYvbtCFRKBHgI0Ln6fRf0nAh4H5EbEsIu4H7iYF0ZbaBs0chHYkBc+jJR2RLz45H7KCvh6rgHdGxPZ5e2lE3JG/91zhtMU2rcwk9bjq6u/aljfc98R2PwOpNurXczAfM0D7q0iDxstIVWtm5q0eNIvXLnPdVs/pKOBXEfEqYJ+Gc3X0nCLiw8AXSb85bpT0fAb3jMzMei8galFqa+MGYAtJm0maQFqwYX7DMeeTepkoJW1uCdw30EnLjGm+BHg6J9EcTwqgrVxCGsNTbrvDAMdC+qF2l/Q8SePoe0U5kN8D0/N45frAnnn/XcCmkl6eP/8LUF8JY3PgpxGxPfC7Fu0hBcdPANdFxOPA80k92Nvz9x8gvdoEKGb2/gL4UP4ZaHg928x69P2L58C2P/EAz0nS5hHx24g4glRjdeN8n9srrUu5MamnCnB9Ps9UpcyyOfQ9o2GxfPnSftvSpc823SJq/bZabUXTrfm/OpttzT1/yjr9tk40u9eRVX78dmjnbHXeXl9/NOnkZ2r1DIbSvhvHjrAuZM/mt2mHkeLSHcDZEbFI0pGSZufDLgGekLQY+BXwmYh4YqDzlhnTnAH8QNJ40t9CR5HWMpybx+PWBeqvI79Kel34jxw46+OCM0kLEP+cFMCUf6hHJF1JWmx4KfAofT0zSMHtWuBF9L163JzUk7oduB+oATMj4kxJ3wRuU8rKeJAUwOeSXou+J/9L4tRm7SUtIgXMFwLLJD1Den25BLgXeBmwLSnoHEIaV5yW7+l00ljl35WyyC4kLd5Mi+d0QX6m3yctd1X/3TqY5/RDSdvl/zdPksY6DyAF/MWk3yzLSOOtV0iaT3olAXBLRPwfZmaV0b3CBRFxMXBxw74jCl8H8Mm8lVJmTHM88JOImBQRawPfJv2l+1BE7Ega+6sv0/Qp4Oh83IuB9SRNBq4mBYD9gG3yOe/Nvdg9SEFxKukv+nrK79Wk5Z5mkoJ08V30nRGxRUS8EfgZcHVOBPo4KThMBH4DHBwRpwE/Av41IvZv1Z6UCLRtRKxFKiB+O2lFjePpSwR6GpgTETuQVtqoB5+DSb27KRExCfhQ3t/qOZ0LrJOf00GF8w/mOa0NbJ6vu3X0/W77RURsFRFvB64Dbsnn2ZfUG50CPC3pbZiZVUitFqW2XqhCIlA9G/QWUqAqvk92IlD759T1RCBJh9RTuNucz8ysq6J7Y5rDYrCJQNCXsDLURKAb87FbkRYcLiq2GUoiUNFA7budCATNn9NgEoGaPqfhSARy9qyZ9VKXsmeHxWATgaYBzZJdupkINBN4dZM2g0kEKmbP/qFFe+h+IlCr57TGJAKZmXWqykGzTCLQNsDxkmqkHtihpDHGZo4C/pu+ZJz7Bzi2nuDyFdJf5k+SJv3/pdXxuc1Dks6mL5Hn5rz/WUkHkV57jiMFmu/mZvXs2Y8DNGuf/Zb0Gviq/Pk24EWFccITgLNzIlCxhMxppFTl2yQtIyUbFSsbNToO+J6kLzacp9XPPNBzOl6pfqKAX9JX9OB++hKBbsrneUypaPGv8vEXjdZEIDXW4qOzNfgmjh/fzdvpgeH4C6OTc/b6+qPJUH+u4fr/UtXn3buAWEaZoHk1qRTRNGASKQA9DOwvaR9Ssko9U3RM/vxM/vXUwnleUsgKPS8irijcQ5D+Et8DWFS47oRC9uyBkMroAdMjYov8eaDgRM6e3RCYXcie7dde0s7A5yNiLeUyeqQe4RhJ90XEy0hB+AMRsSCf6335MkHKwq2xau52q+e0gpQ1OxF4PfCmITynHwFfyufcISJCqazgn/OrXFQoG2hmVmmrwSLUw11G7xjS9JB18/0UE4FcRq/9c3IZPTNbbQQQK6obNKuQPXt+RGyTe0WNBcSdPdv+ObmMnpmtVqo8pukyei6jZ2ZWHSUDZmWDZovs2VZcRg+X0RsJQ/0D9LzJk/ttZr1XvhTk6mxUz9MkldH7U06MOZu+8b25km4CfkyqSgOpjN5epDJ6zwCn5P0zgTcrrxNJGqMkIh4h/aX9R+Ap0hhmcZrJdOX1NGleRu9s+sroPQvUy+g9C7wGOF2rltGb16p9TgRqLKN3Oynh5t587W2BT0q6mRScimX0NiWV0XsGOLnwMzR7TvUyek+TqgnVe5ODeU4/lPRsvu5LSNmzL6evjN436Suj9xhpbPhhUrWlKaM1e9bMVl+juqeJy+itcWX05IpAZtYjXVwabFhUIRHIZfQqVkbPiUBm1jMRRK1WausFl9FzGT0zs0qJWrmtF1xGz2X0RmUi0FD99Zln+m1mVg1Vfj3rMnouo+dEIDOrjtWgIpDL6LmMnpnZiKgnAlWVy+j1cRm9vuNcRs/MeiSorejRgGUJVciedRk9l9EzM0ui2mOaLqPnMnpmZtUSUW7rAZfRcxm9NTJ79rlly/ptZtWkJls3jh3K9btx3tYqHDNdRg+X0XP2rJlVxupQEchl9FxGz8xsZMToL9juMnrVSARyGT0zWwMEtVqt1NYLVUgEalVGz4lALqNnZmugUf161olATgRaHY0bO7bfZlZNnayxORzrcTY75zAHrApnApUpbjCDlLQynvSkjiKNMc7NE/PXJZV2g5QIdA0pEUj0FQiYCbyuUOlGsLI8XD3BZSnwKH09M8iJQKSxvGaJQPfTlwh0pqR6ItAYUiGAjzYkAtUrAvVrL2kR/ROB5gFLSIlALyMlAu2eJ/9fzqqJQHNJiUABXEhf9Z9mz6meCPR9UmWgei96MM/ph5K2y/9vniQlAh1AXyLQHfQlAl0hqZ4IBHCLE4HMrEoij2lWlROBnAjkRCAzq5QKdzSdCFTnRKA+TgQys94pN55Z2THNFolA4PU0vZ6mmVm3BaM7e7ZFIpDX0/R6mmZmXRdUe56m19P0epqjNBFoaH9g1p00qcneZqXBqpuQYLa66tWr1zK8nqbX0zQzq5AeZvmUUCYRqL6e5nZ5DO7nef+SnBX6HdI6kdC3nuYuwOtIvaD61Ijt6csK3U/SxvnV7zGkcbyB1tN8K/BfA92k+tbT3C8itsnnOjRnz84HPlPInm2m1Xqau9LZeprbkhJs6po9p/p6mjuQ1sP8SuH4Tp9TfT3N7YDZA92k+tbTfH2+zs7OnjWzShntS4Ph9TSrkj3r9TTNbI1QWxGltl6oQhm9VlxGz+tpmtkaZtSvctIie7YVl9HDZfRGgxW1Wr9t3Ljx/TYzG2GrwetZr6fp9TTNzEZI94obSJol6S5J9+SZA62Oe6ekkNR2SMpl9FxGz4lAZlYp3Qia+W3aSaQht+nAHEnTmxy3Dil2tEv4BKqRCOQyei6jZ2a2UpeKG+wC3BMR90XEUtLbvn2bHHcUKbny2TL3VoVEIK+n6TJ6ZmZA3yonJYPm1PpbsbwdUjjVRqQaA3UP530rSdoR2Dgi2haZqXMikBOB1shEoGbraS5fvqzfZmYjr4PXs0vqb8Xydkq7c9cpVa37GmlYsTQnAjkRyIlAZlYhXUsEeoT093TdNFbNjVkHeBVwhaQHSH+nzm+XDOREICcC9UsEMjPrmc5ezw7kBmALSZtJmgC8h9RpSJdJuSNTI2LTiNiUFDNmR8SACZBOBMqcCNTH2bNm1kvd6Gnmv+MOIw0b3gGcHRGLJB0pacCSowNpW7A9Iu7Og6V7kxKBfpm/NdB6mncVzyFpVwZOcDkgH/cx0mohdb1eT/NMUiD6TJO23VhP8+2SNiX9A6Px+MY2TZ9TRHw4P9+3kBKBdmrzM7aVxwVOydeqbuVkM1vt1CsCdeVcERcDFzfsO6LFsXuUOeeakghUpj1UKBFI0hWkV7KnAf8JvKvwnA4jrZ5yp6RbgfGFRKD3koq4HyBpcZ7Q60QgMxslgqjVSm29UOb17DbA9fmV65eAowc49ijSONxtkhblzy3lBJf6OpHXkIJS2/U0SQk89USeletpksYHz5G0kJTg892y7bNm62kuLIwTngAcmhOBphbanQY8mH/uW0mBayDHAcfk8xR7+2MbPt8MzI2IrYF/Iz2nRaRgfkaefvIEcLmkO0nv5D9PWsXk/Hy+PUnraU7JiUD19TRvJfVe18hEoOUrVvTbJkxYq99mZiMsIGrltl5Qt7rBg74BaUpE/D33oM4DTo+I83p6UyMsj6POBd4BvCMibs49zU/XB6ULz+nXpGB4fP05Sar/4+TrpGXHNomIZxqu8WFSD/UM4Kzcky5zb6vl69nnlvWfTrLO5HX67Vu6tNR8ZzNLbowhFkXZYIMXxV5veH+pY885+/ghX69TZXqaw+3LuRd7O3A/qYe02pM0WdJBkq4mLYy9mJS9W+z5zpN0S34+l+dfX0PqARef0wJS5uyTpOyw30v6kaT981wkIuK7pPHatYGrJJ2rVJex3+8BJwKZWS91acrJsGibCDTcIuLT7Y9aLT1GCn5zI+LOFsfs35j+LOlJ4HPR4ndMRMyVtA0po/fTwBvI46b51fRRko4mBdDTSQF3dsM5nAhkZj3RzUSg4VCFnuaa6l2kZKCfSjpC0iYl2y2mLxmpbifSWCcAEbEwIr5OCpirJFdJ2oU01/abpDHdzw/u9s3MhkEEtRW1Ulsv9LynuaaKiEuBS5Vqxb4P+D9JS0g9zwcGaHoccKykWRHxhKTtST3JXSVNAWZExBX52O1J2cJIeiMpkekPpMSlj0cqYtzOkvo5SMlPSxq+32xfJ8cOtf2grrXW+PGljx2O64/S9qPpXnvdfjTdazfbl/3H/8Aq3NN00OyxiHgC+AbwjdwLXFH49rxcHg9SjcW9ImK+pI2Aa/Or078B74uIx5SWuPmspJOBZ0gVlQ7M7Z8A9omI39OBiNiw/rWkBY2D7s32dXLsUNuP5LXW9Paj6V573X403etwtR+KwEHTSoiI6wtf7zHAcd8BvtNk/99IRSiatbmxC7doZjasIqo9pumgaWZmFRJEryZhluCgaZ1otuxOq6V4yh471PYjea01vf1IXmu0tx/Ja1W1/aBVuafZ8+IGZmZmdeuv/4KYOfNd7Q8ELrroOyNe3MA9TTMzq4xUuMCvZ83MzMqp8BtQB00zM6sUTzkxMzMrqcq5Ng6aZmZWIUGttqL9YT3ioGlmZpXh4gZmZmYdcNA0MzMryUHTzMyslPCUEzMzs7ICFzcwMzNrKwJqNQdNMzOzEsJjmmZmZmW59qyZmVlJ7mmamZmV5KBpZmZWRnjKiZmZWSkB1MK1Z83MzEpw9qyZmVlpDppmZmYlOWiamZmVkPKAPE/TzMyshCBcRs/MzKycwK9nzczMSqnymOaYXt+AmZlZnyCiVmprR9IsSXdJukfS4U2+/0lJiyXdJumXkjZpd04HTTMzq4yUCBSltoFIGgucBLwZmA7MkTS94bCbgRkRsS1wLnBcu/tz0DQzs0rpRtAEdgHuiYj7ImIp8GNg34br/Coins4ffwNMa3dSj2mamVmldLAI9VRJCwqfT4mIU/LXGwEPFb73MLDrAOc6GPhZuws6aJqZWYUElJ+nuSQiZgz1ipLeB8wAdm93rIOmmZlVSpemnFXx+iIAAAHwSURBVDwCbFz4PC3vW4WkvYAvALtHxHPtTuqgaWZmlVFPBOqCG4AtJG1GCpbvAd5bPEDSDsDJwKyI+FOZkzpomplZpXQjaEbEckmHAZcAY4HTI2KRpCOBBRExHzgemAKcIwngwYiYPdB5HTTNzKxComu1ZyPiYuDihn1HFL7eq9NzOmiamVmldJA9O+IcNM3MrDK6OKY5LBw0zcysQiJFzopy0DQzs0oJ/HrWzMysFL+eNTMzKyWcCGRmZlZGSgRy0DQzMyvFr2fNzMxKctA0MzMrxVNOzMzMSuvSKifDwkHTzMwqIwJqtRW9vo2WHDTNzKxCwmOaZmZmZTlompmZleSgaWZmVpKLG5iZmZURnnJiZmZWSgA19zTNzMzK8etZMzOzUjzlxMzMrDQHTTMzsxJSHpCDppmZWQlBuIyemZlZOS7YbmZmVpJfz5qZmZXkoGlmZlZCRHieppmZWVnuaZqZmZVUq7mnaWZmVo57mmZmZmUEgXuaZmZmbbkikJmZWQccNM3MzEpy0DQzMyslqLn2rJmZWXse0zQzM+uEg6aZmVkZ4VVOzMzMynLtWTMzs5JcRs/MzKycS4CpJY9dMpw30oyqnKVkZmZWJWN6fQNmZmajhYOmmZlZSQ6aZmZmJTlompmZleSgaWZmVtL/B5j2aM2I5LhXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QM_7QOcvlb9y"
      },
      "source": [
        "Exercises\n",
        "=========\n",
        "\n",
        "-  Try with a different dataset\n",
        "\n",
        "   -  Another language pair\n",
        "   -  Human → Machine (e.g. IOT commands)\n",
        "   -  Chat → Response\n",
        "   -  Question → Answer\n",
        "\n",
        "-  Replace the embeddings with pre-trained word embeddings such as word2vec or\n",
        "   GloVe\n",
        "-  Try with more layers, more hidden units, and more sentences. Compare\n",
        "   the training time and results.\n",
        "-  If you use a translation file where pairs have two of the same phrase\n",
        "   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n",
        "   this:\n",
        "\n",
        "   -  Train as an autoencoder\n",
        "   -  Save only the Encoder network\n",
        "   -  Train a new Decoder for translation from there\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtVB34UC1Exk"
      },
      "source": [
        "尝试使用其他数据集\n",
        "另一对语言\n",
        "人类→ 机器（如物联网命令）\n",
        "聊天→ 回应\n",
        "问题:→ 答复\n",
        "用预先训练过的单词嵌入替换嵌入，如word2vec或GloVe\n",
        "尝试使用更多的层次、更多的隐藏单位和更多的句子。比较训练时间和结果。\n",
        "如果使用一个翻译文件，其中对具有两个相同短语（I am test\\t I am test），则可以将其用作自动编码器。试试这个：\n",
        "作为自动编码器训练\n",
        "仅保存编码器网络\n",
        "从那里训练一个新的译码器进行翻译"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "scADqDy2fiT5"
      },
      "source": [
        "最后一部分我们来进行精度验证 基于rouge的方法"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5s6KhzCfwJG"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import keras \n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "text = [' '.join(catetypes)]\n",
        "tokenizer.fit_on_texts(text)\n",
        "\n",
        "keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences([\"下 雨 我 加班\"]), maxlen=2,padding='post',truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uGlJQMqti5N"
      },
      "source": [
        "types=['中国人民银行',\n",
        " '加油站',\n",
        " '教堂',\n",
        " '奇瑞维修',\n",
        " '洗浴推拿场所',\n",
        " '商业贸易',\n",
        " '加水站',\n",
        " '赛马场',\n",
        " '殡仪馆',\n",
        " '现代维修',\n",
        " '中国移动营业厅',\n",
        " '旧货市场',\n",
        " '兴业银行ATM',\n",
        " '湖泊',\n",
        " '住宅区',\n",
        " '玛莎拉蒂维修',\n",
        " '消费者协会',\n",
        " '德国菜',\n",
        " '特色/地方风味餐厅',\n",
        " '认证事务所',\n",
        " '大家乐',\n",
        " '出租车',\n",
        " '国家级机关及事业单位',\n",
        " '特殊买卖场所',\n",
        " '普通商场',\n",
        " '东风标致维修',\n",
        " '一汽大众销售',\n",
        " '汽车俱乐部',\n",
        " '证券公司',\n",
        " '福建菜',\n",
        " '卫生院',\n",
        " '东风悦达起亚维修',\n",
        " '麦德龙',\n",
        " '广告装饰',\n",
        " '吉利销售',\n",
        " '英菲尼迪销售',\n",
        " '地税机关',\n",
        " '进口现代维修',\n",
        " '苏宁',\n",
        " '城市广场',\n",
        " '福田卡车维修',\n",
        " '出入口',\n",
        " '邮政速递',\n",
        " '社区中心',\n",
        " '国美',\n",
        " '林肯维修',\n",
        " '兽医站',\n",
        " '临街院门',\n",
        " '中国建设银行',\n",
        " '桥',\n",
        " '公园广场',\n",
        " '妇科医院',\n",
        " '阿迪达斯专卖店',\n",
        " '一汽丰田销售',\n",
        " '传染病医院',\n",
        " '吉利维修',\n",
        " '迪厅',\n",
        " '本田讴歌维修',\n",
        " '游泳馆',\n",
        " '糕饼店',\n",
        " '屈臣氏',\n",
        " '湖北菜(鄂菜)',\n",
        " '溜冰场',\n",
        " '公安警察',\n",
        " '宠物诊所',\n",
        " '山',\n",
        " '中国农业银行ATM',\n",
        " '一汽大众奥迪销售',\n",
        " '牛扒店(扒房)',\n",
        " '进口大众维修',\n",
        " '其它个人用品店',\n",
        " '交通车辆管理相关',\n",
        " '中国银行ATM',\n",
        " '台球厅',\n",
        " '家电电子卖场',\n",
        " '华夏银行ATM',\n",
        " '候车室',\n",
        " '广汽本田维修',\n",
        " '渔场',\n",
        " '马术俱乐部',\n",
        " '农副产品市场',\n",
        " '河流',\n",
        " '科研机构',\n",
        " '律师事务所',\n",
        " '乡镇以下级政府及事业单位',\n",
        " '广汽本田销售',\n",
        " '建筑物正门',\n",
        " '产业园区',\n",
        " '福田卡车销售',\n",
        " '中国工商银行ATM',\n",
        " '巴西菜',\n",
        " '沃尔沃维修',\n",
        " '站台',\n",
        " '公交车站相关',\n",
        " '充电站',\n",
        " '雷诺销售',\n",
        " '图书馆',\n",
        " '汽车销售',\n",
        " '候机室',\n",
        " '宝马维修',\n",
        " '公检法机关',\n",
        " '东风雪铁龙维修',\n",
        " '出站口',\n",
        " '羽毛球场',\n",
        " '档案馆',\n",
        " '三级甲等医院',\n",
        " '专科医院',\n",
        " '休闲场所',\n",
        " '综合市场',\n",
        " '中国电信营业厅',\n",
        " '新华人寿保险公司',\n",
        " '运动场所',\n",
        " '街道级地名',\n",
        " '货车销售',\n",
        " '广汽丰田销售',\n",
        " '文化用品店',\n",
        " '渣打银行ATM',\n",
        " '公共厕所',\n",
        " '品牌皮具店',\n",
        " '中信银行',\n",
        " '快餐厅',\n",
        " '郑州日产销售',\n",
        " '会计师事务所',\n",
        " '泰国/越南菜品餐厅',\n",
        " '天文馆',\n",
        " '一汽-大众奥迪销售',\n",
        " '东风本田维修',\n",
        " '家具建材综合市场',\n",
        " '体育休闲服务场所',\n",
        " '高等院校',\n",
        " '电视台',\n",
        " '地市级地名',\n",
        " '江淮维修',\n",
        " '城市快速路出口',\n",
        " '花鸟鱼虫市场',\n",
        " '彩票彩券销售点',\n",
        " '泰康人寿保险公司',\n",
        " '人渡口',\n",
        " '商务住宅',\n",
        " '东风销售',\n",
        " '公墓',\n",
        " '中国光大银行',\n",
        " '精神病医院',\n",
        " '甜品店',\n",
        " '道路附属设施',\n",
        " '交通管理机构',\n",
        " '维修站点',\n",
        " '报刊亭',\n",
        " '采摘园',\n",
        " '花卉市场',\n",
        " '学校',\n",
        " '工业大厦建筑物',\n",
        " '呷哺呷哺',\n",
        " '梅赛德斯-奔驰销售',\n",
        " '户外用品',\n",
        " '高速加油站服务区',\n",
        " '雪铁龙销售',\n",
        " '露营地',\n",
        " '一汽解放销售',\n",
        " '马自达维修',\n",
        " '上海大众销售',\n",
        " '凯迪拉克维修',\n",
        " '生活服务',\n",
        " '肯德基',\n",
        " '林场',\n",
        " '外地政府办',\n",
        " '外国机构相关',\n",
        " '网络科技',\n",
        " '摩托车销售',\n",
        " '科技馆',\n",
        " '药房',\n",
        " '招商银行ATM',\n",
        " 'DS维修',\n",
        " '沃尔沃销售',\n",
        " '小学',\n",
        " '名爵销售',\n",
        " '医药保健相关',\n",
        " '杂志社',\n",
        " '公用电话',\n",
        " '中国进出口银行',\n",
        " '法国兴业银行',\n",
        " '马自达销售',\n",
        " '华夏银行',\n",
        " '日本料理',\n",
        " '陵园',\n",
        " '吉普维修',\n",
        " '综合体育馆',\n",
        " '专用停车场',\n",
        " '火车站',\n",
        " '疾病预防',\n",
        " '岛屿',\n",
        " '综合家电商场',\n",
        " '公交卡/月票代售点',\n",
        " '中国邮政储蓄银行ATM',\n",
        " '保龄球馆',\n",
        " '长途汽车票代售点',\n",
        " '雷克萨斯销售',\n",
        " '外国使领馆',\n",
        " '货运火车站',\n",
        " '传媒机构',\n",
        " '中介机构',\n",
        " '体育休闲服务',\n",
        " '麦当劳',\n",
        " '学校内部设施',\n",
        " '上海浦东发展银行ATM',\n",
        " '云贵菜',\n",
        " '妇联',\n",
        " '雪佛兰销售',\n",
        " '停车场出入口',\n",
        " '雷诺维修',\n",
        " '雷克萨斯维修',\n",
        " '医疗保健服务',\n",
        " '进口大众销售',\n",
        " '收费站',\n",
        " '电力营业厅',\n",
        " '机场相关',\n",
        " '果品市场',\n",
        " '楼宇相关',\n",
        " '中式素菜馆',\n",
        " '福特维修',\n",
        " '观致销售',\n",
        " '保险公司',\n",
        " '道路名',\n",
        " '中国人民保险公司',\n",
        " '违章停车',\n",
        " '珠宝首饰工艺品',\n",
        " '海鲜酒楼',\n",
        " '中国农业银行',\n",
        " '博物馆',\n",
        " '壁球场',\n",
        " '法拉利维修',\n",
        " '住宿服务',\n",
        " '宝马销售',\n",
        " '中国太平洋保险',\n",
        " '动物园',\n",
        " '礼品饰品店',\n",
        " '斯巴鲁维修',\n",
        " '别克维修',\n",
        " '诊所',\n",
        " '慈善机构',\n",
        " '斯巴鲁销售',\n",
        " '酒吧',\n",
        " '青年旅舍',\n",
        " '小商品市场',\n",
        " '工商部门',\n",
        " '退票',\n",
        " '国家级景点',\n",
        " '停车场入口',\n",
        " '棋牌室',\n",
        " '耳鼻喉医院',\n",
        " '眼镜店',\n",
        " '购物服务',\n",
        " '交通银行',\n",
        " '女洗手间',\n",
        " '宝马MINI维修',\n",
        " '植物园',\n",
        " '星巴克咖啡',\n",
        " '江苏菜',\n",
        " '寺庙道观',\n",
        " '便民商店/便利店',\n",
        " '肿瘤医院',\n",
        " '典当行',\n",
        " '水族馆',\n",
        " '综合医院',\n",
        " '职业技术学校',\n",
        " '上岛咖啡',\n",
        " '中国邮政储蓄银行',\n",
        " '摩托车维修',\n",
        " '证券营业厅',\n",
        " '兰博基尼维修',\n",
        " '停车场相关',\n",
        " '成人教育',\n",
        " '社会治安机构',\n",
        " '上海银行ATM',\n",
        " '东风标致销售',\n",
        " '汇丰银行ATM',\n",
        " '一汽-大众维修',\n",
        " '劳斯莱斯维修',\n",
        " '东风货车销售',\n",
        " '乒乓球馆',\n",
        " '胸科医院',\n",
        " '票务相关',\n",
        " '高速路出口',\n",
        " '北奔重汽销售',\n",
        " '幼儿园',\n",
        " '荣威销售',\n",
        " '郑州日产维修',\n",
        " '游乐场',\n",
        " '冷饮店',\n",
        " '停车场出口',\n",
        " '旅馆招待所',\n",
        " '山东菜(鲁菜)',\n",
        " '公司',\n",
        " '美式风味',\n",
        " '加气站',\n",
        " '四川菜(川菜)',\n",
        " '购物中心',\n",
        " '人才市场',\n",
        " '中国联通营业厅',\n",
        " '医疗保健用品',\n",
        " '影剧院相关',\n",
        " '游戏厅',\n",
        " '道达尔',\n",
        " '中国民生银行',\n",
        " '立交桥',\n",
        " '农村商业银行',\n",
        " '婴儿游泳馆',\n",
        " '拍卖行',\n",
        " '汽车租赁还车',\n",
        " '旅游景点',\n",
        " '家禽养殖基地',\n",
        " '广汽三菱销售',\n",
        " '眼科医院',\n",
        " '台湾菜',\n",
        " '村庄级地名',\n",
        " '旅行社',\n",
        " '公园景点售票处',\n",
        " '中国光大银行ATM',\n",
        " '残联',\n",
        " '东亚银行',\n",
        " '男洗手间',\n",
        " '楼栋号',\n",
        " '手机销售',\n",
        " '电台',\n",
        " '中信银行(国际)ATM',\n",
        " '江淮货车销售',\n",
        " '经济型连锁酒店',\n",
        " '信息咨询中心',\n",
        " '婴儿服务场所',\n",
        " '培训机构',\n",
        " '特色商业街',\n",
        " '改签',\n",
        " '商场',\n",
        " '车辆通行证办理处',\n",
        " '室内设施',\n",
        " '中国人寿保险公司',\n",
        " '西餐厅(综合风味)',\n",
        " '观致维修',\n",
        " 'Pacific Coffee Company',\n",
        " '音乐厅',\n",
        " '美术馆',\n",
        " '中国银行',\n",
        " '脑科医院',\n",
        " '度假村',\n",
        " '英菲尼迪维修',\n",
        " '平安银行',\n",
        " '清真菜馆',\n",
        " '服装鞋帽皮具店',\n",
        " '矿产公司',\n",
        " '海滨浴场',\n",
        " '民主党派',\n",
        " '汽车维修',\n",
        " '工厂',\n",
        " '车渡口',\n",
        " '交通银行ATM',\n",
        " '菲亚特销售',\n",
        " '平安银行ATM',\n",
        " '公共设施',\n",
        " '船票代售点',\n",
        " '消防机关',\n",
        " '口腔医院',\n",
        " '茶艺馆',\n",
        " '法国兴业银行ATM',\n",
        " '客运港',\n",
        " '花卉苗圃基地',\n",
        " '金融保险机构',\n",
        " '公司企业',\n",
        " '售票',\n",
        " '城市快速路入口',\n",
        " '政府机构及社会团体',\n",
        " '服务中心',\n",
        " '浙江菜',\n",
        " '足球场',\n",
        " '银行相关',\n",
        " '上海菜',\n",
        " '捷豹销售',\n",
        " '港口码头',\n",
        " '克莱斯勒销售',\n",
        " '知名企业',\n",
        " '垂钓园',\n",
        " '地名地址信息',\n",
        " '夜总会',\n",
        " '安徽菜(徽菜)',\n",
        " '地中海风格菜品',\n",
        " '搬家公司',\n",
        " '宝马MINI销售',\n",
        " '建材五金市场',\n",
        " '蔬菜市场',\n",
        " '货车维修',\n",
        " '行业协会',\n",
        " '三星级宾馆',\n",
        " '地市级政府及事业单位',\n",
        " '中国平安保险公司',\n",
        " '国家开发银行',\n",
        " '长途汽车站',\n",
        " '东风雪铁龙销售',\n",
        " '美容美发店',\n",
        " '兴业银行',\n",
        " '印度风味',\n",
        " '政府及社会团体相关',\n",
        " '热点地名',\n",
        " '摩托车服务相关',\n",
        " '高尔夫相关',\n",
        " '飞机场',\n",
        " '区县级地名',\n",
        " '五星级宾馆',\n",
        " '汽车服务',\n",
        " '休闲餐饮场所',\n",
        " '李宁专卖店',\n",
        " '自行车专卖店',\n",
        " '回教寺',\n",
        " '陕西重汽维修',\n",
        " '一汽-大众销售',\n",
        " '隧道',\n",
        " '汽车服务相关',\n",
        " '电讯营业厅',\n",
        " '三菱销售',\n",
        " '进口起亚维修',\n",
        " '售票处',\n",
        " '中国石油',\n",
        " '度假疗养场所',\n",
        " '住宅小区',\n",
        " '专营店',\n",
        " '省级景点',\n",
        " '其它农林牧渔基地',\n",
        " '电影院',\n",
        " '家具城',\n",
        " '华泰财产保险股份有限公司',\n",
        " '餐饮服务',\n",
        " '轮渡站',\n",
        " '上海浦东发展银行',\n",
        " '中餐厅',\n",
        " '东亚银行ATM',\n",
        " '林肯销售',\n",
        " '中国石化',\n",
        " '医药公司',\n",
        " '评估事务所',\n",
        " '别克销售',\n",
        " '保时捷销售',\n",
        " '健身中心',\n",
        " '路口名',\n",
        " '整形美容',\n",
        " '摄影冲印',\n",
        " '北京华联',\n",
        " '法式菜品餐厅',\n",
        " '上海大众维修',\n",
        " '邮局',\n",
        " '交通设施服务',\n",
        " '四星级宾馆',\n",
        " '生活服务场所',\n",
        " '公证鉴定机构',\n",
        " '北京现代维修',\n",
        " '法拉利销售',\n",
        " '路边停车场',\n",
        " '陕西重汽销售',\n",
        " '丧葬设施',\n",
        " '机场货运处',\n",
        " '机场出发/到达',\n",
        " '科教文化服务',\n",
        " '车辆管理机构',\n",
        " '农场',\n",
        " '起亚销售',\n",
        " '耐克专卖店',\n",
        " '洗车场',\n",
        " '农村商业银行ATM',\n",
        " '广发银行',\n",
        " '购物相关场所',\n",
        " '中国建设银行ATM',\n",
        " '纪念馆',\n",
        " '综合酒楼',\n",
        " '商住两用楼宇',\n",
        " '汽车综合维修',\n",
        " '风景名胜',\n",
        " '高尔夫球场',\n",
        " '高速服务区',\n",
        " '一汽丰田维修',\n",
        " '宠物市场',\n",
        " '体育用品店',\n",
        " '汽车救援',\n",
        " '中国铁通营业厅',\n",
        " '意式菜品餐厅',\n",
        " '乐天玛特',\n",
        " '别墅',\n",
        " '北京菜',\n",
        " '建筑公司',\n",
        " 'DS销售',\n",
        " '冶金化工',\n",
        " '永和豆浆',\n",
        " '巴克莱银行ATM',\n",
        " '潮州菜',\n",
        " '老字号',\n",
        " '跆拳道场馆',\n",
        " '火车票代售点',\n",
        " '步行街',\n",
        " '汽车养护',\n",
        " '布艺市场',\n",
        " '验车场',\n",
        " '其它亚洲菜',\n",
        " '教会',\n",
        " '古玩字画店',\n",
        " '乡镇级政府及事业单位',\n",
        " '中国工商银行',\n",
        " '汇丰银行',\n",
        " '东风货车维修',\n",
        " '路虎销售',\n",
        " '少先队',\n",
        " '宿舍',\n",
        " '文艺团体',\n",
        " '六星级及以上宾馆',\n",
        " '电信公司',\n",
        " '驾校',\n",
        " '进口起亚销售',\n",
        " '红十字会',\n",
        " '社会团体相关',\n",
        " '广汽丰田维修',\n",
        " '外国餐厅',\n",
        " '品牌服装店',\n",
        " '现代销售',\n",
        " '东风悦达起亚销售',\n",
        " '土特产专卖店',\n",
        " '韩国料理',\n",
        " '家居建材市场',\n",
        " '检察院',\n",
        " '保时捷维修',\n",
        " '世界遗产',\n",
        " '数码电子',\n",
        " '骨科医院',\n",
        " '高速路入口',\n",
        " '北京现代销售',\n",
        " '自来水营业厅',\n",
        " '乡镇级地名',\n",
        " '通行设施',\n",
        " '临街院正门',\n",
        " '名爵维修',\n",
        " '玛莎拉蒂销售',\n",
        " '户外健身场所',\n",
        " '公园',\n",
        " '自动提款机',\n",
        " '东风日产销售',\n",
        " '商务写字楼',\n",
        " '国税机关',\n",
        " '三菱维修',\n",
        " '奇瑞销售',\n",
        " '货运港口码头',\n",
        " '江淮销售',\n",
        " '中国民生银行ATM',\n",
        " '物流速递',\n",
        " '凯迪拉克销售',\n",
        " '网吧',\n",
        " '剧场',\n",
        " '公共停车场',\n",
        " '洗衣店',\n",
        " '餐饮相关',\n",
        " '动物医疗场所',\n",
        " '摩托车服务',\n",
        " '银行',\n",
        " '沃尔玛',\n",
        " '儿童用品店',\n",
        " '高速停车区',\n",
        " '东风维修',\n",
        " '梅赛德斯-奔驰维修',\n",
        " '中信银行ATM',\n",
        " '地铁站',\n",
        " '宾馆酒店',\n",
        " '科教文化场所',\n",
        " '高尔夫练习场',\n",
        " '钟表店',\n",
        " '政府机关相关',\n",
        " '飞机票代售点',\n",
        " '火锅店',\n",
        " '西北菜',\n",
        " '一汽-大众奥迪维修',\n",
        " '广发银行ATM',\n",
        " '省直辖市级政府及事业单位',\n",
        " '品牌鞋店',\n",
        " '二手车交易',\n",
        " '财务公司',\n",
        " '法院',\n",
        " '卜蜂莲花',\n",
        " '厨卫市场',\n",
        " '广东菜(粤菜)',\n",
        " '水产海鲜市场',\n",
        " '专利事务所',\n",
        " '红旗维修',\n",
        " '网球场',\n",
        " '自然地名',\n",
        " '共青团',\n",
        " '斯柯达维修',\n",
        " '招商银行',\n",
        " 'KTV',\n",
        " '茶餐厅',\n",
        " '书店',\n",
        " '娱乐场所',\n",
        " '会展中心',\n",
        " '工商税务机构',\n",
        " '区县级政府及事业单位',\n",
        " '文化宫',\n",
        " '展览馆',\n",
        " '宠物用品店',\n",
        " '金融保险服务',\n",
        " '斯柯达销售',\n",
        " '交通执法站',\n",
        " '进站口/检票口',\n",
        " '交通服务相关',\n",
        " '水果基地',\n",
        " '渣打银行',\n",
        " '摄影器材店',\n",
        " '华润',\n",
        " '滑雪场',\n",
        " '中学',\n",
        " '音像店',\n",
        " '紧急避难场所',\n",
        " '机械电子',\n",
        " '报社',\n",
        " '商务住宅相关',\n",
        " '雪佛兰维修',\n",
        " '大众销售',\n",
        " '篮球场馆',\n",
        " '必胜客',\n",
        " '东风本田销售',\n",
        " '东北菜',\n",
        " '住宿服务相关',\n",
        " '事务所',\n",
        " '行李查询/行李问询',\n",
        " '疗养院',\n",
        " '吉普销售',\n",
        " '其它能源站',\n",
        " '进口现代销售',\n",
        " '物流仓储场地',\n",
        " '普通地名',\n",
        " '咖啡厅',\n",
        " '灯具瓷器市场',\n",
        " '超市',\n",
        " '宾利销售',\n",
        " '福特销售',\n",
        " '建筑物门',\n",
        " '急救中心',\n",
        " '汽车配件销售',\n",
        " '出版社',\n",
        " '劳斯莱斯销售',\n",
        " '湖南菜(湘菜)',\n",
        " '汽车租赁',\n",
        " '门牌信息',\n",
        " '东风日产维修',\n",
        " '水上活动中心',\n",
        " '医疗保健服务场所',\n",
        " '烟酒专卖店']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}